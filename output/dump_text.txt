<doc id="122944" url="http://fr.wikipedia.org/wiki?curid=122944" title="M4 (langage)">
M4 (langage)

M4 est un langage de traitement de macros.
Un processeur de macros est un outil de remplacement de texte. Sa principale utilisation est de réutiliser des canevas de texte, typiquement dans les applications de programmation mais aussi dans les éditeurs de texte. Parmi les usages les plus courants, l’implémentation GNU de M4 est utilisée dans GNU autoconf, ou encore dans Sendmail pour générer le fichier de configuration sendmail.cf.
À l’époque où l’assembleur était une étape importante du développement logiciel, les programmeurs remarquèrent que la plupart de leurs programmes était de la répétition de texte. Des moyens simples de réutiliser ces textes furent donc inventés. Ils découvrirent rapidement que cela permettait non seulement de réutiliser des pans entiers de texte, mais aussi de substituer des valeurs différentes en fonction de paramètres. Cela définit la portée des processeurs de macro.
M4 offre les possibilités suivantes :
À la différence des processeurs de macros précédents, M4 n’a pas été ciblé pour un langage informatique ou humain particulier. Historiquement, il a toutefois été développé pour supporter le dialecte ratfor du Fortran.

</doc>
<doc id="140890" url="http://fr.wikipedia.org/wiki?curid=140890" title="Advanced Boolean Expression Language">
Advanced Boolean Expression Language

ABEL, acronyme de Advanced Boolean Expression Language, est un langage de programmation informatique utilisé dans le domaine de l'électronique, pour notamment la programmation des PLD. Il a été créé en 1983 par Data I/O Corporation, à Redmond, Washington.

</doc>
<doc id="1736" url="http://fr.wikipedia.org/wiki?curid=1736" title="Logo (langage)">
Logo (langage)

Logo est à la fois une philosophie de l’éducation et une famille de langages de programmation en constante évolution qui aident à la mettre en pratique.
Le projet est né à la fin des années soixante de la rencontre entre le courant cognitiviste en intelligence artificielle et des théories sur l’apprentissage issues de travaux de Jean Piaget et de ses conceptions en matière d’éducation. Ces deux volets sont respectivement représentés par ses promoteurs, Marvin Minsky et Seymour Papert — qui sera le moteur du projet —, au sein du Computer Science and Artificial Intelligence Laboratory (Laboratoire d'intelligence artificielle et d'informatique) du MIT.
L‘appellation, inspirée du grec Logos « parole, discours, intelligence », recouvre, donc, deux concepts étroitement liés quoique distincts : un mode d’apprentissage inspiré des travaux de Jean Piaget sur le développement cognitif de l’enfant et un type d’environnement informatique, à partir d'un langage adapté du LISP spécialement conçu dans une démarche de pédagogie active inspirée des travaux de celui-ci. Il s'inscrit en réaction à une introduction de l'ordinateur dans l'éducation inspirée de l'enseignement programmé.
Sur le plan informatique, Logo est un langage de programmation orientée objet réflexif. Plus lisible que le Lisp, il en est une adaptation, ce qui lui a valu le surnom de « Lisp sans parenthèses ». Essentiellement connu pour la fameuse tortue graphique, mais est également capable de manipuler des listes, des fichiers et des entrées/sorties, … ce qui en fait un langage adapté à l'approche des concepts de l'algorithmique, ce dont on pourra trouver un exemple dans les ouvrages "Computer Science Logo Style" de Brian Harvey, professeur à l'Université de Berkeley.
Bien que langage complet de haut niveau, Logo a été paradoxalement victime de sa tortue - pourtant présente en Pascal - qui l'a cantonnée à une image faussement puérile, ses fonctionnalités de base étaient supérieures aux divers BASIC des années 1980. Il était, à l'époque, un bon marchepied vers la programmation structurée et modulaire et connaît toujours des développements dans le cadre de recherches en intelligence artificielle.
Philosophie du projet.
Logo propose une approche de l’utilisation de l’informatique délibérément constructiviste. C’est l’apprenant, enfant ou adulte expérimenté, qui est le principal acteur de son apprentissage, et l’ordinateur n’est présent que pour lui permettre de construire des réalités dans des environnements divers : les Micromondes, à l’aide d’un langage informatique spécialement conçu à cet effet (la géométrie Tortue en est un exemple).
Il n’est nullement question ici de simulation informatique. « C’est en créant qu’on apprend », telle est la thèse piagétienne que Papert défendra dans la poursuite du projet Logo.
L’objectif va, en effet, au-delà de l’acquisition de concepts qui seraient présents à ces micromondes.
Piaget distingue quatre stades dans le développement individuel dont les apprentissages sont acquis par l’interaction entre l’enfant et son environnement. Il note, toutefois, que, faute de trouver un environnement adéquat – qui n’existe pas -, celui-ci n’atteint pas toujours le dernier stade, celui des opérations formelles. Il émet d’ailleurs cette constatation que nombre d’adultes n'y sont, en réalité, jamais arrivés.
Et c’est ici que l’ordinateur entre en jeu. Papert y voit l’opportunité de créer des environnements propices au développement de ces facultés logiques, à condition qu’il soit correctement adapté à cette fin. Ce sera le cas grâce au langage informatique Logo proprement dit.
L’environnement Logo se veut, donc, imprégné de la pensée de Piaget : il offre à l’apprenant - quel que soit son niveau ou son âge - la possibilité de se représenter et de décrire les phénomènes ainsi que le déroulement de sa démarche entreprise : saisie des moyens utilisés, justification de leur choix et/ou ajustements en cours de tâche. L’objectif poursuivi est d’amener, in fine, l’apprenant à dégager lui-même les caractéristiques de ses actions et de ses propres processus cognitifs. En un mot, qu’il apprenne comment il apprend.
Dans son ouvrage, Papert va même plus loin : l’environnement de Logo pourrait amener l’enfant à adopter de lui-même un mode de pensée procédural, mode de pensée qu’il décrit comment étant plus efficace que tout autre.
Encore faut-il une porte d’entrée qui soit à la portée de cet enfant. Ce sera le rôle de la tortue graphique, un robot dont l’enfant pourra commander les déplacements en s’appuyant sur la connaissance de la manière dont lui-même se déplace. Paradoxalement, le langage été victime de cette tortue qui l'a cantonnée à une image puérile ainsi également d'un succès commercial qui a fait se multiplier des versions incomplètes, non conformes aux exigences fonctionnelles sur lesquelles insiste pourtant son propre concepteur, et parfois limitées à cette tortue graphique. Or, celle-ci n'est pas l'apanage de Logo : elle existe également dans Pascal 7.0.
Dans le développement du projet, l’intelligence artificielle contribuera à différents titres comme celui d’offrir un milieu propice à la recherche fondamentale, avec le Lisp un substrat au développement du langage informatique proprement dit, un premier robot d’expérimentation : la tortue de sol, le développement de la géométrie tortue, … sans oublier l’infrastructure informatique, une ressource rare et chère à l’époque. Il inspire également la notion d'émergence pour comprendre ce que peut pourrait entraîner l'usage de Logo dans d'apprentissage.
Histoire.
Un projet tel que celui porté par Logo relève d’un long processus au cours duquel, tant sous l’influence de l’évolution de la pensée de ses concepteurs – Papert en premier – que des rapides progrès dans le domaine du matériel informatique. Bien que projet et langage informatique vont évaluer de pair, il y a néanmoins parfois lieu d’effectuer une distinction dans l’évocation de leur histoire respective.
La période d’incubation : (1966 à 1980) : une tortue à petits pas.
En tant que langage informatique proprement dit, Logo a été créé chez Bolt Beranek et Newman (BBN). Le concept initial émergea d’intenses discussions en 1966 entre Seymour Papert, Dan Bobrow et . Papert conçut les spécificités fonctionnelles essentielles du nouveau langage et Bobrow contribua à son concept et en réalisa sa première implémentation. Par la suite, contribuèrent également à son développement Richard Grant, Cynthia Solomon, Frank Frazier et Paul Wexelblat.
Il succédait à une première tentative de créer un langage de programmation conçu pour les enfants, TELCOMP, basé sur le FORTRAN. À ce stade, le projet restait très orienté vers l’apprentissage des mathématiques et une familiarisation avec l’algorithmique, tout en insistant pour qu'il soit accessible aux jeunes élèves sans grande préparation. La première version de LOGO fut, d'ailleurs, une version pilote testée en 1967 avec des étudiants en mathématique de grades 5 et 6 à l’école Hanscom Field School de Lincoln, Massachusetts, sous la responsabilité de l’U.S. Office of Naval Research.
À l'issue des quatre années de recherche nécessaires aux chercheurs du BBN, il a reçu de nombreuses interfaces de simulation différentes, dont la tortue graphique, qui apparut cependant relativement tard par rapport à la première version du Logo.
Les premiers utilisateurs en milieu scolaire, eux, l'ont testée à Muzzy Jr High, Lexington, Massachusetts. La première version est sortie, sur un PDP-1, en Lisp. Il était alors appelé Ghost, et était destiné à la résolution de problèmes de base : les bugs pouvaient être mis en valeur immédiatement grâce à la tortue. Le langage n'était pas particulièrement puissant, et la conception avait plutôt été axée sur la simplicité d'utilisation pour des débutants en informatique (qui devaient alors utiliser un Teletype). La possibilité de fournir un commentaire détaillé des erreurs était également déterminante.
En 1970, Seymour Papert fonda le laboratoire LOGO au M.I.T. L’année suivante vit apparaître les premières expérimentations avec les tortues LOGO (de sol ou d'écran), considérées à tort par beaucoup pour être essentielles au projet LOGO alors qu’elles n’en représentent qu’un sous-ensemble. Plusieurs implémentations sur différents matériels et des expériences pédagogiques suivirent au cours de la décade des années 1970 au M.I.T. mais aussi ailleurs comme à l’Université d’Edimbourgh ou à celle de Tasmanie, en Australie (c’est, d’ailleurs, par cette dernière que se diffusa la première tortue graphique sur Apple II sous le nom de Tasmania Logo).
Cette phase de réflexion et d'expérimentation est marquée par des recherches ponctuelles au sein d’écoles voisines (dont la Brookline Public Schools) et donnèrent lieu à des publications à diffusion restreinte (« "papers" »), les Logo Memos, relatant les enseignements tirés de ces expériences.
Apogée et désillusion (1980 à 1990) : du lièvre à la tortue.
LOGO va quitter le laboratoire et connaître sa période faste au début des années 1980. Deux facteurs vont contribuer à cet engouement :
L’horizon de la tortue s’élargit, en effet, avec l’apparition des micro-ordinateurs. Fin des années 1970, le MIT Logo Group s’attelle à développer des versions de Logo pour le Texas Instruments TI-99/4A et Apple II, tous deux sortis en 1977. Si la base du langage est commune, les interfaces graphiques sont différentes eu égard aux spécificités des deux machines : du fait de son interface de type « jeux vidéo », la version pour le TI 99/4A privilégie les projets orientés vers le mouvement (les dyna-turtles ou lutins), tandis que celle pour l’Apple II donne la préférence au graphique tortue bien connu et à la manipulation de mots et de listes - bien moins connue.
En 1980 est lancé un projet pilote à la Lamplighter School de Dallas où 50 TI 99/4A sont mis à la disposition des 450 élèves. Dans la foulée est lancé un autre projet à New York avec 12 TI 99/4A auxquels s’ajouteront un peu plus tard quelques Apple II. De ces deux projets naîtront des produits commercialisés par la société Terrapin Softwares (qui commercialise également des tortues de sols depuis 1977) : le TILOGO sur le TI 99/4A et le Terrapin Logo, devenu par la suite Logo PLUS, sur Apple II.
En 1980, une nouvelle entreprise est formée, la Logo Computer System Inc. (LCSI) qui va regrouper sous l’égide et la présidence de Papert nombre de chercheurs, enseignants, développeurs et autres programmeurs embarqués dans l’aventure qu’a été le développement du projet. Dans les années qui suivent, LCSI implémentera sur la plupart des nouveaux micro-ordinateurs le langage avec ses caractéristiques fonctionnelles réclamées par son initiateur. Ainsi naquirent APPLE LOGO, Commodore LOGO, Atari LOGO, ensuite IBM LOGO, et enfin, Mac LOGO, tous construits sur les mêmes fondements, mais enrichis en fonction de l’évolution technique des matériels. Des versions pour une douzaine de langues furent développées, chose en soi très facile puisque l’architecture permettait de redéfinir aisément les primitives du langage (de même qu’il est toujours possible de « doubler » une primitive par une procédure construite avec celle-ci). En réalité, la vraie difficulté dans les traductions a résidé dans le choix des termes qui doivent être tirés du langage naturel et ne revêtir aucune ambiguïté. C’est ainsi, par exemple que Papert, après avoir longtemps hésité, donna sa préférence à la traduction canadienne DROITE ou GAUCHE plutôt qu’aux TOURNEDROITE ou TOURNEGAUCHE devenus usuels par la suite sous l’influence française. Petit détail amusant, c’est pourtant au Centre mondial informatique et ressource humaine que Papert, qui en était devenu le directeur scientifique, mettra la dernière main à la version française du Apple Logo.
Le plus digne successeur de cette série est certainement le UCBLogo développé par Brian Harvey qui ne cessera d’enrichir le langage informatique dans le strict respect du métalangage, tout en indiquant explicitement comment changer ou traduire les primitives et les messages.
D’une manière ou une autre, les nombreuses versions de Logo s’inspireront avec plus ou moins de rigueur des versions LCSI, y compris un Logo de qualité discutable pour les ordinateurs MSX qui domineront de plus en plus le marché de l’éducation, sauf aux États-Unis où Apple reste le favori. Une domination renforcée par l’échec du lancement du PC Junior d’IBM qui pouvait supporter un Logo de qualité et le choix politique en France de privilégier Thomson MO5 dans le Plan informatique pour tous. Les développeurs se tourneront alors vers ce matériel en ajoutant, par exemple, les tortues dynamiques développées sur le TI 99/4A, le tout fonctionnant avec des cartouches à insérer.
À la même période, va se manifester un certain intérêt pour utiliser Logo en tant que langage de programmation proprement dit comme ce sera le cas avec le MacLogo de LCSI et Object Logo de Coral Software, une autre version pour le MacIntosh qui comprenait notamment un compilateur et même un débuggeur. Mais Logo ne parvint jamais à intéresser les programmeurs professionnels, sans doute à cause de l'étiquette « pour enfant » qui lui collait à la peau.
En 1985, LCSI lance Logowriter qui, outre une interface simplifiée et plus intuitive, comprend un traitement de texte et réintroduit les « lutins » (sprite), des tortues qui peuvent prendre des formes et des couleurs différentes.
Parallèlement, et Steve Ocko vont développer LEGO Logo une interface entre Logo et des moteurs, lumières et autres détecteurs utilisables dans des montages avec les fameuses briques Lego. Cette idée d’utiliser des robots n’était pas neuve mais recueillit néanmoins un succès commercial.
Alors que LCSI marque le pas avec Logowriter, Terrapin Softwares et Harvard Associates, les premiers pour Macintosh, les seconds pour DOS et ensuite Windows, vont continuer à développer des versions qui, bien que bénéficiant des progrès du matériel, se cantonneront à la géométrie Tortue et à la manipulation de mots et de listes.
Par contre, même si les initiatives d'introduction de Logo se multiplient durant cette décennie, il faut bien reconnaître que le volet « projet d'apprentissage » du projet marque le pas dans un monde de l'éducation qui se révélera très vite frileux (cf supra).
Les expériences s'arrêtent souvent à une ou deux semaines, c'est-à-dire le temps de découvrir et de s'amuser avec la tortue graphique comme telle que celle menée par l'INRP en France, sauf dans des ateliers privés ou des écoles privilégiées par un projet pédagogique qui favorise une approche active de la part de l'apprenant.
Ce n'est d'ailleurs pas un hasard si Logo reçoit un accueil privilégié en Argentine où l'éducation est fortement imprégnée de la pensée piagétienne.
Après 1990, de Logo au constructionnisme ; les métamorphoses de la tortue.
Au début des années 1990, Logo est considéré comme un produit vieillot et obsolète en Amérique du Nord. Logowriter n’a plus guère évolué depuis sa sortie. Quant au Logo classique, il n’a pas intégré les apports de la rapide évolution des ressources informatiques. En Europe, l’engouement des premiers temps a fait long feu après l’échec des plans informatique visant à introduire les nouvelles technologies de l’information dans l’enseignement. À l’exception de la Grande-Bretagne qui l’utilise comme un outil pédagogique sans rapport avec le projet d’apprentissage sous-jacent, son usage est devenu anecdotique dès le milieu des années 1980 dans un contexte pédagogique largement défavorable à sa philosophie.
Ce n’est pas nécessairement le cas partout. Par exemple, un ambitieux programme est lancé au Costa Rica par une « ancienne du MIT», Clotilde Fonseca, qui va faire école dans une douzaine de pays d’Amérique Latine. Au Japon, Logowriter va également faire son chemin au début des années 1990.
Un regain d’intérêt se manifestera vers le milieu de la décennie où l’on verra s’effacer Logo, tel qu’il était défini au début des années 1980, au profit du développement de nouveaux produits et d’un nouveau concept : le .
En fait, si le nom de Logo va peu à peu disparaître, les idées qui en formaient le substrat, subsistent dans les grandes lignes. Même si elles intègrent de nouvelles fonctionnalités, les conceptions à la base du langage informatique restent les mêmes : un langage « naturel » avec des mots « de tous les jours », que l’on peut combiner et enrichir de nouveaux mots ;
Par contre, le projet éducatif, lui, s’est affiné. D’abord plutôt vague sur son option pédagogique dans sa description du « facilitateur » en milieu Logo, Papert opte résolument pour une pédagogie active, en insistant sur l’importance de créer des choses - « making things - lorsqu’on apprend ainsi que sur celle de la verbalisation dans la construction de nouvelles connaissances.
Plus tard, Resnick, le concepteur des nouveaux micromondes, va encore compléter le concept en y ajoutant une dimension de travail de groupe.
Sur le plan informatique, MicroWorlds Logo va ajouter dès 1993 de nouvelles fonctions à l’environnement Logo en se basant sur l’interface MacIntosh : de nouveaux outils de dessins, un éditeur de formes, un générateur de musique et la possibilité d’importer des images ou des sons. De même, il prend en charge les tâches multiples de sorte que des objets peuvent être animés ou créer de manière indépendantes : la tortue n’est plus toute seule.
Au MIT, une brique programmable apparaît dans le cadre de Lego Logo qui rend inutile une liaison avec un ordinateur.
Par ailleurs, Brian Harvey va continuer à enrichir le langage de base sur le plan purement informatique UCBLogo, dans sa version distribuée librement, comprend 344 primitives.
À l’autre extrémité, dans le domaine de la recherche, avec, Mitchel Resnick va développer avec des environnements où des milliers de « tortues » peuvent interagir.
Plus récemment, le même Resnick proposera avec Scratch un nouveau projet de type Logo intégrant une implémentation visuelle et dynamique du langage de programmation Smalltalk basé sur Squeak. Squeak est l'héritier du Logo dans l'approche qu'il propose de l'interaction informatique-éducation. Il s'inscrit dans les cadres théoriques de la psychologie du développement et des idées de gens comme Baldwin, Piaget ou Vygotski.
Implémentations.
Il existe plus de 130 implémentations du Logo, aux caractéristiques variées.
Et, faut-il le dire, de qualités variables tant au niveau informatique que par rapport au projet éducatif. Certains ne sont, d'ailleurs pas des langages informatiques, même simplifiés, mais seulement des programmes informatiques.
Ainsi, Papert s'insurgera contre les versions simplifiées comme le « Logo instantané » où les instructions sont facilitées par des touches fonctions, celles limitées au graphisme Tortue ou encore celles où la tortue ne tourne que par des multiples de 10 ou de 30° : "Comment peut-on découvrir à quoi ressemble un angle à 45 degrés quand il peut tourner la tortue seulement dans les multiples de 10 ou 30 degrés à chaque fois ?"
Berkeley Logo.
UCBLogo est l'implémentation la plus populaire, un logiciel libre réalisé par Brian Harvey de l'université de Californie à Berkeley.
Il existe plusieurs implémentations de" UCBLogo", parmi lesquelles "MSWLogo", une version pour MS Windows très utilisée dans les écoles britanniques.
Implémentations propriétaires.
D'autres implémentations ont ou ont eu une importance qui mérite d'être signalée : le P_Logo, des éditions Profil ; le jLogo et le XLogo, basées sur des interpréteurs écrit en Java.
Il n'existe aucune norme de Logo, mais uniquement une tradition. Ainsi, on constate des différences importantes entre les différentes évolutions du Logo. Les exemples de code donnés ci-dessous sont censés fonctionner dans la plupart des dialectes du Logo.
Logo, langage informatique.
Aperçu du Métalangage.
LOGO fait partie de la famille des langages de programmation orientée objet. Ses règles de syntaxe sont réduites au minimum et le vocabulaire se rapproche le plus possible du langage "naturel", des mots de tous les jours. C'est évident pour les commandes de la tortue graphique, mais également pour le traitement de mots ou de listes. Par exemple, il comprend des termes comme SAUFPREMIER, PREMIER, … aujourd'hui largement utilisés dans les bases de données.
À l'origine n'existe que 2 types d'objets : les MOTS et les LISTES.
Les "MOTS" sont des chaînes de caractères. Formellement, les nombres ne sont que des mots particuliers reconnus et évalués automatiquement par leur valeur. 
Les "LISTES" sont des suites ordonnées d'objets.
Un mot est signalé par un guillemet, une liste par des crochets. Si un mot n'est pas précédé d'un guillemet, il est interprété comme une procédure (voir ci-dessous).
Ces objets peuvent servir d'entrées - "d'ARGUMENTS" - à des OPÉRATIONS ou des COMMANDES.
Une OPÉRATION sert à créer un nouvel objet à partir des objets entrant (formellement des ARGUMENTS), qu'elle "retourne" à une autre opération ou à une COMMANDE.
Une COMMANDE dit ce qu'il (l'ordinateur ou le robot) doit faire de cet objet.
Une ligne de programmation est et ne peut être que formulée qu'en termes d'INSTRUCTION.
Une instruction se compose impérativement d'une - et d'une seule - COMMANDE, suivie d'un objet, d'une ou de plusieurs OPÉRATIONS qui retournent l'objet qu'elles créent à l'éventuelle opération qui la précède, ou à la commande.
C'est pourquoi taper simplement 5 + 5 (ou, plus formellement, SOMME 5 5) entraîne un message d'erreur du type ""Ne sait que faire avec 10"", puisqu l'instruction est incomplète du fait de l'absence de commande. De même ECRIS "tout seul" fera apparaître une message "Pas assez d'entrée pour…" puisque, cette fois-ci l'instruction est incomplète du fait de l'absence d'objet.
Par contre, dans l'instruction ECRIS 5 + 5 affiche 10, l'opération d'addition sur des mots directement évalués comme des nombres retournant son résultat à la commande d'affichage,
De même, dans le micromonde "Tortue", AVANCE 5 + 5, fera se mouvoir le robot tortue de 10 pas.
Par contre, ECRIS + 5 produira un affichage du texte 5 + 5 puisqu'il s'agit d'afficher le contenu d'une liste signalée par les […].
Un groupe d'instructions peut toutefois être écrit sur une même ligne. Sera, donc, licite :
codice_1
La seule exception à la règle de commande unique réside dans l'emploi de la primitive REPETE qui accepte comme entrée une liste d'instructions.
codice_2 (formule du cercle en géométrie LOGO).
Soit une instruction qui commande de répéter 360 fois, deux instructions
Les mots prédéfinis dans le langage sont appelés PRIMITIVES du langage.
Ce langage de base peut s'enrichir de PROCÉDURES créées par l'utilisateur. Une fois définie, ces procédures vont faire partie intégrante du langage et obéissent aux mêmes règles d'écriture. Leurs définitions sont écrites et corrigée dans l'éditeur "ED" ou, dans certaines versions, définies directement à l'aide de la commande "POUR", suivie du nom de la procédure (ce qui facilite le passage de la commande directe vers la programmation)
Une procédure comprend trois partie : son nom, les commandes et opérations que son activation déclenchera et le mot FIN. Elle peut être définie comme nécessitant une ou plusieurs entrées qui, sont, en réalité des variables pouvant stocker localement des objets. Dans ce cas, leur utilisation exigera impérativement l'introduction d'objets. Taper un mot qui n'est pas une procédure ou une primitive sera signalé comme une erreur "ne sait comment…"
LOGO se présente comme un langage évolutif : les "primitives" ne sont, en réalité que des procédures "build in".
Dès lors, en toute logique, une procédure doit pouvoir comprendre des procédures, "y compris elle-même"', ce qui confère à LOGO la puissance d'un langage récursif.
codice_3
est donc licite et crée une boucle sans fin.
De même, une procédure peut être construite de manière à nécessiter un ou plusieurs arguments.
codice_4
crée une procédure qui permet de dessiner des cercles de taille variable : par exemple CERCLE 0,5 ou CERCLE 1 ,
mais, toujours, à partir d’un point de la circonférence (ici situé à 180°) puisque la tortue dessine le contour d’un objet graphique et part, dès lors, d’un point sur ce contour.
"PS : rien n’est plus difficile que de dessiner un cercle à partir de son centre : par exemple, au point d’origine (0,0) de la tortue, au centre de l’écran, pour ne rien dire du dessin de cercles concentriques !"
Toujours aussi logiquement, une procédure peut être une opération en utilisant la primitive RETOURNE.
Ainsi si on définit la procédure suivante :
codice_5
codice_6 affichera
30
"Force est de reconnaître qu'en réalité, peu de versions de Logo intègrent ces aspects."
L'interprétation se fait de la gauche vers la droite. Par exemple,
ECRIS SOMME 7 PRODUIT 5 2
17
est interprété par Logo de la manière suivante :
Les variables ne doivent pas être déclarées au préalable. Elles ne nécessitent aucune notation particulière et peuvent être nommée par n'importe quel mot, même par le nom d’une procédure existante, et il est d’ailleurs chaudement recommandé de choisir des termes explicites. Leur contenu étant un objet, il peut être un MOT ou une LISTE.
Par défaut, les variables sont globales. Dans des versions complètes, elles peuvent éventuellement être déclarées comme locales. Lorsqu’elles servent d’arguments à une procédures, elles sont toujours locales et leur contenu ne conserve leur valeur que durant l’exécution de la procédure. Il est néanmoins possible de créer des variables globales à l’intérieur d’une procédure.
Exemple :
DONNE "Nomdelavariable 4
ECRIS SOMME 7 PRODUIT 5 CHOSE "Nomdelavariable
27
En notation simplifiée et plus courante, on peut également écrire :
ECRIS SOMME 7 PRODUIT 5 :Nomdelavariable
27
De même, Logo comprend également des notations mathématiques préfixes ou infixes.
Exemple :
Formellement, seule le forme préfixe répond aux exigences de syntaxe comme quoi les objets suivent une opération à laquelle ils servent d'arguments. Tout comme l'interprétation directe d'un nombre, la forme infixe n'existe que parce que cette notation est familière.
Enfin, par défaut, Logo sauvegarde dans un seul fichier tout l'espace de travail et le restaure en une seule instruction.
Interface graphique : la tortue.
Le terme "Tortue" relève d'une tradition née vers 1950 avec les premiers robots construits par le neurophysiologiste William Grey Walter, pionnier de la cybernétique avec ce qu'il appellera ses "tortoises".
Description.
À l'origine un robot de sol, la "tortue" est un robot sur l'écran, prêt à explorer son espace. Dans ce cas, le plus connu, elle se présente la plupart du temps sous la forme d’un triangle orienté dans la direction qu’elle va prendre. Elle traîne à l’arrière – "et non derrière elle, la nuance est d’importance d’un point de vue pédagogique" – un crayon qui lui permet de laisser des traces de son passage. Ce crayon peut être levé (LC) ou remplacé par une gomme. Avec l’évolution du matériel informatique, il pourra également prendre des couleurs différentes.
Au départ, ce robot occupe une position et une orientation précises. Au départ, ce seront le milieu (position 0,0) et le haut de l’écran, c’est-à-dire vers le « Nord », au cap de 0°.
On travaille, donc, en coordonnées polaires et non pas en coordonnées cartésienne, même si le langage comprend la possibilité d’utiliser ces dernières. La Tortue se déplace comme un navire, c’est-à-dire en prenant une direction relative et en parcourant une distance à partir d’un point et d’une orientation de départ.
Mieux, elle se déplace, en réalité sur un tore, ce qui explique qu’en position normale, elle « ENROULE », c’est-à-dire que si elle disparaît par un côté de l’écran, elle réapparait à son opposé.
Le concept de la « géométrie Tortue » est issu des travaux du Logo Group du MIT et permet à l’apprenant d’explorer un univers géométrique en s’identifiant à la tortue. Ce que Papert appellera la « syntonie avec le corps ».
Au départ, l’utilisateur lui donne des ordres simples, « militaires » : AVANCE, RECULE, DROITE, GAUCHE pour la faire se déplacer. Elle se déplace pas à pas et s’oriente par degré ; à chaque 360°, elle fait, donc, un tour complet sur elle-même (théorème du tour complet de la tortue). Du fait de son crayon, elle laisse une trace de son passage sur l’écran (sauf, bien sûr, si on lui a donné l’ordre de la lever).
Par la suite, ces ordres pourront être rassemblés dans des PROCÉDURES qui enrichiront le langage informatique et pourront, par conséquent, elles-mêmes être appelées dans d’autres procédures.
Dans un grand nombre d'interfaces graphique de Logo, l'écran est divisé en 2 parties afin de permettre de visualiser à la fois les instructions qui lui sont données et leurs résultats :
Quelques exemples.
Exemple de définition de procédure : la procédure CARRE devra tracer un carré à l'écran. Le texte est tapé dans l'éditeur du LOGO, puis sauvé.
ou plus simplement
Emploi de CARRE dans une autre procédure :
Dans cet exemple,
Pour employer PLCARRE, il suffit de taper dans la zone de commande PLCARRE.
Le passage de paramètres à une procédure est possible.
Utilisation : CARRE 50 trace un carré de 50 pas de TORTUE.
Pour faire un CERCLE, il suffit de décrire le périmètre de celui-ci
"En réalité, il s'agira d'un polygone régulier à 36 côtés, cette formule ne s'applique qu'au versions LOGO où la Tortue ne peut tourner que par des angles de 10°.
La rosace présentée en illustration peut donc s'écrire (KTurtle)
pour un hexagone
REPETE 6100 TG 60
Logo, philosophie de l'éducation.
Il faut le dire tout de go : dès l’abord, Papert n’envisage pas Logo – et, l’informatique, en général - comme un outil pédagogique, ni, a fortiori, son usage scolaire, mais comme le moyen de créer un nouvel environnement d’apprentissage. Dans "Jaillissement de l'esprit" (op. cit.), il oppose l'apprentissage syntone à l'apprentissage dissocié que présente traditionnellement l’école, dans laquelle ce qui est enseigné ne s’accorde pas avec les enfants (cf infra). Néanmoins, passé les premiers pas en laboratoire, force est de constater que les premières utilisations de Logo se passeront dans des écoles, lieux institutionnels – institutionnalisés – des apprentissages. Dès lors, sauf à réserver Logo à quelques clubs ou ateliers fréquentés par quelques privilégiés, le problème de son introduction dans le milieu scolaire va vite se révéler incontournable et, dans son sillage, apparaîtront les questionnements pédagogiques.
Le temps passant, Papert montrera de plus en plus de réticence vis-à-vis de l’école : « "Une réforme (de l’enseignement) vise à modifier l'école, mais, in fine, c’est l'école qui change la réforme. On peut voir au premier abord une tautologie dans cette proposition d'expliquer les échecs d’une réforme. Mais dire que l'école change de la réforme est très différent de dire tout simplement que l'école résiste ou rejette la réforme. Elle résiste à la réforme d'une manière particulière - en s'appropriant ou en l'assimilant à ses propres structures. Ce faisant, elle désamorce l’action des réformateurs et parvient parfois à prendre dans quelque chose de ce qu'ils proposent" » .
Selon lui, les ordinateurs ont plutôt la vocation de substituer une autre structure à l’école, pas de l’améliorer.
Cadre théorique : les hypothèses de Papert.
Dans le sillage de Piaget.
Avec le projet Logo, Papert veut mettre en pratique les idées constructivistes de Piaget grâce à l'informatique. Il ajoute, toutefois, une dimension aux notions d’assimilation et d’accommodation développées par ce dernier : l’importance de l’affectif dans le processus d’apprentissage (NB : Piaget n’a pas étudié cet aspect par manque d’éléments théorique à ce sujet).
Une autre différence porte sur les raisons d’une difficulté de l’apprenant à assimiler certains concepts. 
Selon Piaget, certains concepts ne pourront être assimilés qu’à partir d’un certain âge et après l’assimilation d’autres concepts (les pré-requis). Ces stades de développement de l’intelligence sont communs à tous les enfants et ont un caractère universel, indépendant de la culture au sein de laquelle se passe l’apprentissage. Par contre, pour Papert, si l’acquisition d’un concept pose problème, c’est par manque de matériau à disposition de l’apprenant pour l’aider à l’assimiler dans sa culture. Autrement dit, l’ordre dans lequel sont acquises les connaissances n’a pas ce caractère universel, mais dépend de l’abondance ou de pénurie de matériaux permettant leur acquisition dans une culture donnée (cf . Partant de là, Papert propose de créer de nouveaux matériaux à manipuler par l’enfant qui soient propres à aider l’acquisition de notions comme les mathématiques et la physique et cela, au travers d’environnements construits à cet effet à partir de cette nouvelle venue qu’est l’informatique.
Apprentissage syntone versus apprentissage dissocié.
Encore faut-il pour cela que ce support informatique réponde aux exigences d’’un tel matériau pour que l’enfant puisse s’en emparer et le manipuler comme les autres.
Pour ce faire, il part d’un constat : l’apprentissage le plus répandu et qui réussit le mieux, est celui de l’apprentissage de la langue. Or, cet apprentissage se produit naturellement, sans intervention d’enseignant désigné. Il se construit, point barre. Le Logo group va s’inspirer de ce modèle d’apprentissage de la langue (en dehors de l’école) pour tenter de l’appliquer à d’autres domaines. Pour cela, il faut que l’enfant continue à trouver un sens à ce qu’il fait, que ceci s’accorde avec sa perception et ce qu’il connaît déjà.
C’est tout le contraire, selon lui, d’un apprentissage scolaire dominé par une conception disciplinaire et transmissive de l’enseignement et le suivi d’un “programme d’enseignement” pour chaque niveau qui ne s’accorde pas avec l’enfant, mais qui lui est imposé.
Dès lors, prenant le contre pied les dictacticiels qui, créé pour enseigner à l’élève une discipline, ne font que reproduire l’enseignement classique avec un ordinateur, il veut que ce soit l’enfant qui apprenne à l’ordinateur à réaliser des tâches et non l’inverse et, donc, à l’instar de Dwyer avec le BASIC, l’apprenant sera programmeur et non programmé. 
Par contre, contrairement à ce dernier qui, même simplifié, reste un langage d’informaticien, LOGO sera conçu dans une langue proche du langage naturel et, donc, facile à assimiler.
Apprendre les mathématiques en « mathématie ».
Tout à l’opposé de cet apprentissage naturel du langage est, pour le mathématicien qu’est Papert, celui des mathématiques. En effet, pour nombre (la plupart ?) des personnes ayant suivi une scolarité traditionnelle, les mathématiques reste un sujet de dégoût.
Or, pour lui, la distinction entre “sciences” et “lettres” comme deux groupes de disciplines n’est que culturelle : tout le monde est naturellement mathématicien de par des besoins de la vie courante, ce qui n’empêchent pas certaines personnes de refuser les mathématiques dès qu’elles sont identifiées comme telles.
Si beaucoup de personnes sont mathophobes, c’est à cause de l’enseignement scolaires des mathématiques qui se caractérise par une dissociation du vécu des enfants et se résume souvent pour eux par des recettes à apprendre. Ces mathématiques scolaires sont une construction faisant suite à des accidents, ou plus généralement, une histoire, mais n’ont pas été réfléchies selon des critères objectifs. L’habitude est devenue la seule raison du contenu de ces programmes scolaires en mathématiques.
Pour remplacer cela, Papert propose de plonger les enfants en “mathématie”. Les enfants vont découvrir naturellement des notions de mathématiques dans un micromonde de la même manière qu’ils apprennent naturellement une langue ou d’autres concepts, telle que décrite par Piaget.
Ce micromonde où les mathématiques pourraient être appropriées par les enfants, doit reposer sur trois principes :
Si ce dernier principe démontre l’intérêt que Papert porte au champ socio-cognitif de l’apprentissage, il implique que l’enfant ne se retrouve pas seul devant l’ordinateur. Et la problématique de cet accompagnement contituera sans doute LA pierre d’achoppement pour Logo.
La tortue, objet de transition.
Pour que l’enfant entre dans ce micromonde de la « mathématie », Logo comprend une voie d’accès qui lui propose un apprentissage syntone, cest-à-dire qu’il lui permette de relier la manipulation du nouveau matériau proposé avec ses apprentissages passés tout en restant attractif et motivant : d’où la partie graphique du langage consacrée à la Tortue.
La Tortue – quelle que soit sa forme : robot ou forme sur l’écran - est un objet anthropomorphique (au début, beaucoup d’enfants lui prêtent toutes sortes d’intentions !) dont les déplacements dans l’espace peuvent être commandés par des mots concrets, issus du langage familier. L’exécution des dessins par des commandes simples crée ainsi une seuil de communication avec l’ordinateur qui reste très proche du quotidien.
Apprendre à contrôler la Tortue met à contribution chez l’enfant son désir de communiquer, son plaisir de donner des ordres et son goût pour le mouvement. L’activité de programmation consiste, donc, à apprendre à l’ordinateur (la Tortue, en l’occurrence) ce qu’il veut lui vouloir faire. De la sorte, si l'enfant peut s'appuyer sur la connaissance intuitive qu'il a des mouvements de son compte (sur ses schèmes sensori-moteurs), en s'identifiant avec la Tortue ("jouer Tortue" avec son corps), il doit traduire son intuition sous une forme qui soit compréhensible à celle-ci. Or ""traduire une intuition sous forme de programme, c'est la concrétiser, la rendre plus palpable et plus accessible à la réflexion"" (Papert, 1981, o. c., p. 82).
La Tortue est, donc, un objet de transition entre l’acquis de l’enfant qui est la connaissance de son corps et de ses mouvements ainsi que le langage simple qui les commande ou les décrit. Cette appropriation est facilitée par trois éléments qui, mutatis mutandis, correspondent aux principes directeurs décrits plus haut :
Un autre aspect du langage Tortue réside dans une nouvelle approche de la géométrie en propposant un micromonde que l’enfant peut explorer et dans lequel il peut construire selon son mode d’apprentissage naturel et non sur une approche formelle et propositionnelle de cette partie des mathématiques : une nouvelle pierre d’achoppement pour Logo.
L'erreur n'est pas une faute.
Traditionnellement, lorsqu’un élève fait une erreur en mathématiques – comme dans d’autres domaines -, il s’empresse de l’oublier. Cette réaction est encouragée par la sanction scolaire qui dit c’est soit "faux", soit "bon".
En LOGO, l’erreur n’est pas qualifiée de cette façon. Ce n’est qu’un défaut partiel et momentané dans un programme (« un simple bug informatique »). On ne jette pas la totalité d’un programme - ou d’une liste d’instructions dans les premiers temps - parce que tout ne se passe pas comme prévu. L’élaboration d’un dessin, puis d’un programme, se fait par une suite d’essais, d’erreurs et de corrections. Les enfants prennent conscience qu’il n’y pas que du “tout bon” et du “tout faux” puisque qu’ils peuvent s’approcher peu à peu, pas à pas, de la solution pour un projet initialement imaginé.
Papert développe longuement cet aspect de suites d’essai-erreur ainsi que le jugement de valeur porté sur l’erreur, car cette question est cruciale à ses yeux. LOGO ne peut pénaliser pas l’erreur de la même manière que l’enseignement classique qui décourage les enfants à se construire des théories.
L’objectif à poursuivre dans cette esprit, était de trouver le moyen de fournir à l’enfant un contexte lui permettant d’élaborer des “théories de transitions”. Ces théories de transitions sont communément qualifiées de “fausses”, sans plus. Or, dans leur processus d’apprentissage, les enfants se construisent des modèles qui leur permettent de se faire la main avant de les abandonner s'ils se révèlent inadéquats. Papert s’appuie ici sur les travaux de Piaget qui démontrent que ces fausses théories qu’élaborent les enfants sont nécessaires pour apprendre à penser. Les théories non orthodoxes des jeunes enfants ne résultent pas d’une faiblesse, mais sont un moyen pour eux d’assouplir leurs facultés cognitives, de développer en s’entraînant leur aptitude à la construction de théories plus orthodoxes. Les micromondes procureront, donc, aux enfants l’occasion de se construire des théories à eux et de les confronter à la réalité des choses en les testant sur l’ordinateur. De la sorte, ils entrent sans le savoir dans une démarche scientifique classique, mais ce nouveau statut de l'erreur sera une fois encore une autre pierre d’achoppement pour Logo.
La programmation structurée comme modèle de pensée.
Piaget s'est interrogé sur une certaine convergence entre les résultats de ses recherches sur la genèse des opérations logiques et mathématiques et un certain nombre de résultats mathématiques atteints dans leurs recherches des structures-mères (Structure_) par les Bourbaki.
Chez ces derniers, une structure complexe est une combinaison de structures plus simples, dont les plus importantes sont des structures mères qui constituent des éléments fondamentaux. Or, Piaget va observer que les enfants développent des structures intellectuelles proches de ces dernières :
Il existerait, donc, une similitude entre le parcours de l’enfant construisant l’arithmétique élémentaire et l’histoire de la mathématique, mais également entre les mécanismes qui permettent aux deux de construire une nouvelle connaissance plus complexe à partir d’anciennes plus simples. En bref, l’acquisition d’une structure facilite l’acquisition des autres.
Papert étend cette similitude à l’informatique par une autre correspondance avec la programmation : des procédures simples, en s’assemblant, peuvent former des résultats complexes.
Alors que Piaget cherchait à comprendre comment se développe l’enfant "hinc et nunc", Papert cherche à agir sur le développement via le nouvel environnement culturel permis par l’ordinateur. La culture informatique peut “"grandement renforcer, chez les enfants, leur capacité à concevoir les structures en place sous des aspects qui mobiliseront leur potentiel conceptuel"”. Mais cela n’est possible que lorsque le langage informatique dispose de procédures pures (autonomes et mobilisables de manière modulaire) comme c’est le cas en Logo. En effet, dans son emploi, la programmation structurée devient assez vite indispensable. Elle consiste à découper un tout en petites parties indépendantes qui, une fois au point, peuvent entrer une ou plusieurs fois dans le tout. Dès qu’un enfant a un projet un peu ambitieux, il est confronté au handicap de répétition et à la difficulté de débugage. Or, ce dernier est largement facilité lorsque le projet est découpé en petites procédures (modules).
L’hypothèse de Papert est que la pratique de la programmation structurée aura des conséquences sur le raisonnement de l’enfant face à certaines autres tâches complexes dans la mesure où il y aura transfert de cette manière de décrire et d’aborder un problème lorsqu’il sera confronté à d’autres situations situées dans un autre champ d’action.au nouveau problème qui se pose à lui. Mais encore faut-il pour cela que l’enfant accède à cette programmation structurée ! Encore une pierre d'achoppement.
La Tortue à l’épreuve de la pédagogie.
Dans un premier temps, les enseignants, sans y être forcément favorables, ont bien accueilli l’alternative que leur apportait Logo comme un moindre mal à l’introduction de l’ordinateur à l’école face à l’enseignement assisté (EAO) ou à l’enseignement programmé par l’ordinateur (EPO). Rares furent toutefois ceux qui adhéraient à la vision de Papert en connaissance de cause tant sur le plan de l’apprentissage que sur celui de l'impact possible du nouvel outil informatique sur l'enseignement. Rien d’étonnant, dès lors, à ce que les conceptions des mises en œuvre de Logo divergeront rapidement entre un monde pédagogique centré sur le « comment produire un "enseignement" efficace ? » et Papert, centré comme Piaget sur le « quelles sont les conditions proprices à un "apprentissage" efficace ? ». Mais, par ailleurs, on ne peut nier que certains aspects de Logo faisaient problème (cf infra).
Il reste que comme le constate Jean-Michel Chevalier, ""L'intensité des critiques (des pédagogues) est à la hauteur de l'engouement qu'il suscite dans les années 80"". Ceux-ci sont, en effet, guidés avant toute chose par un souci de rentabilité et de gain de temps en contexte scolaire, Tout à l'opposé de Papert.
Sur le plan expérimental, Logo avait d’abord été utilisé dans une approche surtout individualiste propre au contexte américain. En France, Gérard Bossuet va rapidement le présenter comme n’étant pas seulement un objet structurant, mais également comme un prétexte à la communication avec les autres, enfants ou adultes, au même titre que, par exemple, l’imprimerie chez Célestin Freinet . Partant de l’idée que la classe forme une micro-société englobant enfants, enseignants mais aussi parents et s’inspirant des travaux de Doise et Mugny sur l’importance de l’interaction sociale dans le développement cognitif, Pierre Biernaux franchit encore un pas en expérimentant l’introduction des ateliers à l’intérieur même de cet autre entité sociale qu’est l’école - démarche qui impliquait nécessairement l’inclusion de l’équipe de chercheurs dans ses observations.
Plus tard, Resnick intégrera cette dimension de travail en groupe dans l’idée de « constructionnisme ».
Apprendre en « Mathématie » peut être déconcertant… pour l’enseignant.
Très tôt, souvent dans le cadre de thèses de doctorat, des chercheurs se sont intéressés aux apport de Logo dans leur domaine - celui de l’enseignement des mathématiques - soit pour faciliter l’accession de certains concepts : géométrie, variable, récursion,… soit pour étudier l’opportunité de l’intégrer dans le cursus d’algèbre ou de géométrie. Le plus souvent, ceci s’adressait à des élèves plus âgés et Papert, de rappeler dans la préface de l’ouvrage précité que le but de Logo était aussi, sinon avant tout de donner aux jeunes enfants la possibilité de se familiariser très tôt avec des notions proches, d’y "toucher" (to feel) sans pour autant forcément déjà en comprendre la signification, mais de sorte que soit facilitée leur acquisition plus tard.
Si pour ces spécialistes, l’enjeu était palpable, il en allait bien autrement dans l’enseignement proprement dit auprès de jeunes enfants qui œuvre dans un cadre d’objectifs à atteindre au travers d’un programme bien établi. 
En effet, la géométrie tortue ne correspond pas toujours à celle enseignée dans les écoles dans la mesure où la tortue se déplace comme le fait de manière naturelle – et dont il peut en prendre conscience - l’enfant qui la commande : partir d’où on est, prendre une direction et avancer dans celle-ci d’un certain nombre de pas (""jouer « tortue""). Ainsi en va-t-il, par exemple, de la famille des polygones réguliers et, plus précisément, du triangle.
Dans l’enseignement, les polygones convexes réguliers sont définis par des angles et des côtés égaux. En Logo, ils se construisent par la formule générale qui obéit au Théorème du Tour complet de la Tortue (TTT) en 360° :
En considérant que le polygone se dessine par la droite et où nbr est un nombre quelconque et N est le nombre d’angles et de côtés, compris entre 3 et l’infini (note : Si N = 1, on obtient un point et si N= 2, un segment de droite).
Or, le problème se pose pour le triangle dont on enseigne que la somme de ses angles est toujours égale à 180°. Ce qui n’est pas le cas en Logo puisque l’on fait tourner la tortue 3 fois à 120°.
En fait, dans son exploration de l’espace, le robot tortue contourne l’objet géométrique. Tout comme l’enfant qui la commande, parcourerait un triangle sur le sol, elle le dessine sans en avoir une connaissance (ou une définition) préétablie. En conséquence de quoi, ses rotations doivent se penser en termes d’angles supplémentaires et non d’angles "internes". En effet, la tortue s’arrêtant avant de tourner « regarde » devant elle, c’est-à-dire, dans le sens du segment de droite qu’elle vient de dessiner, puis tourne dans celui où elle va dessiner ensuite.
Ceci, comme d'autres aspects, ne va pas manquer d'être très déconcertant pour certains enseignants.
« "Est-ce Logo marche ? Nous constatons que oui, il marche à conditions de lui donner des jambes pédagogiques."".
Plus tard vont apparaître d’autres recherches dans un champ plus large que l’apport mathématique de Logo et, plus particulièrement, sur son apport possible dans l’enseignement en général.
Ici, l’optique, est, donc, claire :en quoi Logo peut aider l'enseignant dans la poursuite de ses objectifs :
« En éducation, l’informatique peut être d’abord considérée comme une technologie éducative, c’est-à-dire un ensemble de moyens pouvant faciliter l’enseignement et l’apprentissage des disciplines scolaires traditionnelles. »
Mais force est de constater que les phases expérimentales de ces recherches vont se révéler souvent bien courtes pour évaluer les effets à terme de son usage comme le regrette, par exemple, Valke qui, bien que n’observant pas de différences significatives entre son groupe expérimental et son groupe témoin, croit toutefois pouvoir déceler une tendance très claire : si la période de recherche avait été plus longue, un effet aurait pu apparaître .
Or, de leur côté, Verchaffen, De Corte et Schrooten font remarquer l’importance d’un quota minimum d’heures de pratiques qui devrait, effectivement, avoir un impact sur les aptitudes cognitives des élèves des écoles élémentaires.. mais à condition que cette pratique soit conduite dans un environnement didactique vigoureux et orienté. Il estiment ce quota à une cinquantaine d’heures .
Cette inquiétude de ne pas voir apparaître des résultats qui soient à la fois rapides et tangibles peut s’observer d’une autre manière comme chez Noss et Hoyles qui s’interrogent sur le plaisir d’utiliser REPETE ou le retour au mode pilotage, c’est-à-dire que l’élève ne prend pas appui sur le mode procédural pourtant déjà employé. Ils en tirent les conclusions qu’ils n’ont pas réfléchi sur les structures mathématiques et n’ont pas intégré la compréhension de l’outil .
Ce à quoi, Papert avait déjà répondu dans la préface de l’ouvrage précité de Hoyles et Noss, en soulignant que le plaisir de cette exploitation de cette commande magique par les enfants constitue, en fait, une approche de la récursivité. D’autre part, l’intérêt que constitue la commande REPETE n fois en tant qu’une approche intuitive de la multiplication ; même si elle n’est pas évidente de premier abord.
Somme toute, l’apport de ces recherches expérimentales ne peut se comprendre à la lumière de s’éclairer par l'aphorisme suivant : « "S’il faut neuf mois à une femme pour concevoir un enfant, suffit-il d’en réunir neuf pendant un mois pour arriver au même résultat ?" ».
Or, Papert inscrit l’apport de l’informatique (et de Logo) dans une perspective de changement culturel, c’est-à-dire à long terme. Mais, par ailleurs, il faut bien avouer combien est difficile de trouver les moyens pour mener une recherche sur si long terme. Ainsi, Biernaux va s'y atteler en suivant des enfants de 4 classes pendant 7 années mais ne pourra exploiter les observations obtenues faute de moyens, mais aussi par le désintérêt suscité par Logo après un aussi long laps de temps.
L’accompagnement : problème central de l’environnement Logo.
S’ils saluent sa relative simplicité et son caractère ludique qui rendent les premiers pas facile, Retschitzki et Gurtner insisteront plus tard sur le fait que Logo n'est ni aussi simple qu’il n’y paraît, ni véritablement limité dans ses possibilités. Par conséquent, pour que sa pratique soit profitable, un accompagnement est nécessaire mais il importe non seulement que celui-ci se fasse de manière continue mais surtout qu’il soit de qualité et, donc, opéré par des personnes disposant en la matière d’un sérieuse compétence. Observation plus que pertinente, mais qui reste à définir : par exemple, comment répondre à une équipe avec une pratique d’un heure par semaine pendant 6 ans qui demande à son enseignante comment écrire un programme en Logo qui compte le nombre de matchs à organiser pour un tournoi de ping-pong ? Que faire si une équipe de deux enfants de 6 ans, avec un an de logo dans les mêmes conditions, décide de construire une échelle centrée sur l’écran ?
À cet égard, il faut bien reconnaître que Papert reste sans doute par trop dans le vague à l’instar, d’ailleurs, de son maître à penser Piaget qui n’a jamais fourni (ou voulu fournir) d’indications claires en la matière (pour peu que cela soit possible). Mais, des travaux de l’un et de l’autre, on peut imaginer une pédagogie qui ne céderait ni au romantisme rousseauiste, ni à l’empirisme de l’éducation traditionnelle qui conçoit l’esprit de l’enfant comme entièrement – et exclusivement - formé par les interventions des adultes ou, éventuellement, d’enfants plus avancés. Mais, par contre, qui soulignerait l’importance d’un modèle d’éducation qui s’appuie sur l’activité constructrice et créative de l’enfant sans pour autant nier les rôles de la transmission culturelle et de l’interaction sociale.
Bref, il n’existe pas de recettes toutes faites en la matière.
C’est ainsi que pût s’observer aussi bien une large éventail de modalités d’accompagnement allant de la non-directivité complète aux manuels avec exercices préétablis de Christina Gaillard.
l'approche pédagogique ou scolaire.
Comme il fallait s’y attendre, à coup d’expérimentations contrôlées et de tests statistiques, les pédagogues se sont appliqués à proposer leurs recettes pour un bon usage de Logo, avec en vue l’optimisation de son efficacité dans un usage scolaire.
Par exemple, Tamara Lemerisie et d’autres vont proposer une classification hiérarchisée en fonction d’une efficacité croissante :
En conséquence de quoi, s'appuyant sur les études précitées, Olivier De Marcellus proposera une sorte de vade-mecum du bon animateur Logo :"
On est loin, très loin, des principes directeurs à la base du projet tel qu’énoncés par Papert (notamment sur le concept socio-cognitif) et, à la lecture de ce qui précède, on comprend mieux ses déclarations de 1997 citées en début de partie.
D’une manière plus générale, on est, en effet, frappé de l’absence d’autonomie laissée à l’enfant (devenu ici l’élève) dans la démarche ainsi que du gommage de l’aspect affectif dans son apprentissage, et, dès lors, on peut s’interroger sur les démarches ou concepts rééellement acquis. En vertu de quoi, il devenait légitime de se poser la question de l’utilité de Logo dans un tel contexte surtout eu égards aux coûts non négligeables tant en termes d’investissements personnels que matériels.
l'approche "facilitation".
Aux antipodes de ces démarches visant à « scolariser » Logo qui leur sont postérieures, les premiers usages de Logo étaient fortement teintés de cette non-directivité telle que décrite par Lemerise comme les « projets libres » où la passivité de l’accompagnateur est la règle. De fait, si l’attitude passive peut fonctionner lors de la découverte de Logo, durant la phase de « pilotage » de la tortue durant laquelle peut-être même est-elle souhaitable, elle montre vite ses limites. Mais celle-ci reflétait-elle bien la pensée de Papert et de Piaget ?
L’utilisation du terme « facilitateur » par Papert et, à sa suite, par Bossuet, semble avoir, en effet, induit chez certain l’idée d’une référence implicite à Carl Rogers qui n’est pourtant jamais cité par ces auteurs. Avant toute chose, il convient de rappeler que celui-ci, primo-auteur de la formule n’a, en définitive, jamais été non-directif. Lui-même est revenu d’ailleurs sur ce terme en lui préférant celui d’Approche Centrée sur la Personne. La non-directivité n’est pas le laisser-faire ou le laxisme comme aiment à le faire croire autant ses détracteurs que parfois ses apologistes.
Par ailleurs, Papert parle en réalité de « "facilitateur d’apprentissage" » Tant dans les videos disponibles que dans « Jaillissement de l’esprit », il ne se confine nullement dans une attitude passive où il se bornerait à attendre les demandes des enfants, mais intervient, suggérant ici une solution, soulignant là une situation qu’il estime exploitable : « "une situation riche" ». La question reste comment et quand intervenir à bon escient ?
Forte d’une expérience de sept années de faciltateur dans un atelier Logo inséré dans une école, Mirelle Daubresse considérera comme essentielle le respect de l’autonomie de l’apprentissage chez les enfants si l’on veut que leur intérêt reste constant et qu’ils puissent trouver dans leurs activités en Logo les matériaux dont ils ont, personnellement, besoin et/ou qu’il leur seraient utiles. 
De l’approche centrée sur la personne (en l’occurrence, l’enfant) de Rogers, elle retient que le rôle du facilitateur d’apprentissage est d’aider à choisir et à clarifier les projets des enfants de l’atelier, et de prendre en compte le désir de chacun de réaliser les projets, seul ou en équipe, qui ont une signification pour lui car c’est là que se niche la force motivante qui va soutenir un apprentissage significatif. Mais, dans le cadre spécifique de Logo, d’autres exigences sont requises : 
Quant aux principes d’intervention proprement dits, notamment en vue d’aider les enfants à franchir un pas de plus, elle considére qu’un principe doit toujours guider le facilitateur : garder constammant en-tête la notion d’équilibration développée par Piaget, selon laquelle, pour être efficace, le déséquilibre, ici provoqué, ne doit jamais être ni insuffisant, ni être excessif, et s’appuyer sur les acquis .
Quand on sait que cette formation, appuyée par des longs extraits video in situ et des analyse de projets réels s’adressait à de petits groupes sur 20 jours répartis sur une année, on mesure combien l’accompagnement en Logo implique d’engagement personnel. Y compris, d'ailleurs, dans son usage plus "scolaire".
Une tortue prétexte : le dimension affective.
Comme signalé plus haut, Papert insiste sur le rôle de l’affectivité dans l’apprentissage. Si cet aspect est bien présent dans la dernière approche décrite ci-dessus, il l’est beaucoup moins dans l’approche pédagogique qui semble l’avoir gommée dans ses expérimentations. Mais force est de reconnaître avec Piaget que les outils pour la valider ou simplement l’étudier n’existent pas en dehors d’une observation forcément individuelle et, donc, peu propice à une généralisation.
En annexe, on trouvera quelques exemples tirés d’expériences en atelier dans lesquelles les praticiens de Logo se retrouveront certainement. Ils peuvent apporter un éclairage sur les événements affectifs susceptibles d’exercer une influence sur les apprentissages tels qu’ils peuvent survenir dans un environnement Logo. Soulignons au passage que la tortue, cet animal emblème, même si son choix doit beaucoup au hasard, présente des caractéristiques relativement neutres d’un point de vue affectif : un animal sympathique mais sans plus. Pas vraiment à chouchouter.
A leur lecture, on ne peut que regretter l’absence de publications relatives à l’utilisation de Logo en matière de remédiation et, plus généralement, sur la manière dont les enfants se saisissent de Logo pour régler certains obstacles à leur apprentissage. Ni, en miroir, comment son usage permet de détecter ces derniers. Par exemple, plusieurs mémoires de fin d’études ont été rédigés sur ce sujet à l’Université de Lille 2 ou à l’Institut Marie Haps à Bruxelles selon lesquels de bons résultats avaient été obtenu en orthophonie/logopédie.
Or, d’une manière générale c’est, semble-t-il avec les enfants présentant des difficultés d’apprentissage que Logo et sa tortue se sont révélés particulièrement prometteur dans la mesure, entre autres, qu’il ne demandait qu’un investissement limité à un personnel aguerri en la matière.
Épilogue.
Logo a marqué le passage d’une conception de l’emploi de l’ordinateur dans l’enseignement reposant sur un usage tutorial vers sa maîtrise que l’on jugeait devenir indispensable. L’enjeu, à cette époque, n’était pas nécessairement de favoriser l’apprentissage comme le concevait Papert, mais celui d’une véritable acculturation passant par sa programmation : la question était déjà posée au début des années 70 de savoir combien de temps quelqu’un qui ne connaît rien à l’ordinateur pourra être considéré comme instruit.
Lorsqu’il apparaît dans le paysage informatique, une autre question commençait à se poser : est-ce que l’alternative se limite bien à ce seul choix ou n’existe-t-il pas une troisième voie : celle d’un outil.
En effet, à cette époque sortiront les premiers logiciels bureautiques comme, par exemple, sur l’Apple II, Visicalc (tableur), Visidex (Gestion de fiches), Visifile (base de données) ou Visi On (générateur de graphiques) développés par Visicorp, ou encore Apple Plot (générateur de graphiques) et Apple Pie (Traitement de texte).
Commentant son texte 30 ans plus tard, Luehrmann concédait que, dans la trichotomie exposée par Taylor, c’est seulement l’utilisation comme outil qui a eu véritablement un impact dans les écoles et, plus particulièrement, les tableurs .
Tout comme Papert, il concluait en regrettant le monopole de l’école sur l’éducation qui empêche les innovations. Prônant le développement des cours sur Internet, rejoignant ainsi le point de vue de plusieurs auteurs qui, pensant que les systèmes éducatifs actuels ne peuvent pas sérieusement intégrer les technologies informatiques, prévoient des changements très profonds des modes de scolarisation.
Mais, même s’il a joué un grand rôle, l’abandon de Logo ne doit pas seulement se comprendre au travers de son rejet par un monde pédagogique orienté sur l’enseignement plus que sur l’apprentissage et, en définitive plus soucieux de l’enseignant que de l’apprenant. L'essor de ce qu’on appelait alors les microordinateurs a d’abord profité à Logo mais celui-ci a souffert ensuite de leur succès et de l’accélération de l’innovation en la matière qui allait lui retirer plusieurs de ses principaux atouts :
En outre, il faut le rappeler, personne à l’époque n’avait vu venir l’Internet.
Papert a-t-il vraiment cru que Logo allait changer l’école ? Vraisemblablement pas, mais jusqu’à son accident de 2006 qui a mis fin à sa carrière de chercheur, il est resté convaincu, plus encore que d’autres, que l’informatique – et plus spécifiquement l’ordinateur personnel - allait modifier les conditions des apprentissages entraînant de manière inéluctable des changements dans l’enseignement et, par voie de conséquence, de l’école appelée, selon lui, à devenir obsolète à moyen terme. Dans cette perspective, il s’intéressera, notamment vers les conceptions de pédagogies actives de Montessori ou de Dewey.
En l'occurrence, Logo doit être considéré a posteriori comme un premier pas dans cette dynamique qui a bousculé le paradigme univoque de l’utilisation tutoriale de l’informatique. Pour Papert, il a été certainement l’occasion d’une mise en pratique de ce qu’il avait appris auprès de Piaget.
Extrait d'un entretien avec Papert :

</doc>
<doc id="8256" url="http://fr.wikipedia.org/wiki?curid=8256" title="Algol (langage)">
Algol (langage)

Algol est un langage de programmation. Il a été créé à la fin des années 1950. Dérivé d'un projet UNESCO d'abord appelé IAL (""), son nom est l'acronyme d' . Son objectif était de décrire algorithmiquement des problèmes de programmation. Les principales différences au niveau de la conception par rapport à Fortran furent l'utilisation de blocs marqués par BEGIN END, permettant variables locales et tableaux dynamiques, et surtout la récursivité, concepts qui seront largement repris par ses successeurs.
Le langage existe en trois versions : Algol 58, Algol 60 et Algol 68.
Historique.
Le premier rapport décrivant le langage date de 1958 et a donc donné lieu à Algol 58. Présentant des ambiguïtés sévères, il fut stabilisé sous le nom d'Algol 60, langage largement adopté dans les Universités, et qui fit faire des progrès importants à la compilation.
Ses trois principaux descendants sont :
Hormis un succès universitaire certain, Algol 60 sera peu utilisé dans des programmes commerciaux. Cela est dû au manque de fonctions standards d'entrée-sortie (corrigé en 1965 et surcorrigé dans Algol 68), et à une mauvaise adaptation aux programmes de gestion. Au plan scientifique, il était moins efficace que Fortran, tout en permettant des traitements a priori impossible dans ce langage.
Algol 60 a été publié en 1960. John Backus et Peter Naur faisaient partie du comité qui l'a créé. Algol 60 a inspiré beaucoup de langages. C. A. R. Hoare a déclaré à son sujet : « Voici un langage très en avance de son temps, il n'a pas seulement été une amélioration de ses prédécesseurs "mais aussi une amélioration de presque tous ses successeurs" ». Ce commentaire est parfois attribué faussement à Edsger Dijkstra, célèbre aussi pour ses commentaires humoristiques.
La suite de cet article est principalement consacrée au langage Algol 60. En effet, sans mention de millésime le terme Algol désigne le langage Algol 60, tandis que les Algols désigne l'ensemble de la famille.
Caractéristiques.
Algol 60 est un langage typé, procédural récursif et à structure de blocs. Il permet un emploi dynamique des types mais ne permet pas à l'utilisateur d'en définir de nouveaux. Algol 60 a été défini sans instructions d'entrées/sorties ; une implémentation sur une machine donnée en comportait nécessairement, mais elles variaient de l'une à l'autre. En réaction à cette situation, Algol 68 les a surspécifiées.
Algol 60 permet deux types de passage de paramètres lors de l'appel de procédure : passage par valeur et le passage par nom, proche de la macro-substitution. Le passage par nom possède des qualités mal comprises, du fait d'une confusion avec le passage par référence, plus répandu, aussi a-t-il été abandonné dans les successeurs d'Algol 60. Par exemple, on a reproché à ce mode Algol 60 l'impossibilité d'écrire une procédure échangeant deux valeurs si un des paramètres est un entier et l'autre un tableau indexé par ce même entier.
En réaction contre le manque de formalisme dans le projet Fortran, John Backus a conçu la BNF pour "Backus Normal Form" permettant la spécification de Algol 58. Cette méthode de description d'un langage a été révisée et étendue par Peter Naur sous le nom "Backus Naur Form" avec le même acronyme pour spécifier Algol 60, ainsi muni d'une grammaire indépendante du contexte.
Algol 68.
Algol 68 a été défini comme langage universel basé sur des types et des opérateurs prédéfinis, des procédés de construction de nouveaux types, et de nouveaux opérateurs avec possibilité de surcharge et d'extension des opérateurs prédéfinis, le tout permettant d'adapter le langage à chaque famille d'applications.
Comme une grammaire indépendante du contexte, telle que l'on peut définir avec BNF, s'avère une grammaire simple, que la rigueur demande de compléter par des restrictions sémantiques en langue naturelle, trop souvent ambiguës, l'équipe de Adriaan van Wijngaarden a retenu un système grammatical, dit (seconde forme) couvrant la syntaxe en rapport avec la sémantique. S'appuyant sur une hyper-grammaire (donnant des schémas de règles ou hyper-règles) interagissant avec une méta-grammaire (reflétant la théorie des types constructibles), le système grammatical produit une infinité de contraintes de BNF sémantiquement adéquates. Le Rapport Révisé a parfaitement illustré l'adéquation de ce dispositif, qui définit une syntaxe sémantiquement correcte. Cette approche totale facilite une compilation « carrée ».
Architectures supportant Algol.
Le B5000 de Burroughs Corporation et ses successeurs étaient des machines à pile conçues pour être programmées avec un Algol étendu ; leur systèmes d'exploitation est écrit dans cet Algol depuis 1961, ouvrant la voie à l'écriture des systèmes d'exploitation en langage symbolique, reprise par Multics puis Unix. Unisys Corporation continue de commercialiser des machines descendant du B5000 supportant plusieurs compilateurs Algol étendus.
Exemple de code (Algol 60).
Les programmes Algol 60 sont à format libre, avec le point-virgule comme séparateur principal. 
Les termes en caractère gras (procedure…) sont des mots réservés du langage. Chaque implémentation du langage peut utiliser sa propre convention lexicale (par exemple 'PROCEDURE').

</doc>
<doc id="122056" url="http://fr.wikipedia.org/wiki?curid=122056" title="Fortran 90">
Fortran 90

Fortran 90 est une version du langage de programmation Fortran, qui est très utilisé dans le domaine du calcul scientifique en raison du très grand nombre de programmes-source disponibles dans ce langage. Toutefois, ses utilisateurs ont voulu y ajouter au fil du temps les idées intéressantes utilisées dans d'autres langages. Cela a donné les versions Fortran 90, puis Fortran 95.
Le Fortran 90 introduisit dans FORTRAN les ajouts suivants :
"GNU Compiler Collection" (GCC) permet de compiler du Fortran 90 à partir de la version 4.0.

</doc>
<doc id="258048" url="http://fr.wikipedia.org/wiki?curid=258048" title="Groovy (langage)">
Groovy (langage)

Groovy est le nom d'un langage de programmation orienté objet destiné à la plate-forme Java. Il constitue une alternative au langage Java pour cette plate-forme et est inspiré de Python, Ruby et Smalltalk. Il est l'objet de la spécification JSR 241.
Groovy utilise une syntaxe très proche de Java, avec des accolades, et est directement compilé, soit à la volée dynamiquement, soit classiquement avec un compilateur en bytecode. 
Groovy s'intègre et est entièrement compatible avec la JVM étant donné que le bytecode est le même.
Il peut donc
Groovy peut être comparé à BeanShell, l'objectif de faire un langage de scripting proche de java est le même, la mise en œuvre étant différente.
Principales caractéristiques du langage.
Groovy possède certaines caractéristiques qui le différencient du Java standard :
Comparaison entre Java et Groovy.
Voici une comparaison de Java et Groovy :
Standard Java (Java 5+)
Groovy
Langage de balisage (XML, HTML…).
Une des caractéristiques notables de Groovy est sa gestion native des langages de balisage comme XML et HTML. Cette prise en charge permet de définir et manipuler par programmation plusieurs types de structures avec une syntaxe commune.
Exemple :
ce code Groovy… 
… produit le contenu XML suivant :

</doc>
<doc id="188377" url="http://fr.wikipedia.org/wiki?curid=188377" title="FASM">
FASM

FASM ("flat assembler") est un programme assembleur pour l'architecture IA-32 (appelée également architecture x86) . Le nom signifie "flat assembler". FASM est écrit en langage assembleur et existe pour les systèmes DOS, DexOS, GNU/Linux, Windows, et Menuet. FASM a quelques caractéristiques évoluées pour un langage assembleur tel que les macros, les structures, et les données virtuelles. FASM intègre des bibliothèques pour l'environnement graphique Windows et OpenGL.

</doc>
<doc id="7942" url="http://fr.wikipedia.org/wiki?curid=7942" title="Programme assembleur">
Programme assembleur

Un assembleur est un programme d'ordinateur qui traduit un programme écrit en langage assembleur — essentiellement, une représentation mnémonique du langage machine — en code objet.
En plus de traduire les mnémoniques d'instructions en code binaire, les assembleurs sont capables de gérer des noms symboliques pour les emplacements mémoire (pour stocker des données ou référencer des points du programme) et un langage macro pour effectuer des substitutions textuelles - typiquement utilisé pour coder des séquences courtes d'instructions fréquemment utilisées qui seront insérées dans le code plutôt que d'écrire des procédures.
Historiquement, les assembleurs sont apparus comme le premier outil permettant au programmeur de prendre du recul par rapport au code objet et de se consacrer à la programmation proprement dite.
Les programmes assembleurs sont plus simples à écrire que les compilateurs pour les langages de haut-niveau. Ils sont disponibles depuis les années 1950.
Les programmes assembleur donnent un accès plus direct au microprocesseur que l'on souhaite programmer. Toutefois les architectures RISC comme le PowerPC, le MIPS, SPARC et HP Precision demandent pour optimiser leur fonctionnement des réarrangements d'instructions difficilement compatibles avec l'usage lisible de l'assembleur. Le recours à un compilateur devient alors inévitable pour tirer le maximum de l'architecture sous-jacente, en particulier les pipelines dont disposent les processeurs RISC.

</doc>
<doc id="122053" url="http://fr.wikipedia.org/wiki?curid=122053" title="Fortran 95">
Fortran 95

Fortran 95 est une version du langage de programmation Fortran, qui est très utilisé dans le domaine du calcul scientifique en raison du très grand nombre de programmes-source disponibles dans ce langage. Toutefois, ses utilisateurs ont voulu y ajouter au fil du temps les idées intéressantes utilisées dans d'autres langages. Cela a donné les versions Fortran 90, puis Fortran 95.
Fortran 95 reprend les extensions déjà définies dans Fortran 90 et y ajoute :
Les rapports ISO définissant le Fortran 95 sont le TR 15580 et le TR 15581

</doc>
<doc id="125676" url="http://fr.wikipedia.org/wiki?curid=125676" title="Lingo">
Lingo

Lingo est le langage de script qui accompagne le logiciel Macromedia Director. 
L'auteur du Lingo est le développeur John Henry Thompson. La lingo a été enrichi par de nombreuses sociétés ayant développé des xtras, dont intel, ageia, havok...
Origine du nom.
Le mot Lingo signifie en anglais argot, au sens de "langage vernaculaire", langue spécialisée appartenant à un groupe précis (ex. l'argot des typographes).
Contrairement aux langages de niveau 4 les plus répandus (basic, javascript...), le script lingo ne reproduit pas les concepts de la programmation à l'identique mais les remanie à sa façon en vue d'une application efficace et simple. Afin de marquer la distinction il utilise des termes différents, par exemple le "tableau" est renommé "list", une classe est appelée "parent script"...
Caractéristiques du langage.
Lingo utilise actuellement la syntaxe Basic.
Lingo avait au départ une syntaxe verbose dérivé du langage HyperTalk utilisé dans le logiciel auteur HyperCard distribué sur les MacIntosh à partir de 1986. Il a été prévu au départ pour être le plus lisible possible pour les anglophones.
Syntaxe.
Voici un exemple de fonction :
Les fonctions commencent en effet toutes par on de fonction[(arguments)] et se terminent par end de fonction. Lingo est un langage très laxiste, on est par exemple autorisé à ne pas mettre les parenthèses après le nom de la fonction (on multiplie a, b).
À noter, les variables sont typées dynamiquement et il n'existe pas de différenciation entre le "=" d'affectation et le "=" de comparaison.
Après des années d'évolution syntaxique, Lingo est devenu un langage "pointé" assez classique, et donc très lisible.
Director est un logiciel dédié à l'interactivité. Par conséquent, Lingo permet l'interception facile d'un grand nombre d'évènements tels que : preparemovie (avant l'affichage), startmovie (au moment de l'affichage), mousedown (clic enfoncé), mouseup (clic relâché), etc. Certains scripts intercepteurs évènements concernent l'ensemble du programme, d'autres peuvent ne s'appliquer qu'à des objets précis, comme les "sprites" (occurrence d'un objet - par exemple graphique - sur la "scène").
Variables.
Les variables numériques en lingo sont simplifiées. Les variables globales ou d'objet ne se déclarent qu'en dehors des fonctions. Les variables locales sont déclarées implicitement.
Le typage est implicite, ainsi:
Il n'existe pas de variables booléennes, lingo utilise les entiers 0 et 1, qui pour des raisons de lisibilité peuvent toutefois s'écrire true et false.
Les chaînes de caractères peuvent être lus comme des tableaux à l'aide de la variable globale "the itemDelimiter" et la prioriété .item des strings, ou bien les propriétés .line et .word des string.
les noms des variables peuvent contenir des lettres, des chiffres, ou le signe underscore. Elles ne peuvent pas commencer par un chiffre.
Symboles.
On peut créer des "symboles" avec le signe dièse (#). Un symbole n'est pas une variable mais un nom de variable ou fonction.
Par exemple, dans "maCouleur = #rouge", le mot "#rouge" ne signifie rien pour Lingo ; en revanche, maCouleur = couleurs[#rouge] permet de retrouver la propriété rouge de l'objet couleurs, la fonction call(#rouge, obj, arguments...) permet d'appeler la méthode rouge de l'objet obj.
Classes de base.
Lingo possède une liste de classe correspondant aux structures de données classiques, avec d'importantes automatisations.
Classes de gestion des tableaux.
Classe List.
La classe list contient un tableau à mémoire dynamique. Ces tableaux sont "one-based", le premier index est égal à 1. Cela permet d'utiliser le zéro comme identifiant nul lorsque l'on référence les indexes.
Y écrire ou y lire le contenu d'une cellule est une opération aussi lourde que la syntaxe pointée (plus lente sur des grosses listes que des petites). Pour optimiser les opérations sur les tableaux il faut utiliser le plus possible l'algèbre des tableaux, qui évite de nombreuses lectures de cellule.
Les listes se créent ainsi :
Les tableaux peuvent contenir n'importe quel types de données:
Algèbre des tableaux.
Les tableaux peuvent utiliser tous les types d'opérateurs compatibles avec le contenu des cellules. Cela permet une considérable accélération des boucles de calcul puisque celles-ci sont alors gérées en natif.
Exemples avec les entier et les décimaux:
Pour les exemples avec des tableaux de vecteurs et matrices, voir les classes vector et transform.
Classe propList.
Contient un tableau associatif. Les identifiants peuvent être soit:
L'algèbre est identique à celui des listes linéaires.
Classe matrix.
Encode un tableau à deux dimensions. Ajouté à la v11 pour les terrains du moteur physx.
Classes de géométrie 2d.
Classe point.
Encode un vecteur 2d. Ses coordonnées se nomment "locH" et "locV". Elles peuvent être entières ou décimales.
Les données se lisent par les propriétés locV / locH ou comme un tableau:
L'algèbre des vecteurs 2d se comporte exactement comme l'algèbre des tableaux et peut se combiner avec:
Classe rect.
Encode un rectangle. Les valeurs peuvent être entières ou décimales.
Quelques méthodes:
L'algèbre des rectangles est identique à celui des points 2d.
Classe quad.
Encode un quadrilatère. Utile surtout pour les manipulations d'images.
Classes de géométrie 3d.
Classe vector.
Encode un vecteur 3d. Nombres décimaux uniquement.
Ses coordonnées sont accessibles de deux manières: soit avec les propriétés x, y, z, soit avec l'index de dimension:
Quelques méthodes:
L'algèbre des vecteurs 3d diffère de celle des listes et des vecteurs 2d:
L'algèbre des vecteurs peut se combiner avec celui des tableaux.
Classe transform.
Encode une matrice de transformation 3d composée de 16 décimales.
Les 3 premiers groupes de 4 nombres encodent les 3 vecteurs du repère. Le dernier groupe encode l'origine. (le nombre de ces groupes sert aux calculs internes).
Exemple: choisir le vecteur (0,0,1) pour l'axe X:
Quelques méthodes:
Algèbre des matrices:
L'algèbre des matrices se combine également avec les tableaux:
Classes du moteur 3d.
Classe Scene.
Sous-classe de "member" qui s'affiche comme un sprite et permet de rendre une scene 3d avec directx ou opengl
Suit un pattern de type "fabrique": tous les éléments de la scene 3d sont instanciés et détruits à l'aide de méthodes de la classe scene. En voici quelques-uns:
Classe modelresource.
Stocke des vertexbuffers ("meshes") et référence des shaders par défaut.
Note: ses méthodes de construction ne suivent pas la structure des vertexbuffer, chaque triangle est renseigné indépendamment. Une fois appelée la méthode build() les vecteurs sont triés par groupe utilisant le même shader, les vertexBuffer obtenus sont accessibles via le modificateur #meshDeform des models utilisant la ressource.
Classe model.
Référence une matrice, une liste de shaders et un modelresource. Génère automatiquement une boundingSphere. La classe model permet d'afficher le modelResource. Son modificateur #meshDeform permet d'accéder aux vertexBuffer du modelResource.
Classe physx.
Permet de contrôler une scene 3d avec le moteur physx de nvidia. Sous-classe d'xtra member, se contrôle comme un script xtra classique.
Suit le pattern fabrique qui permet de créer divers objets physiques: corps convexe, concave, cloth, personnage, etc. Requiert le modificateur #meshDeform pour lire les structures polygonales.
Types de scripts.
Il existe 4 types de scripts en Lingo, deux de type procédural, deux de type objet:
Les scripts procéduraux.
Utilisent uniquement des variables et fonctions globales. Leur utilisation doit rester limitée car les variables globales sont consommatrices de cpu et ram: elles sont dupliquées dans l'interprétateur javascript.
On utilise autant que possible les script objets, les script procéduraux uniquement quand c'est nécessaire.
"movie script".
Ce sont les scripts utilisés pour le code procédural.
Ces scripts reçoivent quelques fonctions-événements prédéfinis qui correspondent à l'ouverture de l'application, sa fermeture, le rafraichissement d'image.
Evenements d'ouverture et clôture:
Evenements de rafraichissement d'image:
Evenement indépendant:
Evenements souris:
Les scripts dits d'acteur.
Ce sont des scripts qui se trouvent directement à l'intérieur d'un acteur. Leur type n'est pas défini mais ils fonctionnent comme les "movie script".
Ils reçoivent les évènements de souris et de rafraichissement lorsqu'une instance de l'acteur est visible.
Les scripts objet.
Les scripts dits "parents".
Permettent de simuler des classes d'objet. La syntaxe des méthodes reste procédurale : il faut faire passer une référence à l'objet "me" en premier argument.
classe instanciable.
Si ce script se nomme "nombre", on l'instanciera par exemple de cette manière :
et on invoquera sa fonction "incremente" de cette manière :
classe statique.
Un script parent peut servir de classe statique.
On accède à sa référence comme ceci:
héritage.
L'héritage en lingo ne fonctionne pas comme dans les langages objet classiques, il se base sur la propriété "ancestor" des scripts parents, qui correspond à une instance de la classe-mère. Il ne s'agit donc pas d'héritage mais d'une surcharge.
Director remonte automatiquement aux propriétés de l'objet ancestor depuis la référence fille ce qui permet de retrouver l'effet d'une classe héritée. Attention donc à la valeur de l'argument "me": il doit toujours correspondre à l'instance de dernière génération.
Cela ne marche pas pour toutes les propriétés et méthodes des classes natives de director (auquel cas il faut pointer l'ancestor).
Les scripts d'application ou "behaviors".
Ce sont des objets complexes dont le script n'est pas directement accessible. Ils contiennent de nombreux événements permettant d'interagir avec les sprites, la souris, le clavier, par exemple pour créer des boutons ou des éditeurs de texte.
Les scripts de comportement sont souvent développés pour être réutilisés par des graphistes ou intégrateurs. Par un simple drag and drop ces scripts se rattachent à des objets de la scène: image, sprite, acteur, frame... Ces scripts ont des fonctions prédéfinies qui permettent de paramétrer manuellement les instances de même que les composants flash.
Implémentations.
Le Lingo est un langage propriétaire, il n'en existe donc qu'une seule implémentation.
Commandes lingo et syntaxe javascript.
Depuis sa version MX2004, le logiciel Director accepte l'usage de deux langages différents : le Lingo, et une implémentation de JavaScript/ECMAScript qui exécute une grosse partie des opérations lingo.

</doc>
<doc id="2359" url="http://fr.wikipedia.org/wiki?curid=2359" title="PowerBuilder">
PowerBuilder

Powerbuilder est un langage de programmation et un environnement de développement intégré initialement développé par la société PowerSoft, qui a été rachetée par Sybase en 1994, SAP a ensuite racheté Sybase en 2010.
C'est un langage semi-compilé, orienté objet, générant du C++ utilisé principalement pour des applications de gestion. Il est disponible sous Windows.
Le principe central de Powerbuilder est la standardisation du dialogue avec les bases de données à l'aide de datawindows et la possibilité d'utiliser du langage SQL directement dans le langage PowerScript.
Datawindow.
Une datawindow est un composant logiciel qui présente dans une fenêtre les données issues d'une base de données SQL. Ce composant gère automatiquement l'affichage, la création, la modification et la suppression de données dans la table concernée. Ses formes de présentation diverses lui permettent d'être utilisée en liste, en forme libre, en rapport, etc.
Obtenir de l'aide.
Il existe plusieurs moyens d'obtenir de l'aide. Forums NNTP (anglais uniquement) ou web. Deux forums en français coexistent.
Tests unitaires.
Il est possible de faire des tests unitaires sur les projets PowerBuilder à l'aide de PBUnit.
Automatisation.
OrcaScript permet d'automatiser la build d'une application PowerBuilder sans utiliser l'environnement graphique. OrcaScript peut aussi se connecter à un source control pour effectuer un "getLatestVersion". 
Communauté.
PowerBuilder est connu pour sa base de clients loyaux, et son développement facile.
Par conséquent, il y a une variété de groupes de communauté et de ressources pour les développeurs PowerBuilder souhaitant partager leurs techniques et s'assembler. Ceux-ci incluent :
- International Sybase User Group
- PowerBuilder Developer's Journal. 
Il existe aussi les blogs de TeamSybase. 
PowerBuilderTV est une série des webinars par et pour la communauté PowerBuilder, avec sessions présentés par les évangélistes, développeurs et éditeurs PowerBuilder.

</doc>
<doc id="2153" url="http://fr.wikipedia.org/wiki?curid=2153" title="Natural">
Natural

Natural est un langage de programmation de quatrième génération semi-compilé, édité par la société allemande Software AG. 
Définition.
Sa syntaxe est fortement inspirée de celle de Cobol : on y retrouve des instructions telles que "move", "perform", "compute", ainsi que des principes tels que la redéfinition de données ou la possibilité de définir le scope d'une variable. Néanmoins, cette syntaxe reste assez simple et beaucoup moins verbeuse que Cobol :
L'intérêt d'un langage semi-compilé est sa portabilité sur différents systèmes (mainframe, Unix, Windows, etc.) ; en effet il suffit de porter le « RunTime Natural » sur une plateforme pour pouvoir y exécuter des programmes Natural originellement créés sur une autre plateforme (c'est le même principe que celui de Java avec les portages des JVM.
Ce langage fut créé au départ pour permettre l'accès aux bases de données Adabas (du même éditeur). Il s'est rapidement enrichi pour pouvoir supporter des bases de données relationnelles comme DB2 ou non relationnelles comme DL1, VSAM.
Il est surtout utilisé dans l'industrie et les sociétés de grande taille, car la base Adabas est supportée non seulement sur des plateformes comme Unix ou Windows mais surtout sur de gros systèmes autorisant une gestion d'I/O massive.
Les instructions d'accès au système de gestion de base de données (SGBD) sont fonctionnelles (elles masquent les requêtes physiques et l'organisation des données) : chaque instruction d'accès à une table de la base se présente sous forme d'une boucle de lecture suivant une clé simple ou composée. 
Par exemple, la lecture se présente sous la forme de deux mots-clefs.
Le langage dispose d'extension permettant également le codage des accès sous forme de requêtes SQL.
Évolutions.
Natural 2006 dispose d'un vocabulaire étendu pour traiter de façon native les documents XML.
Natural reste, comme Cobol, fortement orienté vers les applications de gestion, du fait:

</doc>
<doc id="289964" url="http://fr.wikipedia.org/wiki?curid=289964" title="PhBRML">
PhBRML

PhBRML () est une extension du langage VRML 2.0.

</doc>
<doc id="175120" url="http://fr.wikipedia.org/wiki?curid=175120" title="Booch">
Booch

La méthode Booch est, avec OMT et OOSE, l'une des méthodes d'analyse et de conception orientées objet à l'origine d'UML. Son nom vient de celui de son concepteur, Grady Booch, qui sera aussi l'un des pères du langage UML (avec Ivar Jacobson, fondateur de la méthode OOSE et James Rumbaugh, fondateur de la méthode OMT).
Cette méthode permet de faciliter l'implémentation de programmes dans des langages de programmation orientée objet, ainsi que de représenter les différentes phases du développement d'un projet. Pour les programmeurs, l'avantage est d'obtenir une modélisation d'une solution qui soit indépendante de son implémentation dans un langage particulier (par exemple Java, C++, PHP...).
Ses concepts fondamentaux sont l'objet, la classe, la méthode et l'attribut.

</doc>
<doc id="257305" url="http://fr.wikipedia.org/wiki?curid=257305" title="Airelle (langage)">
Airelle (langage)

Airelle est un langage de programmation objet écrit au-dessus du langage Lisp.

</doc>
<doc id="27" url="http://fr.wikipedia.org/wiki?curid=27" title="Ada (langage)">
Ada (langage)

Ada est un langage de programmation orienté objet dont les premières versions remontent au début des années 1980.
Présentation.
Ada est un langage de programmation conçu par l’équipe de CII-Honeywell Bull dirigée par Jean Ichbiah en réponse à un cahier des charges établi par le département de la Défense des États-Unis (DoD). Son développement a commencé au début des années 1980 pour donner Ada 83. Pour cela, l'équipe de Jean Ichbiah s'est inspirée de son précédent langage LIS (Langage d'Implémentation de Systèmes), conçu à la CII pour permettre le développement de systèmes d'exploitation portables (à 95 %, disait Ichbiah).
Ada 83 a été ensuite repris et amélioré au milieu des années 1990 pour donner Ada 95, le second langage objet normalisé de manière internationale (publié en février 1995, il est précédé de peu par Common Lisp, publié en décembre 1994). Sous les auspices de l’Organisation internationale de normalisation (ISO), le langage a bénéficié d'un amendement (Ada 2005) puis d'une nouvelle révision appelée Ada 2012.
Le nom "Ada" a été choisi en l’honneur d’Ada Lovelace, sans doute la première informaticienne de l’histoire. Il est associé à la couleur verte car, lors de l’appel d’offre du DoD, les différentes propositions étaient désignées par des couleurs pour éviter tout biais, et l’équipe qui l’a conçu était l’équipe verte.
Voici quelques particularités d’Ada :
Il est souvent utilisé dans des systèmes temps réel et embarqués nécessitant un haut niveau de fiabilité et de sécurité. De nos jours, Ada95 est employé bien sûr par son initiateur, mais aussi dans toutes les technologies de pointe ; en France, l’automobile, les transports ferroviaires (ALSTOM, Siemens Transportation Systems, ANSALDO STS) (TGV, Corail, RER, METEOR), les technologies aéronautiques (Thales Air Systems, Thales Avionics, Airbus, EADS Défense et sécurité) et les technologies spatiales (Thales Alenia Space, EADS Astrium, CNES, Arianespace).
En 2013, il est possible de trouver des compilateurs Ada pour certains systèmes d’exploitation (Windows, Linux, VxWorks) et architectures matérielles, y compris un compilateur libre (GNAT, inclus dans "GNU Compiler Collection") compilant de l’Ada 83/95/2005/2012.
Ada est parfois utilisé en introduction aux cours de programmation informatique avancée, et il peut être utilisé pour les cours d'introduction à la programmation.
Autres langages dans la mouvance Ada.
Ada est inspiré du Pascal dont il a repris tant l'esprit de la syntaxe que de l'architecture. Le langage Ada a inspiré Bertrand Meyer pour la conception du langage Eiffel, qui y ajoute des notions de programmation par contrat (mais se montre moins adapté à l'industrie sous certains aspects). La notion de programmation par contrat, formalisée par Bertrand Meyer avec Eiffel, a amené la création d'une extension au langage Ada, , pour lui faire supporter des notations permettant d'exprimer des assertions contractuelles dans les spécifications.
Dans le domaine des bases de données, Ada a inspiré le langage PL/SQL.
Le langage Ada est également à la base de la conception des différents langages de la norme IEC 61131-3, en particulier la partie déclarative commune à tous les langages et le langage ST (Texte structuré).
"Hello, world!" en Ada 95 ou Ada 2005.
Un exemple courant pour montrer la syntaxe d’un langage est le programme Hello world :
Il existe des raccourcis pour Ada.Text_IO.Put_Line nécessitant moins de caractères, mais ils ne sont pas utilisés ici pour des raisons de compréhension. Pour des explications plus détaillées, vous pouvez consulter .

</doc>
<doc id="13417" url="http://fr.wikipedia.org/wiki?curid=13417" title="Awk">
Awk

awk — dont le nom vient des trois créateurs, Alfred Aho, Peter Weinberger et Brian Kernighan — est un langage de traitement de lignes, disponible sur la plupart des systèmes Unix et sous Windows avec Cygwin ou Gawk. Il est principalement utilisé pour la manipulation de fichiers textuels pour des opérations de recherches, de remplacement et de transformations complexes.
Présentation.
Awk est le plus souvent utilisé pour la production de fichiers plats aux spécifications particulières (échanges entre différents systèmes d'informations hétérogènes). Il est aussi utilisé comme "parser" de fichiers XML ou de fichiers textes pour générer des commandes SQL à partir des données extraites. Il peut être utilisé aussi pour des opérations de calculs complexes et mise en forme de données brutes pour faire des tableaux statistiques.
On distingue awk, la commande originale, du "new awk" (nawk), arrivée un peu plus tard sur le marché. 
Les implémentations GNU de awk, sont en fait des "new awk". On trouve en général la commande awk dans /usr/bin sous Unix. Certains systèmes GNU/Linux le mettent dans /bin. En général, elle est dans la variable d'environnement PATH. Cependant, on peut faire des scripts en awk et le shebang (#!/usr/bin/awk -f) devient faux. Le script est donc inutilisable si le binaire n’est pas là où on l’attend.
Il agit comme un filtre programmable prenant une série de lignes en entrée (sous forme de fichiers ou directement via l'entrée standard) et écrivant sur la sortie standard, qui peut être redirigée vers un autre fichier ou programme. Un programme Awk est composé de trois blocs distincts utilisables ou non pour le traitement d'un fichier (prétraitement, traitement, posttraitement). Awk lit sur l'entrée ligne par ligne, puis sélectionne (ou non) les lignes à traiter par des expressions rationnelles (et éventuellement des numéros de lignes). Une fois la ligne sélectionnée, elle est découpée en champs selon un séparateur d'entrée indiqué dans le programme awk par le symbole FS (qui par défaut correspond au caractère espace ou tabulation). Puis les différents champs sont disponibles dans des variables : $1 (premier champ), $2 (deuxième champ), $3 (troisième champ), ..., $NF (dernier champ).
« awk » est aussi l'extension de nom de fichier utilisée pour les scripts écrits dans ce langage (rarement utilisée).
La syntaxe est inspirée du C :
codice_1
où la structure du programme est :
codice_2
Chaque ligne du fichier est comparée successivement aux différents motifs (le plus souvent des expressions rationnelles, et globalement une expression booléenne) et l'action du premier motif renvoyant la valeur vraie est exécutée. Dans ce cas, ou si aucun motif n'est accepté, le programme lit la ligne suivante du fichier et la compare aux motifs en partant du premier.
Quelques options : 
Description technique.
Un fichier est divisé en lignes ("records" en anglais) elles-mêmes divisées en champs ("fields" en anglais)
Les séparateurs d'entrée-sortie sont stockés dans des variables et peuvent être modifiés : 
Pour retourner le n champ :
Deux masques spéciaux : 
Pour définir un intervalle, on utilise la virgule comme ceci : 
Plusieurs fonctions sont déjà implémentées : 
Structures de contrôles : la syntaxe provient directement du C : 
Par rapport au C il y a quelques extensions :
Implémentation.
Il existe divers programmes qui utilisent la syntaxe du awk original, voici les plus connus :

</doc>
<doc id="43109" url="http://fr.wikipedia.org/wiki?curid=43109" title="B (langage)">
B (langage)

Le langage de programmation B est un langage depuis longtemps obsolète qui a représenté la transition entre BCPL et le langage C. C'est principalement l'œuvre de Ken Thompson et il apparut pour la première fois en 1969 environ.
Description.
C'était en fait le BCPL privé de tout ce que Thompson pensait ne pas être essentiel, afin de pouvoir être utilisé sur de petits ordinateurs et avec quelques changements pour correspondre aux goûts de Thompson (principalement réduire le nombre de caractères dans un programme).
Comme le BCPL et le Forth, le B avait un seul type de donnée, le « mot » ("word") d'ordinateur. La plupart des opérateurs (+, -, *, /) le considéraient comme un entier ("integer") mais d'autres comme une adresse mémoire. Sur d'autres points, il pourrait se faire passer pour une ancienne version du C. Quelques bibliothèques de fonctions existaient, dont certaines ressemblaient vaguement aux fonctions d'entrée-sortie de la bibliothèque standard du C.
Historique.
Les premières implémentations étaient pour les mini-ordinateurs de DEC, PDP-7 et PDP-11 et ont été développées en même temps que UNIX.
Le langage B a été implémenté sur les ordinateurs de la série Honeywell 6000 et leurs successeurs ("mainframes") par une équipe de l'université de Waterloo, dans l'Ontario, au Canada, afin de pouvoir écrire pour le "time-sharing" de ces machines un succédané des commandes "UNIX" baptisé "UW-Tools". Le compilateur B et les "UW-Tools" étaient distribués gratuitement en France par Bull, jusque vers l'année 2000. 
D'après Ken Thompson, le B a été grandement influencé par BCPL, mais le nom B lui-même n'a rien à voir : c'était en fait une évolution d'un ancien langage, "Bon", du nom de l'épouse de Ken Thompson, prénommée Bonnie.

</doc>
<doc id="100757" url="http://fr.wikipedia.org/wiki?curid=100757" title="Erlang (langage)">
Erlang (langage)

Erlang est un langage de programmation, supportant plusieurs paradigmes : concurrent, temps réel, distribué. Son cœur séquentiel est un langage fonctionnel à évaluation stricte, affectation unique, au typage dynamique fort. Sa couche concurrente est fondée sur le modèle d'acteur. Il possède des fonctionnalités de tolérance aux pannes et de mise à jour du code à chaud, permettant le développement d'applications à très haute disponibilité.
Il a été créé par Ericsson, qui l'utilise dans plusieurs de ses produits, tel que le commutateur ATM AXD 301. Initialement propriétaire, il est publié sous licence Open Source en 1998. Il est également utilisé par d'autres entreprises développant des logiciels liés aux réseaux de télécommunications, comme T-Mobile et Nortel.
Il est aussi utilisé pour écrire le serveur XMPP ejabberd, le serveur HTTP Yaws ainsi que le logiciel de modélisation 3D Wings 3D. Il possède de nombreuses bibliothèques incluses dans la distribution de base et regroupées sous le nom de "OTP (Open Telecom Platform)". OTP représente le framework standard de l'univers Erlang, la plupart des programmeurs l'utilisant comme base d'interopérabilité. Il peut s'interfacer avec d'autres langages comme Java ou C++.
« Erlang » fait référence au mathématicien Agner Erlang, tout en étant la contraction d'"Ericsson Language".
Exemples.
Comme tous les langages fonctionnels, Erlang repose beaucoup sur la récursivité.
En Erlang, la fonction factorielle peut s'écrire sous une forme récursive, comme suit : 
où codice_1 est le cas de base, et codice_2 le cœur récursif.
Une version utilisant la récursion terminale, avec un accumulateur :
L'algorithme de tri Quicksort avec une implémentation également récursive peut s'écrire sous cette forme en Erlang (de nombreuses variantes existent) :
Le code fait des appels récursifs à la fonction codice_3 jusqu'à ce que l'ensemble soit trié. L'expression codice_4 peut se traduire par « Choisir l'ensemble des codice_5 tels que codice_5 est un membre de codice_7 et codice_5 est inférieur à codice_9 ». L'opérateur codice_10 est celui de la concaténation entre les listes.
Fonctionnalités notables.
Le partage de données par passage de message.
Contrairement aux processus légers (threads) dans des langages classiques tels Java ou C, les processus Erlang ne partagent pas de mémoire pour communiquer ce qui permet d'éviter les problèmes liés à la synchronisation. La transmission d'informations se fait uniquement par passage de messages. La primitive qui permet l'envoi d'un message est "send", exprimée par codice_11.
La syntaxe est la suivante :
dans lequel codice_12 est l'identité du processus destinataire et codice_13 une expression quelconque.
À la différence d'autres langages concurrents comme Ada, l'envoi et la réception d'un message sont asynchrones en Erlang. Du point de vue de l'émetteur, l'envoi est instantané quel que soit l'état du destinataire. Le message est simplement remis dans la boîte aux lettres de ce dernier qui pourra le consommer au moment voulu. Cette propriété permet de découpler temporellement l'émetteur du receveur et ainsi de maximiser le niveau de concurrence dans le système tout en restant tolérant à la latence introduite par la communication dans un système distribué.
Gestion explicite du temps.
Du fait de ses origines comme outil logiciel de télécommunications, Erlang permet la définition de contraintes de temps réel souple "(soft real time)", c'est-à-dire l'exécution d'une action à l'intérieur d'un temps déterminé. Erlang incorpore la gestion du temps dans la primitive de réception de message "receive", dont la syntaxe est la suivante:
Le processus qui exécute le code ci-dessus attendra au plus, la valeur de l'expression codice_14. Si aucun message correspondant à codice_15 ou codice_16 n'est reçu par le processus d'ici là, il exécute alors l'action codice_17.
La programmation distribuée à base de nœud et de processus.
Les processus Erlang s'exécutent dans une machine virtuelle. Plusieurs machines virtuelles possiblement situées sur différents ordinateurs peuvent être connectées entre elles et former les nœuds d'un système distribué. La communication entre processus localisés sur des nœuds différents utilise les mêmes primitives et possède la même sémantique que pour la communication entre processus du même nœud. Du point de vue du programmeur, la localisation d'un processus est transparente.
Les connexions entre nœuds sont dynamiques. Un nœud peut joindre et quitter le système (ou en être isolé par une panne) à n'importe quel moment. Cette caractéristique autorise la tolérance aux pannes par redondance et la montée en charge d'une application par ajout de nouveaux nœuds.
La richesse de l'environnement.
Bâties sur le langage, les bibliothèques "Open Telecom Platform (OTP)" offrent des fonctionnalités de distribution des traitements et de supervision des nœuds avancées, ainsi qu'une base de données répartie. L'accent est mis sur la tolérance aux pannes puisque le couple Erlang/OTP permet entre autres de :

</doc>
<doc id="1105" url="http://fr.wikipedia.org/wiki?curid=1105" title="Fortran">
Fortran

Fortran (FORmula TRANslator) est un langage de programmation utilisé principalement en calcul scientifique.
Historique.
John Backus, pionnier de l'informatique, publie en 1954 un article titré "Preliminary Report, Specifications for the IBM Mathematical FORmula TRANslating System, FORTRAN." Il faut ensuite deux ans d'efforts à l'équipe qu'il dirige au sein d'IBM pour écrire le premier compilateur FORTRAN ( lignes, pour l'IBM 704).
Le nom du langage a été écrit conventionnellement en majuscules (FORTRAN) jusqu'en 1992 et l'introduction du Fortran 90 à syntaxe libre. En FORTRAN 77, les lettres minuscules ne font pas partie du langage. Cette convention se retrouve dans cet article et est conforme aux différentes normes du Fortran, de 1966 à aujourd'hui.
Aujourd'hui encore (années 2010), le langage Fortran reste très utilisé pour plusieurs raisons :
Toutefois, beaucoup de programmes scientifiques sont à présent écrits en C et C++, dont les compilateurs sont disponibles sur la plupart des machines. D'autres langages compilés sont parfois utilisés pour le calcul scientifique, et surtout des logiciels tels que Scilab ou Matlab. Ces derniers incorporent d'ailleurs les bilbiothèques BLAS et LAPACK, développées en Fortran. Matlab était d'ailleurs à l'origine un programme en Fortran, distribué aux universités et aux centres de recherche.
Le FORTRAN, créé à l'époque des cartes perforées (en particulier avec le système FMS), optimise la mise en page de ses sources dans cette optique, jusqu'au Fortran 90 qui introduit une syntaxe « libre ». Avant Fortran 90, le code commence à partir de la 7 colonne et ne doit pas dépasser la 72. Il se présente alors ainsi :
Il faut également noter qu'avant Fortran 90, les espaces n'ont pas de signification entre la 7 et la 72 colonne. Ainsi, la boucle « DO I=1,5 » peut aussi s'écrire « DOI=1,5 ». En revanche, « DO I=1.5 » est équivalent à « DOI=1.5 », une affectation.
De nombreux codes industriels ont été écrits en Fortran et la compatibilité des nouvelles versions avec les précédentes est indispensable, au prix de conserver des notions qui ne s'imposent plus. Pour cette raison, Fortran 90 est complètement compatible avec FORTRAN 77. Les versions suivantes du standard ont cependant introduit des incompatibilités.
Le langage BASIC, dans sa version originale (1964), a été conçu comme un petit langage à caractère pédagogique permettant d'initier les étudiants à la programmation, avant de passer aux langages « sérieux » de l'époque : FORTRAN et Algol. On y retrouve donc quelques traits du langage Fortran.
Compilateurs.
Le compilateur libre GCC permet de compiler le Fortran 77 (compilateur g77, jusqu'à gcc 3.4.6). Le compilateur gfortran apparaît avec GCC 4.0.0, en 2005. Il est issu d'un fork réalisé en 2003 de , un autre compilateur libre, dont le développement a débuté en 2000. Le développent de G95 a par ailleurs été interrompu entre 2008 et 2012. En 2013, gfortran prend pleinement en charge le standard Fortran 95, et une partie de Fortran 2003 et Fortran 2008. Il n'a d'ailleurs pas à rougir devant les compilateurs commerciaux, pour le support de ces deux « nouveaux » standards, les fabricants étant parfois plus intéressés par l'amélioration de la vitesse du code produit que par les dernières fonctionnalités offertes par le standard.
On trouve de nombreux compilateurs commerciaux, parmi lesquels : Lahey, Absoft, , (filiale de NVidia), NAG, etc. La plupart des fabricants de stations de travail ou d'ordinateurs destinés aux calcul intensif, proposent également un compilateur de Fortran : Intel, IBM, HP, SGI, Oracle (suite au rachat de "Sun Microsystems"), Unisys, Cray, etc. Cela comprend aussi les fabricants aujourd'hui disparus, tels que CDC ou DEC (ce dernier a été racheté par Compaq, qui a plus tard fusionné avec HP).
Certains de ces compilateurs commerciaux ont des versions gratuites pour une utilisation non commerciale : c'est le cas d'Intel, Oracle, PathScale. IBM a également mis à disposition une version beta de son compilateur XL Fortran pour MacOS X (sur PowerPC), jusqu'à la sortie de la version commerciale.
Exemple.
Notes :
Différentes versions de Fortran.
Le langage Fortran a connu de nombreuses évolutions :
Bibliothèques graphiques.
Les normes Fortran n'incluent pas d'instructions graphiques. Pour pallier ce manque, il faut utiliser des bibliothèques :

</doc>
<doc id="102195" url="http://fr.wikipedia.org/wiki?curid=102195" title="J (langage)">
J (langage)

Le langage J a été créé au début des années 1990 par Kenneth Iverson, inventeur d'APL. Iverson a raffiné APL et considère avoir simplifié sa notation en lui ajoutant des concepts de verbes, d'adverbes et de conjonctions. Ces notions étaient déjà présentes en APL, où les variables ont un rôle de mots, les "filtres" d'adjectifs et les "opérations" et "fonctions" de verbes.
Le langage J s'interface avec le web, les bases de données, etc. Il est disponible sur plusieurs plateformes, dont MS Windows, Linux et MacOS X. La version "J701" est sous double licence : GPLv3 ou une licence commerciale suivant l'usage envisagé.
Accueil.
L'arrivée du J a créé une scission dans le front des utilisateurs d'APL.
L'apparition de différentes extensions non compatibles entre mises en œuvres du langage APL a donné un peu d'élan supplémentaire à J, qui présente une plus grande portabilité.

</doc>
<doc id="118808" url="http://fr.wikipedia.org/wiki?curid=118808" title="Algol W">
Algol W

Algol W est une version du langage Algol due à Niklaus Wirth, proposée au comité Algol 68 pour succéder à Algol 60. Bien qu'antérieure au Pascal, elle était plus puissante à certains points de vue. En particulier toute expression ou tout bloc ramenait un résultat, ce qui permettait l'écriture d'expressions particulièrement élégantes.
Algol-W est visiblement une étape transitoire entre Algol 60 et Pascal. Il représente une modification relativement légère d'Algol 60, auquel N. Wirth a ajouté les types de données « string », « bitstring », les nombres complexes et les références à des enregistrements (structures), ainsi que le passage de paramètres par valeur, sans changer grand-chose d'autre.
Comme tous les autres langages de Wirth (Pascal, Modula-2, Oberon, etc.), Algol-W est un petit langage à typage statique qui diffère beaucoup moins d'Algol 60 que d'Algol 68, langage nettement plus « gros » et plus complexe. 

</doc>
<doc id="120346" url="http://fr.wikipedia.org/wiki?curid=120346" title="Esterel (langage)">
Esterel (langage)

Esterel est le nom d'un langage de programmation conçu dans les années 1980 par un groupe dirigé par Gérard Berry.
Ce langage est dit synchrone et réactif. Il est impératif et permet l'expression simple du parallélisme et de la préemption. Il est de ce fait bien adapté à la modélisation des systèmes à prépondérance contrôlée.
En tant que langage appartenant à la classe des systèmes informatiques "réactifs" :
Ce langage peut modéliser de nombreux systèmes et milieux : logiciels, matériels, contrôle de flux etc.
Syntaxe/comportement du langage.
Un signal S peut être activé ou désactivé. On l'active via l'instruction emit S.
On change sa valeur (par exemple une valeur du type entier) via l'instruction emit S(valeur).
Pour illustrer l'instantanéité de l'activation des signaux, les instructions emit O; emit O1; emit O2; aboutissent à l'activation instantanée et simultanée en une seule itération des trois signaux O, O1, et O2.
Une autre illustration : le symbole || signifie la parallélité des instructions qu'il sépare.
Un exemple de module :
Un exemple d'utilisation du module précédent dans un autre module :
AB / O signifie que le O de la sous-fonction ABRO est nommé AB dans la fonction ABCRO.
Le langage est encore en développement, sans véritable standard établi. Il existe plusieurs compilateurs Esterel qui permettent de générer du code C, VHDL ou Verilog.
La société Esterel Technologies a engagé un processus de normalisation de la version 7 du langage à l'IEEE en 2005. Le manuel de référence présenté pour la normalisation est disponible.
Il en existe une version orientée objet : Esterel ++, conçue par Dassault Aviation. Différents formalismes graphiques (Syncharts, UML) sont proposés.

</doc>
<doc id="186550" url="http://fr.wikipedia.org/wiki?curid=186550" title="Occam (langage)">
Occam (langage)

Le langage de programmation Occam est un langage de programmation adapté à l'architecture parallèle, apparu en 1983. Il a été développé par Inmos pour la programmation de ses architectures en parallèle Transputer, mais a également été porté sur d'autres plates-formes.
Le nom est un hommage à Guillaume d'Occam (parfois orthographié Ockham) et au principe méthodologique du rasoir d'Occam.
Le langage Occam est un langage procédural classique qui offre, outre l'exécution d'instructions séquentiellement (avec SEQ), l'exécution des instructions en parallèle (avec PAR) et même la mise en « parallèle asynchrone » de processus (avec ALT) pour une exécution non-déterministe d'un parmi plusieurs.
L'exécution en PAR des processus se fait avec des rendez-vous, comme en Ada.
Occam contient aussi les « commandes gardées » de Edsger Dijkstra : un processus n'est lancé que si la valeur de sa garde, évaluée par le système, est vraie.
Le "Transputer Development System" (TDS) d'Inmos était l'outil de développement classique, mais il était possible d'utiliser "Parallel C" ou d'autres outils. L'éditeur du TDS était , c'est-à-dire qu'il donnait la possibilité de plier et déplier des blocs de code, ce qui était très innovant ; à l'heure actuelle, il n'existe encore aucun remplaçant valable.
Quelques notes sur les extraits de code ci-dessous :
Quelques exemples de code réel
codice_1
Autre exemple :
codice_1
Exemple de multiplexeur de canaux :
codice_1

</doc>
<doc id="122984" url="http://fr.wikipedia.org/wiki?curid=122984" title="Rebol">
Rebol

Rebol est un langage de programmation script de haut niveau conçu et imaginé par Carl Sassenrath basé sur la sémantique dénotationnelle et se proclamant « Messaging Language ». On peut éventuellement le rattacher au langage Logo (surtout connu pour sa tortue) avec lequel il partage beaucoup de points communs. Il existe plusieurs versions de l'interpréteur Rebol dont certaines sont gratuites :
Le langage est disponible sur plusieurs plates-formes, notamment Windows, Linux, Mac OS X et Open BSD.
Il est caractérisé par une grande rapidité de développement et de programmes légers, du fait de son haut niveau d'abstraction. Ainsi une "adresse IP"
(exemple : 192.164.86.8) est considérée comme un type de base en rebol et dispose de fonctions de manipulation en propre, ce qui facilite l'écriture des programmes.
C'est un langage qui propose une implémentation orientée objet particulièrement simple mais très efficace. En effet, il n'y a pas de notion de classe, chaque objet étant instanciable à partir d'un autre. Les notions d'instanciation et d'héritage sont moins distinctes que dans la plupart des autres langages orientés objets. 
Il propose aussi un mécanisme très performant (instruction Parse) qui permet de définir simplement un dialecte, un langage personnalisé à la syntaxe choisie de manière à résoudre plus facilement un problème informatique qu'avec la syntaxe générale du langage.
Il dispose maintenant d'un plugin qui permet l'exécution d'applets rebol depuis un navigateur web (en septembre 2004, disponible encore seulement pour Windows et Internet Explorer, mais une possibilité existe pour l'utiliser aussi avec Firefox).
Rebol3.
REBOL 3 a été lancé en 2004 et devait ouvrir Rebol au monde extérieur avec notamment l'intégration d'une couche ouverte facilitant l'intégration avec le monde extérieur via le module Host-Kit. 
Mais seul face au projet, Carl Sassenrath souhaitant avoir la maîtrise totale sur son oeuvre, n'a pas réussi.
C'est finalement pendant l'été 2012, sur son blog, qu'il lança une première lueur d'espoir à l'ensemble de la communauté en attente de nouvelles sérieuses depuis plus de 2 ans .
Finalement, après beaucoup d'attente, le 12 décembre 2012 Carl Sassenrath a annoncé sur son blog la disponibilité du troisième opus du langage de programmation REBOL en Open Source 
Les sources sont disponibles sur github sous licence Apache.

</doc>
<doc id="2631" url="http://fr.wikipedia.org/wiki?curid=2631" title="Ruby">
Ruby

Ruby est un langage de programmation libre. Il est interprété, orienté objet et multi-paradigme. Le langage a été standardisé au Japon en 2011 (JIS X 3017:2011), et en 2012 par l'Organisation internationale de normalisation (ISO 30170:2012).
Historique.
Yukihiro « Matz » Matsumoto est le créateur de Ruby. Frustré par son expérience en développement Smalltalk et Lisp, il débute la conception d'un nouveau langage en 1993 sous Emacs, puis publie une première version en 1995 sous licence libre. Il enchaîne depuis les nouvelles versions.
Des changements de version majeurs ont eu lieu :
La dernière version stable est la 2.1.0, publiée le 25 décembre 2013.
Depuis l'arrivée d'une documentation anglophone, et du en 2004, Ruby a connu un certain engouement qui n'a cessé de croître jusqu'en 2007 dans le monde de la programmation.
Philosophie.
Ruby est fortement orienté objet et se rapproche ainsi du paradigme objet de Smalltalk :
Malgré cet aspect exclusivement objet, la programmation procédurale est possible et fréquente.
Ruby utilise une syntaxe simple, inspirée par Eiffel et Ada.
Le langage est souvent présenté comme évitant au maximum les mauvaises surprises, selon le principe de moindre surprise.
Mais puisqu'il n'est pas possible d'éviter la surprise de "tous" les utilisateurs, Yukihiro Matsumoto précise qu'il cherche surtout à éviter "sa" propre surprise.
Ainsi, plus on connaît le langage, plus on connaît la logique de son auteur, et moins on s'étonne des fonctionnalités qu'on découvre.
Fonctionnalités.
Les fonctionnalités principales sont :
Implémentations.
L'interpréteur officiel, Ruby MRI, fonctionne sur de nombreux systèmes d'exploitation : UNIX, Linux, Microsoft Windows, MS-DOS, OS X, OS/2, AmigaOS, etc.
Il est publié sous la double licence libre GNU GPL et la licence Ruby.
Ruby est fourni avec irb, un interpréteur de commandes interactif pour tester en profondeur le fonctionnement du langage. Il existe une version web d'irb pour tester Ruby dans un navigateur.
Depuis le , le développement de Ruby (1.9) est basé sur l'interpréteur YARV écrit par Koichi Sasada.
Ce nouvel interpréteur apporte un gain notable en performances.
Il existe plusieurs autres interpréteurs Ruby :
" À noter qu'il existe aussi une solution non-libre, commercialisée par HipByte basée sur le travail du projet MacRuby, appelé RubyMotion crée par Laurent Sansonetti"
"La version 2.0 permet de créer des applications graphiques pour OS X et pour IOS."
Interprètes embarqués.
Ruby possède une interface de programmation en langage C qui lui permet d'être intégré au sein d'autres logiciels. Ruby est notamment utilisable dans :
Le logiciel de création de jeu vidéo intègre dans ses versions XP et VX une bibliothèque nommée RGSS, permettant l'usage de scripts en Ruby.
Bibliothèques.
Il existe de nombreuses bibliothèques de fonctionnalités adjoignables au langage.
Le dépôt historique de ces bibliothèques est le (RAA).
Il contient des fonctionnalités supplémentaires pour Ruby comme des bibliothèques de classes et de modules, mais aussi des extensions permettant d'utiliser des bibliothèques tierces.
Le "RAA" contient également des logiciels écrits en Ruby. Parmi ces logiciels on trouve notamment "Rubygems" qui est un outil d'empaquetage et d'installation pour les extensions Ruby.
Il permet de déployer rapidement des bibliothèques et des programmes Ruby.
Le site web "Rubyforge" est également un hébergeur important de programmes et de bibliothèques écrites en Ruby.
Exemples.
Le classique :
Utilisation des objets :
Utilisation de Mixin et de l'Héritage

</doc>
<doc id="7027" url="http://fr.wikipedia.org/wiki?curid=7027" title="Smalltalk">
Smalltalk

Smalltalk est un langage de programmation orienté objet, réflexif et dynamiquement typé. Il fut l'un des premiers langages de programmation à disposer d'un environnement de développement intégré complètement graphique. Il a été créé en 1972. Il est inspiré par Lisp et Simula. Il a été conçu par Alan Kay, Dan Ingals, Ted Kaehler, Adele Goldberg au Palo Alto Research Center de Xerox. Le langage a été formalisé en tant que Smalltalk-80 et est depuis utilisé par un grand nombre de personnes. Smalltalk est toujours activement développé.
Smalltalk a été d'une grande influence dans le développement de nombreux langages de programmation, dont : Objective-C, Actor, Java et Ruby.
Un grand nombre des innovations de l'ingénierie logicielle des années 1990 viennent de la communauté des programmeurs Smalltalk, tels que les Patron de conception (appliquées au logiciel), l’ (XP) et le . Ward Cunningham, l'inventeur du concept du Wiki, est également un programmeur Smalltalk.
Historique.
Il existe un grand nombre de variantes de Smalltalk, comme c'est souvent le cas avec les langages de programmation. Sans autre qualificatif, le mot Smalltalk est souvent utilisé pour désigner Smalltalk-80, la première version à avoir été rendue publique en 1980.
Smalltalk est le produit d'un groupe de chercheurs conduit par Alan Kay au Palo Alto Research Center (PARC) de Xerox ; Alan Kay a conçu les premières versions de Smalltalk qui ont été implémentées par Dan Ingalls. La première version, nommé Smalltalk-71, a été créée en quelques matinées sur le pari qu'un langage de programmation basé sur l'idée d'envoi de messages inspirée de Simula pouvait être réalisé en « une page de code ».
Concepts.
Les principaux concepts de Smalltalk sont :
Description.
Smalltalk implémente, en plus des principes objets de base (classe, objet, héritage, polymorphisme), des concepts originaux (métaclasse) et introduit la notion d'objet persistant, de traitement des exceptions et le principe Modèle-Vue-Contrôleur. 
Une caractéristique surprenante de Smalltalk est l'absence totale d'instructions de contrôle intégrées au langage : if-then-else, for, while, etc. Toutes ces instructions sont implémentées en utilisant des objets. Par exemple, les décisions sont prises en envoyant un message ifTrue à un objet Booléen, et en passant un fragment de code à exécuter si le Booléen est vrai. Le seul aspect intégré par défaut est la syntaxe pour envoyer un message à un objet.
L'exemple suivant illustre le style de programmation Smalltalk. L'exécution de ce code permet de trouver les voyelles dans une chaîne. Le déclare les variables, déclare les paramètres :
À la dernière ligne, la chaîne aString reçoit un message select: avec un bloc de code en argument.
Voici le code de la super-classe Collection qui fait le travail :
Ce code répond au message en itérant au travers de ses membres (c'est la methode do:) en évaluant le code aBlock à chaque caractère ; aBlock (aCharacter isVowel) une fois évalué crée un booléen, qui est alors envoyé à ifTrue:. Si le booléen est vrai, alors le caractère est ajouté à la chaîne qui sera retourné.
Comme select est défini dans la classe abstraite Collection, on pourrait également l'utiliser de cette façon :

</doc>
<doc id="169433" url="http://fr.wikipedia.org/wiki?curid=169433" title="UIML">
UIML

UIML signifie User Interface Markup Language et est un dérivé d'XML permettant de décrire des interfaces graphiques. Normalement les gens pensent à employer XML pour décrire des documents ou des données, mais il est juste un formalisme qui peut être employé pour n'importe quel genre de données structurées. Il y a des outils qui convertissent une représentation d'UIML en représentation pour divers toolkits (par exemple Java awt).
L'objectif est de créer à partir d'XML, un langage commun de description d'interface utilisateur, ouvert et libre d'utilisation. Le but est de permettre le développement d'outils de création d'interfaces utilisateur qui soient indépendants des plateformes, qu'il s'agisse des plateformes actuelles ou futures.
Initié en 1997, le projet UIML vise à définir un métalangage canonique qui peut décrire n'importe quelle interface utilisateur, sans être tributaire du type d'unité ou d'interface graphique utilisée. UIML peut décrire les interfaces utilisateur qui sont aujourd'hui populaire - interface de bureau, interface web, interface mobile, système embarqué, ou encore applications « voix ». UIML peut également décrire les interfaces utilisateur pour les applications développées à la demande ou les applications à venir. Pour les développeurs qui intègrent les développements de tiers, UIML décrit la couche de présentation.
UIML fait l'objet d'une normalisation par l'OASIS depuis 2009 environ ; dès‑lors, l’ancien site UIML.org qui a transféré la responsabilité de la maintenance du standard à OASIS, n’existe plus.
XUL, XAML, MXML fournissent des fonctionnalités semblables à UIML, mais ne sont pas des standards. Cependant, un autre standard, XForms, couvre partiellement les mêmes fonctionnalités.
UsiXML, un standard parallèle de IUML, vise la même finalité.

</doc>
<doc id="3133" url="http://fr.wikipedia.org/wiki?curid=3133" title="Virtual Reality Markup Language">
Virtual Reality Markup Language

Le Virtual Reality Modeling Language (abrégé en VRML) ou Virtual Reality Markup Language est un langage de description d'univers virtuels en 3 dimensions. Ce langage interprété est une norme internationale ISO et les fichiers VRML ont habituellement pour extension .wrl.
C’est à proprement parler un langage de présentation et non de programmation, puisque comme pour le langage HTML par exemple, un fichier VRML ne contient généralement pas une suite d'instructions mais plutôt les informations permettant au visionneur d'afficher ensuite les éléments (formes, senseurs, lumières, etc).
Présenté lors de la World Wide Web Conference de 1994, VRML n'est pas l'œuvre d'un unique programmeur, mais plutôt le résultat de la collaboration de plusieurs professionnels de la 3D, dont entre autres Mark Pesce, Tony Parisi, Gavin Bell (Silicon Graphics) et Paul Strauss (Silicon Graphics).
Le but premier de ce langage est de permettre la représentation d'univers interactifs 3D virtuels. Les fichiers .wrl sont des fichiers texte décrivant les scènes virtuelles à l'aide du langage VRML. Les fichiers .wrl, qui peuvent être stockés localement sur un ordinateur ou téléchargés depuis un serveur web, sont visualisés à l'aide d'un visionneur, qui est soit un plugin ajouté au navigateur web ou encore un logiciel autonome indépendant du navigateur web, qui est installé sur l'ordinateur de l'utilisateur.
Les programmes VRML peuvent décrire des formes simples (points, lignes, polygones) ou complexes (sphères, cubes, cônes, cylindres...), du texte, des images, des animations, des éclairages, des sons, des hyperliens, ainsi que leur agencement dans l'espace, leur texture, leur couleur, leur matériau...
Exemple de description de forme en langage VRML.
Une fois le programme interprété par le visionneur, le monde virtuel s'affiche à l'écran, en 3D; la caméra (c'est-à-dire le point de vue) se positionne à l'endroit prévu de la scène, et l'utilisateur est alors libre de se déplacer dans ce monde (généralement à l'aide du clavier ou de la souris) et d'interagir avec les différents objets présents. Les "sensors" de proximité permettent de lancer une action lors du passage à proximité d'un objet, les "sensors" de touché permettent de déclencher, par exemple, avec un clique sur l'objet l'ouverture d'un autre monde virtuel...
En 1996, une nouvelle mouture du langage fut présentée : VRML 2.0 (par la suite rebaptisée VRML97). Parmi les améliorations par rapport à la version 1.0, on peut citer :
En complément des informations de base concernant les différents objets de la scène 3D, le VRML v2 possède un véritable langage de programmation interne appelé VrmlScript, dont la syntaxe est similaire au JavaScript. Il permet notamment de manipuler les objets (nœuds) de la scène VRML (de type SFNode), ou d'autres types de données propres au VRML comme les SFTime, SFColor, ou encore SFRotation.
Un script écrit en VrmlScript est exécuté à l'intérieur d'un objet (ou nœud) de type Script{}, comme ceci :
Ce langage ouvert et accessible à tous, est bien documenté sur le web et est souvent utilisé pour :

</doc>
<doc id="159948" url="http://fr.wikipedia.org/wiki?curid=159948" title="Lisaac">
Lisaac

Lisaac est un langage de programmation impératif à prototype compilé conçu afin d'écrire le système d'exploitation Isaac. 
C'est un système intégralement modulaire et entièrement composé d'objets posés sur le matériel de la machine. C'est ainsi un langage de haut niveau conçu pour être adapté au développement de pilotes de périphériques.
Présentation générale.
Lisaac est inspiré du langage Self pour les concepts d'objets à prototypes, issu de recherches poursuivies dans les années 1990 par "Sun Research". Il est aussi inspiré du langage Eiffel, un langage objet à classes, pour les aspects d'ingénierie logicielle et notamment pour la programmation par contrat. Enfin les concepts utiles à la programmation système comme la gestion des interruptions ont été rajoutés.
L'objet à prototypes se différencie de l'objet à classe en ce qu'il n'est plus nécessaire de créer une classe, un « moule » de l'objet que l'on instanciera dans le corps du programme. 
Dans le monde à prototype, ne règnent que des objets. Un objet est vivant dès l'exécution. Un objet ne s'instancie pas, il se clone. Un objet peut posséder plusieurs parents (héritage multiple). Un objet peut dynamiquement changer de parents (héritage dynamique).
Le compilateur Lisaac génère du C ANSI optimisé et est ainsi multi-plateforme.
Caractéristiques.
Un langage objet à prototype.
Dans ce type de langage, l'objet règne en maître. Un objet est physiquement présent en mémoire, il se clone. L'héritage se situe au niveau des objets, pas des classes.
Un objet héritant d'un autre objet, plusieurs objets peuvent hériter d'un même objet physique. Étant une entité physiquement séparée, il est possible de changer de parent à l'exécution (voir héritage dynamique)
Protections.
En lisaac, on n'est plus limité par le "private", "public" et "protected". Plus exactement le "protected" est étendu :
On défini une méthode ou propriété publique ou privé en définissant dans Section Public ou Section Private.
Par contre, pour faire du protected, on va faire Section SELF ie. tous les objets héritant de SELF vont pouvoir accéder aux propriétés/méthodes de cette section, ce qui revient à protected.
Mais là où cela devient intéressant est la possibilité de définir Section NUMERIC ou Section ARRAY.
Dans ces sections, seuls les objets (resp.) NUMERIC et ARRAY ainsi que leur descendance auront accès aux méthodes et propriétés définies dans ces sections.
Héritage dynamique.
En lisaac, l'héritage peut se définir par une fonction. Imaginons l'objet DECOD_MPEG2 possédant une méthode renvoyant les Bitmap video issus du décodage :
On veut pouvoir lire la vidéo en mode fenêtré, en plein écran sur l'écran SVGA ou sur la sortie TV...
on a :
Redéfinition des opérateurs.
On peut redéfinir les opérateurs dans n'importe quel objet vu qu'ils sont des méthodes comme les autres (il faut les mettre entre apostrophes, c'est tout).
Dans l'objet NUMERIC on a :
Si on crée un objet MATRICE, on peut le redéfinir
On a redéfini l'opérateur + pour l'objet MATRICE.
Priorités des opérateurs.
Comme on peut le voir dans l'exemple précédent, la priorité et l'associativité des opérateurs est programmable. Cela demande de la part du compilateur une étude approfondie afin de fixer l'ordre d'évaluation des expressions.
Généricité.
On peut définir un objet générique de plusieurs objets :
DICTIONARY(CLE,VALEUR)
Programmation par contrat.
Pour une meilleure fiabilité du code, des mécanismes de programmation par contrat inspirés de la Notation Z ont été ajoutés. 
Lisaac permet de définir des "require", "invariants" et "ensure" comme en Eiffel.
Facilités système.
Lisaac offre deux fonctionnalités systèmes :
Performances.
De récents benchmarks ont démontré les performances du code produit par le compilateur : un décodeur MPEG1/2 complet, écrit en C a été traduit en lisaac en conservant rigoureusement les mêmes structures algorithmiques.
Les résultats sont encourageants : avec 37 % de lignes de code en moins que le source C, Lisaac produit un exécutable 1,9 % plus lent que l'exécutable produit à partir du source C. De plus, grâce à la gestion dynamique de la mémoire, le lecteur est plus fiable.
De nouvelles optimisations sont à l'étude afin de réduire cet écart.
Voir aussi suppression de la liaison dynamique
Suppression de la liaison dynamique.
Les langages objets classiques, jusqu'à SmartEiffel, utilisent des VFTs (de l'anglais "Virtual Function Table") pour compiler la liaison dynamique: :
Soient l'objet IMAGE, et ses deux descendants PNG et XCF. Quand on appelle la fonction PNG.affiche_toi() en Java ou PNG→affiche_toi() en C++, on se retrouve en assembleur avec un appel du type :
L'adresse de PNG (l'objet receveur) pointe sur la base de la VFT, ensuite on ajoute le bon index pour recuperer le champ correspondant à la bonne méthode...
Ce qui implique que cela vide le cache du processeur et que l'inlining est bloqué à la compilation.
Le compilateur lisaac optimise la liaison dynamique en analysant finement le type dynamique des objets grâce à un algorithme de prédiction de type. La liaison dynamique supprimée, il devient possible de procéder à des inlining et à des spécialisations de code.
Syntaxe et sémantique.
La syntaxe est d'abord inspirée de Smalltalk mais aussi d'Eiffel et de Self, la syntaxe des blocs d'instructions est largement inspirée de C.
Lisaac est sémantiquement et syntaxiquement très proche des langages Self et Eiffel. Il reprend aussi quelques éléments syntaxique du C et du Pascal. Comme son grand frère Self, ce langage est minimaliste avec l’absence de construction pour les conditionnelles, les boucles et les itérations : Le compilateur Lisaac ne sait pas ce qu'est une conditionnelle, on implémente celle-ci avec les trois objets Boolean, True, False (True et False héritant de Boolean), dans lesquels les conditionnelles (if ; if/else, etc.) sont définies.
Un pattern matching, au sein du compilateur, va reconstruire les séquences afin de les optimiser et de les rendre aussi rapides qu'en C.
L’approche à objets a pu être respectée par l’absence de types de base (comme par exemple le "int", nombre entier, en Java) pour laisser place à une encapsulation objet à la manière du langage Eiffel et de ses objets de type "expanded".
Versions.
La numérotation des versions du compilateur Lisaac ne suit pas le schéma classique : chaque numérotation du compilateur suit la spécification qu'il implémente.
Les compilateurs disponibles en téléchargement sont généralement stables, attendus qu'ils ne sont disponibles que lorsqu'ils sont débogués. C'est une volonté ferme de son auteur.

</doc>
<doc id="306642" url="http://fr.wikipedia.org/wiki?curid=306642" title="Self (langage)">
Self (langage)

Self est un langage de programmation orienté objet à prototype issu de recherches poursuivies par Craig Chambers et Ole Agesen dans les années 1990 par "Sun Research".

</doc>
<doc id="263155" url="http://fr.wikipedia.org/wiki?curid=263155" title="Simula">
Simula

Simula () a été créé en 1962 sous la dénomination Simula I par Ole-Johan Dahl et Kristen Nygaard à partir d'Algol 60. Le langage évolua en 1967 sous le nom de Simula 67 en implantant le premier le modèle de classe de Hoare (Record Class, Hoare 1965). Il est donc le premier langage à classes et donc le père de tous les langages à classes tel que Smalltalk, C++, Java, ou encore Eiffel. Il inspira Dan Ingalls dans la conception de Smalltalk qui introduisit la programmation orienté objet. C'est la raison pour laquelle Simula 67 est souvent considéré à tort comme le premier langage orienté objet alors que ce paradigme est introduit bien après Simula 67 dans les années 1970 par Alan Kay.
Historique.
Simula a été développé dans les années 1960 au d'Oslo, initialement par Ole-Johan Dahl et Kristen Nygaard. Syntaxiquement parlant, c'est un sur-ensemble d'Algol, qui ajoute à celui-ci les concepts, aujourd'hui familiers, des langages à classes comme C++ Java ou autres et de la simulation à événements discrets.
Simula n'a jamais été un simple langage universitaire, puisqu'il a été utilisé pour des applications industrielles , mais son influence historique est considérée comme plus importante que les applications qui auraient pu être développées avec lui.
Par Simula on entend généralement Simula-67, c'est-à-dire la version de 1967, alors que la version précédente datait de 1962 : Simula .
Simulation discrète.
Comme son nom l'indique, en plus de constituer un langage de programmation généraliste, Simula a été conçu de façon à contenir des bibliothèques de classes offrant un support de concepts spécifiques à la simulation à événements discrets. La classe , héritant de "Simulation" permettait ainsi à l'utilisateur d'hériter pour ses propres classes de simulation du comportement de base d'un processus pouvant s'exécuter en mode dit « "quasi-parallèle" », à l'aide du concept de coroutine.
Une coroutine est une routine à plusieurs points de sortie et qui, à chaque ré-entrée du flot d'exécution dans celle-ci lors d'un appel à l'instruction Resume, reprend son exécution à la dernière instruction où le flot l'avait précédemment quitté lors d'un appel à l'instruction Detach. Le point d'exécution est stocké dans le LSC : .
Pour clarifier le propos, le programme suivant produirait l'affichage indiqué plus bas : 
Affichage :
La bibliothèque de simulation discrète permettait de gérer la file des processus au moyen d'instructions dédiées (Activate, Passivate, Hold, etc.)
Programmation objet.
La plupart des constructions qui permettront plus tard la réalisation des concepts principaux de la programmation orientée objet sont d'ores et déjà présents dans Simula 67 :
Cette liste succincte permet de prendre conscience de la percée conceptuelle opérée par Simula en 1967 dans le domaine des langages impératifs structurés.
Malheureusement, les auteurs de Simula apportèrent une certaine confusion dans le monde de la programmation orientée objet. Avec l'apparition de ce nouveau paradigme avec Smalltalk, Ole Johan Dahl et Kristen Nygaard, changèrent les dénominations utilisées dans Simula pour se conformer aux concepts véhiculés dans Smalltalk (classes d'objets, objets, attributs, méthodes, etc.) et déclarèrent que Simula 67 fut en fait le premier langage orienté objet. Pourtant, l'approche utilisée dans Simula 67 n'est pas celle définie par Alan Kay, l'auteur de la programmation orientée.

</doc>
<doc id="26184" url="http://fr.wikipedia.org/wiki?curid=26184" title="Oberon (langage)">
Oberon (langage)

Oberon (alias Oberon-1) est un langage de programmation développé par Niklaus Wirth et Jürg Gutknecht de 1985 à 1987.
Quoique le langage soit basé sur Modula-2 — dont Wirth est l'auteur —, plusieurs propriétés ont été éliminées et l'extension de type, en outre, fut introduite.
Sa syntaxe ressemble au Pascal.
Oberon élimine également le mécanisme explicite de désallocation de mémoire et intègre un ramasse-miettes.
En 1991, Niklaus Wirth, Jürg Gutknecht et Hanspeter Mössenbock conçoivent Oberon-2, une extension d'Oberon qui inclut les procédures liées au type (méthodes), la polymorphie des objets, les tableaux dynamiques et l'exportation de variables en lecture seulement.

</doc>
<doc id="324794" url="http://fr.wikipedia.org/wiki?curid=324794" title="OPL (langage informatique)">
OPL (langage informatique)

L'OPL (Optimization Programming Language) est le langage de programmation des ordinateurs Psion, apparu sur les modèles MC, comme dérivé du POPL des Organiser I et II.
Il existe une version pour les Series 3, une version étendue pour les Series 3a, 3c, Siena et 3 MX (gestion du niveau de gris, du plus grand écran etc.), et une version pour Series 5, très différente, gérant, par exemple, les menus cascadés ou l'écran tactile.
Il est possible de faire tourner les programmes écrits pour Series 3 en mode compatibilité sur les ordinateurs plus récents de la même architecture.
C'est un langage facile d'abord, grâce à la bonne documentation fournie par PSION, souvent à l'achat du matériel, et grâce à la présence, sur l'appareil, de l'éditeur de programmes et du compilateur.
Le langage est procédural, les variables sont typées et déclaratives, et le code est semi-compilé (réversible avec le logiciel "revtrans").
L'éditeur étant limité à pour le texte source (mais il y a déjà moyen de faire beaucoup dans cette limite), il existe un programme additionnel permettant de gérer les "include".
Il est possible, également, d'incorporer dans l'OPL des parties de code en C.
Liens externes.
Exemple de code OPL

</doc>
<doc id="334901" url="http://fr.wikipedia.org/wiki?curid=334901" title="Io (langage)">
Io (langage)

Io est un langage de programmation pur objet basé sur les prototypes et distribué sous licence BSD. Il a été créé en 2002 par Steve Dekorte.
Présentation.
Lorsque Steve Dekorte imagina son langage, il le voulait léger, simple, multi-plateforme et facile à embarquer dans un autre programme. C'est ainsi qu'est né Io (dont le nom doit refléter sa simplicité).
Il s'inspire de différents langages tout en tirant parti de leurs qualités respectives :
Io est un langage de script disposant de plusieurs extensions dans divers domaines tels que le chiffrement des données, la programmation réseau, le graphisme ou encore les bases de données.
Machines virtuelles.
Io se décline sous trois machines virtuelles ce qui lui apporte une grande portabilité puisque celui-ci (comme tout langage interprété) peut être exécuté sous n'importe quelle architecture pour autant que la machine virtuelle soit disponible pour celle-ci.
IoVM.
"IoVM" est la base du langage ; la plupart des fonctionnalités se trouvant dans "IoServer" et "IoDesktop". Elle peut être utilisé indépendamment ou en tant que langage embarqué dans un plus grand projet.
IoServer.
"IoServer" apporte de nombreuses fonctionnalités par rapport à la conception d'applications serveurs telles que les applications Web.
IoDesktop.
Et enfin, "IoDesktop", se veut être une solution de développement multimédia. Il est donc possible par son intermédiaire d'exploiter des images, OpenGL et tout ce qui est en rapport avec le multimédia.
Ces trois machines virtuelles permettent aux scripts Io de fonctionner de manière identique peu importe le système. Elles sont actuellement disponibles sous Mac OS X, Linux, BSD, Irix, Win32 et Symbian. Cependant, écrites en C ANSI, elles peuvent être facilement portées sur de nombreuses autres plates-formes.
Exemples de code.
Io est un langage qui se veut simple et puissant. Voici quelques exemples de code.
Bonjour tout le monde.
La ligne de code suivante fera apparaître le message "Bonjour tout le monde !" à l'écran.
Compter les moutons.
Pour plus d'exemples, vous pouvez visiter la page d'exemples sur le site officiel.

</doc>
<doc id="343043" url="http://fr.wikipedia.org/wiki?curid=343043" title="VisualWorks">
VisualWorks

VisualWorks est une implémentation de Smalltalk développée initialement au Xerox PARC, puis par ParcPlace Systems et enfin repris par Cincom. VisualWorks s'exécute sur plusieurs plates-formes comme Apple Macintosh, GNU/Linux, plusieurs versions d'UNIX et Windows. 

</doc>
<doc id="346122" url="http://fr.wikipedia.org/wiki?curid=346122" title="Locomotive BASIC">
Locomotive BASIC

Locomotive BASIC est un dialecte propriétaire du langage de programmation BASIC écrit par Locomotive Software. Disponible seulement sur certaines Compatible PC Amstrad (Amstrad PC-1512 par exemple) et tous les Amstrad CPC où l'interpréteur était intégré sur une puce mémoire non-modifiable (ROM). C'est le principal ancêtre du Mallard BASIC se trouvant sur les Amstrad PCW.
Il a été édité en plusieurs versions : la version 1.0 se trouvait sur les modèles CPC464, la version 1.1 sur les CPC664, la version 1.2 sur les CPC6128 et la version 1.4 sur les machines Amstrad CPC Plus.
À noter toutefois que les versions 1.2 et 1.4 s'annoncent comme étant des 1.1 à l'invite. Si la transition entre les versions 1.0 et 1.1 apportait son lot de nouvelles commandes, les versions 1.2 et 1.4 n'offraient rien de nouveau sinon des corrections de bugs ou des améliorations de performance.

</doc>
<doc id="351987" url="http://fr.wikipedia.org/wiki?curid=351987" title="CDuce">
CDuce

CDuce est un langage de programmation fonctionnel, d'ordre supérieur, fortement typé, adapté à la manipulation sûre et efficace de documents XML.
Une opération de filtrage par motifs permet d'exprimer de manière concise des extractions de données complexes, et le système de type garantit que tous les documents valides en entrée seront traités de manière exhaustive, et qu'aucun document invalide en sortie ne pourra être produit.
Le projet OCamlDuce vise à intégrer CDuce dans le langage généraliste OCaml.

</doc>
<doc id="366242" url="http://fr.wikipedia.org/wiki?curid=366242" title="Visual DialogScript">
Visual DialogScript

, souvent abrégé VDS est un langage de programmation simplifié de type script ou batch.
Fonctionnalités.
Il permet de programmer de manière rapide un utilitaire basique pouvant automatiser certaines tâches rapides ou ne nécessitant pas l'intervention d'un langage de programmation plus complexe.
Fonctionnement.
Un exécutable compilé d'environ 10-15 ko représente le programme écrit. Une fois le programme lancé, le langage est interprété par une dll équivalente à la version du logiciel par exemple "VDSRUN30.dll" pour "Visual DialogScript 3", ou "VDSRUN40.DLL" pour "Visual DialogScript 4"
Améliorations.
Depuis la version 5, Visual DialogScript est capable entre autres de :

</doc>
<doc id="389014" url="http://fr.wikipedia.org/wiki?curid=389014" title="SableVM">
SableVM

SableVM est un programme informatique consistant en une machine virtuelle libre pour Java développée par l'équipe SableVM. Celle-ci se propose de réaliser un ensemble maintenable et portable. Le logiciel est distribué sous licence LGPL. Il utilise également GNU Classpath (dont les droits sont détenus par la Free Software Foundation) sous licence GPL sauf pour le lien.
SableVM est compatible avec les spécifications complètes de Java. La machine virtuelle a été conçue de manière à s'approcher des performances des compilateurs JIT ("just-in-time"). SableVM est la première machine virtuelle Java libre qui supporte le "JVMDI" ("Java Virtual Machine Debugging Interface") et "JDWP" ("Java Debug Wire Protocol"). Ces interfaces de débogage sont utilisées par Eclipse pour offrir un environnement de développement efficace et riche. 

</doc>
<doc id="404704" url="http://fr.wikipedia.org/wiki?curid=404704" title="Processing">
Processing

Processing (autrefois typographié Proce55ing) est une librairie java et un environnement de développement libre (sous licence GNU GPL), créé par Benjamin Fry et Casey Reas, deux artistes américains. Processing est le prolongement « multimédia » de Design by numbers, l'environnement de programmation graphique développé par John Maeda au Media Lab du Massachusetts Institute of Technology. 
Processing est tout particulièrement adapté à la création plastique et graphique interactive. 
Le logiciel fonctionne sur Macintosh, Windows, Linux, BSD et Android. Il est basé sur la plate-forme Java — il permet d'ailleurs de programmer directement en langage Java.
Il existe également une version en Javascript de Processing, appelée Processing.js, cette version pouvant être exécuté dans un environnement HTML 5 ou via node.js.
Les programmes réalisés avec Processing peuvent être lus par les navigateurs internet équipés du plug-in java, mais aussi sous forme d'applications indépendantes pour Windows, Linux ou Mac OS X (en réalité n'importe quelle machine disposant d'une Machine virtuelle Java).
Philosophie.
Le principe majeur de Processing est la simplicité, dans la mise en œuvre des programmes comme dans la syntaxe du langage. Adapté à la création graphique, Processing réclame moins d'efforts que Java pour effectuer des tâches simples telles que la modification d'une animation à intervalle régulier (qui permet des créations animées). Ses fonctionnalités sont limitées aux besoins des créateurs d'images 2D et 3D générées par programmation mais peuvent être étendues, par le biais de modules externes, à la capture d'un flux vidéo, à la génération et à la manipulation de son, à l'interfaçage des ports d'entrées-sorties, etc.
Processing s'adresse aux artistes en « arts numériques » et aux graphistes, notamment dans le domaine du graphisme d'information et dans celui du graphisme génératif. Il permet d'élaborer des sketches.
Syntaxe.
On peut écrire le traditionnel Hello world de cette manière :
et même ainsi, sans la moindre déclaration préliminaire :
Cependant, la méthode suivante est sans doute plus typique du fonctionnement de Processing : 
Les gestionnaires "setup()" et "draw()" sont deux fonctions pré-définies très importantes dans processing. La première, setup(), est exécutée une seule fois au lancement du programme. La seconde, "draw()" est lancée à intervalle régulier, par défaut dix fois par seconde.
Processing emploie un typage rigoureux et est sensible à la casse. La structure de ses fonctions de base (comparaisons, conditions, boucles, etc.) est familière pour les utilisateurs du C++ ou de Java.
Par exemple, une condition s'évalue ainsi :
et une boucle se construit de cette façon :
Proce55ing.
L'ancien nom de Processing, "Proce55ing", a été forgé ainsi car le nom de domaine "Processing.org" était pris et le site officiel a d'abord dû exister à l'adresse "Proce55ing.org". À présent, les auteurs de Processing disposent du nom de domaine "Processing.org", ils n'utilisent plus l'ancienne forme du nom et en déconseillent l'usage. Cependant, de nombreuses personnes abrègent le nom en p5.
Extensions et projets alternatifs.
Le projet "Arduino", qui se base sur "Processing", comme son « ancêtre », "Wiring", permet la manipulation de circuits électroniques extérieurs pour interfacer des capteurs ou des appareils électroniques divers (servomoteurs, leds…). Un autre environnement logiciel, Fritzing, a été conçu pour aider les utilisateurs au prototypage de matériel destiné à être utilisé avec "Arduino" et "Processing". Le projet "Mobile Processing", comme son nom l'indique, a l'ambition de porter "Processing" sur téléphones portables. Enfin, "Processing.js" est une implémentation JavaScript de Processing.
Depuis sa version 1.5.1, Processing peut produire des applications pour plate-forme Android et accéder aux capteurs spécifiques aux dispositifs mobiles (accéléromètre, GPS, etc.). Depuis la version alpha de Processing 2.0, Processing pourra aussi exporter directement du contenu au format HTML5/Javascript.
De nombreuses librairies externes peuvent être ajoutées à Processing pour accéder à des ressources telles que la vidéo, le son, la reconnaissance faciale, la caméra Kinect, les moteurs physiques, etc.

</doc>
<doc id="293795" url="http://fr.wikipedia.org/wiki?curid=293795" title="Izibasic">
Izibasic

IziBasic est un langage de programmation de la famille des BASIC, destiné aux assistants personnels sous Palm OS. Le public visé est constitué aussi bien de programmeurs débutants ou amateurs que plus expérimentés.
IziBasic est un outil de développement de haut niveau, de type compilateur pour BASIC, qui construit des applications autonomes, directement sous Palm OS, sans nécessiter l'utilisation d'un PC.
Les codes sources sont écrits en utilisant :

</doc>
<doc id="468290" url="http://fr.wikipedia.org/wiki?curid=468290" title="Stream Editor">
Stream Editor

sed (abréviation de Stream EDitor, « éditeur de flux ») est, comme awk, un programme informatique permettant d'appliquer différentes transformations prédéfinies à un flux séquentiel de données textuelles. sed lit des données d'entrée ligne par ligne, modifie chaque ligne selon des règles spécifiées dans un langage propre (appelé « script sed »), puis retourne le contenu du fichier (par défaut). Bien qu'originellement écrit pour Unix, par en 1973/1974 (Bell Labs), sed est maintenant disponible sur pratiquement tous les systèmes d'exploitation disposant d'une interface en ligne de commande.
Présentation.
sed est souvent décrit comme un éditeur de texte non-interactif. Il diffère d'un éditeur conventionnel en ceci que la séquence de traitement des deux flux d'informations nécessaires (les données et les instructions) est inversée. Au lieu de prendre une par une les commandes d'édition pour les appliquer à l'intégralité du texte (qui doit alors être intégralement en mémoire), sed ne parcourt qu'une seule fois le fichier de texte, en appliquant l'ensemble des commandes d'édition à chaque ligne. Comme une seule ligne à la fois est présente en mémoire, sed peut traiter des fichiers de taille complètement arbitraire.
Principe de fonctionnement.
Le jeu de commandes de sed est basé sur celui de l'éditeur ed. En effet, la majorité des commandes fonctionne de manière similaire, malgré l'inversion du paradigme. Par exemple, la commande codice_1 signifie "s'il s'agit de la ligne 25, alors efface-la (c'est-à-dire, ne la renvoie par vers la sortie)", au lieu de "va à la ligne 25 et efface-la", telle que ed l'exécute. Les exceptions notables sont les commandes de copie et de déplacement, qui s'appliquent sur un intervalle de lignes, et qui par conséquent n'ont pas d'équivalent direct dans sed. À la place, sed introduit une mémoire tampon supplémentaire appelé "hold space", ainsi que des commandes pour la manipuler.
Par exemple, la commande ed pour copier la ligne 25 à la ligne 76 (codice_2) pourrait être codée en deux commandes distinctes dans sed (codice_3). La première mémorise la ligne dans le "hold space", la seconde la récupère lorsqu'il est temps.
Utilisation.
L'exemple suivant montre une utilisation habituelle de sed :
La commande codice_4 signifie "substitute" (« substituer »). Le drapeau codice_5 signifie "global", ce qui indique que toutes les occurrences dans chaque ligne doivent être remplacées. Après le premier caractère codice_6 est donnée une expression rationnelle que sed doit trouver. Après le deuxième codice_6 est précisée l'expression remplaçant ce qu'il a trouvé. La commande de substitution (codice_8) est de loin la commande de sed la plus puissante et la plus fréquemment utilisée.
Une application possible de la substitution est la correction d'une faute d'orthographe récurrente, ou le remplacement de toutes les occurrences d'un sigle. Par exemple :
Il n'est pas obligatoire d'utiliser « codice_6 » comme délimiteur. Les caractères « codice_10 » (liste non exhaustive) peuvent également servir pour éviter l'accumulation d'anti-slash de « protection » rendant la syntaxe peu lisible. Les commandes suivantes sont équivalentes:
sed peut aussi servir à numéroter les lignes d'un fichier, supprimer les balises HTML d'un texte, etc. Toutefois, sur certaines plates-formes, le langage Perl est bien souvent utilisé en remplacement de sed.
Sur Unix, sed est souvent utilisé comme filtre dans un tube :
Dans cet exemple, des données sont générées, puis elles sont modifiées à la volée en remplaçant les "x" par des "y".
Plusieurs substitutions, ou autres commandes, peuvent être regroupées dans un fichier, appelé "script sed" (codice_11 dans l'exemple suivant), puis appliquées sur les données :
En plus des substitutions, d'autres types de traitements simples sont disponibles. Par exemple, le script suivant retire les lignes vides ou qui ne contiennent que des espaces :
Cet exemple utilise des métacaractères pour former des expressions rationnelles :
sed permet également l'utilisation des champs pour identifier certaines parties d'une chaîne de caractère. Un champ est défini par une expression rationnelle identifiée par les balises codice_12 et codice_13, le champ peut ensuite être utilisé avec codice_14 où codice_15 est le numéro du champ (le nombre de champs est limité à 9). Exemple : permuter deux champs séparés par un tiret :
Autre exemple : afficher les N derniers caractères d'une chaîne :
Deux champs sont définis : codice_16 qui contiendra les premiers caractères et codice_17 qui contiendra les N derniers. Les accolades de l'expression rationnelle qui permettent de spécifier le nombre d'occurrences codice_18 doivent être protégées par un anti-slash.
Programmation.
Les structures complexes sont possibles avec sed, dans la mesure où il peut être assimilé à un langage de programmation très spécialisé mais simple. Par exemple, le contrôle du fil d'exécution peut être géré à l'aide d'étiquettes ("labels", un codice_19 suivi du nom de l'étiquette) et de l'instruction de branchement codice_20. Une instruction codice_20 suivie d'un nom d'étiquette valide transférera le fil d'exécution au bloc suivant l'étiquette. Si l'étiquette n'existe pas, alors l'instruction termine le script.
sed est l'une des commandes Unix les plus anciennes permettant à la ligne de commande de traiter des fichiers de données. Il a naturellement évolué comme successeur de la célèbre commande grep. Cousin du plus jeune Awk, sed permet au script shell d'effectuer des traitements puissants et très utiles. sed a probablement été l'un des tout premiers outils d'Unix à réellement encourager l'utilisation omniprésente des expressions régulières. En ce qui concerne la vitesse de traitement, sed est généralement plus rapide que Perl, et sensiblement plus rapide que Awk.
sed et Awk sont souvent cités comme étant les ancêtres et les inspirateurs de Perl. En particulier, la syntaxe codice_8 de l'exemple précédent fait partie intégrante de la syntaxe de Perl.
Le langage de sed ne dispose pas de variable et ne possède qu'un goto primitif comme instruction de contrôle de flux. Toutefois, il est turing-complet [http://sed.sourceforge.net/grabbag/scripts/turing.txt].
Extensions.
GNU sed intègre plusieurs nouvelles fonctionnalités telles que l'édition « en place » (le fichier original est remplacé par le résultat du traitement par sed). L'édition en-place est souvent utilisée pour remplacer un script ed. Par exemple :
peut être utilisé à la place de
Il existe une version améliorée de sed, appelée super-sed (ssed [http://www.gnu.org/directory/text/editors/super-sed.html]), qui intègre des expressions rationnelles compatibles avec Perl.
Exemple.
L'exemple qui suit montre comment sed, qui traite habituellement chaque ligne séparément, peut supprimer les sauts de lignes des lignes dont la ligne qui suit commence par une espace.
Pour illustrer l'effet souhaité, considérons le texte suivant :
La commande sed donnera :
Voici la commande :
qui peut se décomposer de la manière suivante (les codice_23 permettent de séparer les commandes) :
e façon plus concrète on peut regrouper les entêtes d'un fichier type mbox ( par exemple ), en le déroulant et supprimant les corps :

</doc>
<doc id="475326" url="http://fr.wikipedia.org/wiki?curid=475326" title="ArmScript">
ArmScript

ArmScript est un langage de programmation interprété qui repose sur des commandes. Il a été créé en novembre 2005.
Il reprend les bases des autres langages (variables, etc.) mais tout le langage repose sur des fonctions prédéfinies, qui prennent des arguments qui peuvent être des variables ou des "flags". Un nouveau système d'arguments, les "surplus", rendent le code source plus compréhensible en plusieurs points.
Actuellement, le langage permet :
L'intérpreteur normalisé s'appelle "arm"
À long terme, ArmScript serait le langage principal du système d'exploitation hypnOS.

</doc>
<doc id="333579" url="http://fr.wikipedia.org/wiki?curid=333579" title="Inform (programmation)">
Inform (programmation)

Inform est un langage de programmation optimisé pour la création de jeux en fiction interactive, créé en 1993 par Graham Nelson.
Vue d'ensemble.
Le système Inform est composé d'une part d'un compilateur qui génère des fichiers lisibles par les machines virtuelles "zmachines" ou "glulx", et d'autre part de bibliothèques qui aident à la modélisation d'aventures textuelles. Les manuels disponibles pour l'apprentissage d'Inform sont uniquement en anglais, bien qu'il soit tout à fait possible de réaliser des jeux en français grâce aux traductions de certaines bibliothèques du système. Quelques jeux existent déjà en français (voir les liens externes).
Le langage inform 6 est à la fois procédural et orienté objet.
Inform 7.
Le 30 avril 2006, Graham Nelson a annoncé la version beta Inform 7 sur la liste de diffusion rec.arts.int-fiction . Cette nouvelle version, qui a pris à lui et son équipe 3 ans de développement dans le plus grand secret, est décrite comme une "réinvention radicale". Inform 7 est en effet un programme complet tournant sur MacOSX, Windows et Linux, et la nouvelle syntaxe utilise dorénavant du code source en langue naturelle, sous forme de règles déclaratives, permettant à un auteur d'écrire avec plus de liberté. Inform 6 est toujours utilisé en traitement sous-jacent du code transcrit par l'interface d'Inform 7.

</doc>
<doc id="506270" url="http://fr.wikipedia.org/wiki?curid=506270" title="Sather">
Sather

Sather est un langage de programmation orienté objet. Il est né aux alentours de 1990 à l’ à l'Université de Berkeley, développé par une équipe internationale menée par Steve Omohundro. Il supporte le ramasse-miettes et la généricité par sous-typage.
Il vaut probablement mieux le voir comme un langage orienté objet, avec de nombreuses idées empruntées au langage Eiffel. Même le nom est inspiré d'Eiffel, la Tour Sather se situe à Berkeley. Sather s'inspire également d'autres langages de programmation et paradigmes : itérateurs, programmation par contrat, classes abstraites, héritage multiple, fonctions anonymes, surcharge d'opérateur, contrevariance. Certaines de ces caractéristiques ne sont normalement présentes que dans les langages de programmation fonctionnelle.
L'implémentation originelle de Berkeley est maintenant maintenue par de nombreuses personnes, pas toutes de Berkeley, et a été adoptée par la . Il existe au moins deux autres implémentations : Sather-K de l'université de Karlsruhe, et Sather-W de l’.
Sather est implémenté par un compilateur vers le langage C, c'est-à-dire que le compilateur ne sort pas du code objet ni du code machine, mais des fichiers source C en tant que langage intermédiaire.

</doc>
<doc id="312908" url="http://fr.wikipedia.org/wiki?curid=312908" title="TTCN">
TTCN

TTCN est un langage de programmation pour les tests des protocoles de communication. Une suite de tests TTCN consiste en un grand nombre de scénarios de test écrits en TTCN.
Jusqu'à la version 2, le langage est écrit d'une manière non conventionnelle dans des tables et appelé "tree and tabular combined notation" (« notation combinée arborescente et tabulaire »). La lecture et l'écriture dans ce langage nécessitaient des éditeurs spécifiques à TTCN.
Avec la version 3, TTCN fut renommé "testing and test control notation" (« notation de tests et de contrôle de tests »). Il est plus proche des langages de programmation modernes et peut s'écrire dans un éditeur de texte traditionnel. TTCN-3 est encore plus flexible que TTCN-2, parce qu'il peut être utilisé pour tester les logiciels traditionnels, en plus des protocoles.
Pour leur exécution, toutes les versions ont besoin de compilateurs ou d'interpréteurs dédiés.
TTCN est largement utilisé par exemple par l'ETSI et l'UIT pour tester les protocoles de télécommunication. Les tests de conformité des standards ETSI comme ISDN, DECT, GSM, EDGE ou 3G ont été effectués en TTCN. Depuis quelques années, il est utilisé pour tester d'autres protocoles standards comme Bluetooth et IP.
L'exécution de ces tests sur des produits (par exemple, des téléphones fixes ou mobiles ou des éléments de réseau) permet de vérifier que l'implémentation du protocole de ces produits respecte les exigences définies par les standards de télécommunication.
TTCN est souvent utilisé en tandem avec ASN.1.

</doc>
<doc id="282726" url="http://fr.wikipedia.org/wiki?curid=282726" title="SR (programmation)">
SR (programmation)

SR (abriéviation de Synchronizing Resources) est un langage de programmation dédié à la programmation concurrente.

</doc>
<doc id="233267" url="http://fr.wikipedia.org/wiki?curid=233267" title="BCPL">
BCPL

BCPL (Basic Combined Programming Language) est un langage de programmation créé par Martin Richards de l'Université de Cambridge (1966) et une réponse aux difficultés rencontrées avec son prédécesseur le Combined Programming Language (CPL) durant les années 1960. Le premier compilateur fonctionnel fut écrit pendant sa visite du Massachusetts Institute of Technology (MIT) au printemps 1967. Ce langage fut décrit la première fois dans un journal au "1969 Spring Joint Computer Conference". Dennis Ritchie développa plus tard le C à partir du BCPL.
Histoire.
BCPL est un langage de programmation propre, puissant et portable. Il rend possible l'écriture de compilateurs petits et simples. C'est notamment un choix populaire pour l'amorçage d'un système. D'après les informations reçues, quelques compilateurs peuvent fonctionner sur 16 ko seulement. Plusieurs logiciels d'exploitation ont été écrits partiellement ou complètement en BCPL (par exemple, TRIPOS ou Amiga Kickstart). 
Une raison majeure de la portabilité de BCPL s'explique par la structure de ses compilateurs, qui sont scindés en deux parties
En peu de temps cette pratique devint courante, voir le Pascal ou Java, mais le compilateur BCPL de Martin Richards a été le premier à utiliser une machine virtuelle à cette fin.
Ce langage n'est pas courant, puisqu'il ne possède qu'un seul type de données : 
le type "word" comportant un nombre fixe de bits (nombre habituellement choisi pour s'aligner sur le langage machine). L'interprétation de toutes les valeurs est déterminée par l'opérateur utilisé lors du traitement. Pour permettre ce fonctionnement, l'exécution ne réalise pas de contrôle de type.
La notation hongroise a été développée pour aider les programmeurs à éviter les fautes de type endémiques en BCPL.
En 1979, BCPL était supporté par au moins 25 architectures ; en 2001 il n'était plus que très peu utilisé. La conception de BCPL influença significativement le langage B, qui lui-même influença le C, qui est à présent le langage de choix 
pour la programmation système.
La philosophie du BCPL peut être récapitulée par la citation du livre, "BCPL, the language and its compiler" :
Hello World.
C'est d'après les informations reçues le langage originel du fameux Hello world.
Le premier MUD[http://www.mudconnect.com/mud_intro.html] fut aussi écrit en BCPL .

</doc>
<doc id="77553" url="http://fr.wikipedia.org/wiki?curid=77553" title="ABAP">
ABAP

ABAP est un langage de programmation propriétaire, faisant partie de l'ensemble logiciel SAP. Il s'agit actuellement du langage utilisé dans la programmation des Web Application Server faisant partie de la plateforme Netweaver pour la réalisation de progiciels.
Sa version "ABAP/4" est objet, le chiffre "4" faisant de plus référence à son appartenance à la classe des langages de quatrième génération.
Histoire.
L'acronyme ABAP signifiant à l'origine "Allgemeiner Berichtsaufbereitungsprozessor " ("processeur générique pour la préparation de rapport") et a par la suite été anglicisé en Advanced Business Application Programming.
ABAP est l'un des successeurs du COBOL et est apparu dans les années 1980 dans la vague des langages de quatrième génération (L4G). Il s'agit d'un dérivé du langage permettant de réaliser des sorties de données (appelées "rapports") de l'application SAP R/2, sur lequel de nombreuses multinationales avaient bâti leur architecture d'application professionnelle. ABAP a par la suite été maintenu comme langage de référence pour les applications SAP R/3 qui sont apparus en 1992.
À l'origine, ce langage comprenait le concept de "Base de données logique" qui devait permettre à tout utilisateur de créer lui-même les rapports dont il avait besoin. Il s'est avéré en fait que développer des programmes avec ce langage ne pouvait être fait en pratique que par des professionnels disposant d'une solide expérience.
Le langage a été par la suite étendu pour englober un modèle de données orienté objets (ABAP Objects) à partir de sa version 4.5, pour être finalement intégré comme langage d'un produit plus général appelé NetWeaver. Ce dernier utilise aussi bien ABAP que le java.
C'est un langage interprété.
Composants du langage.
Un "outil de transport" . À chaque modification d'un programme, celui-ci doit être "transporté" de l'environnement dans lequel il est créé vers un environnement de test puis dans l'environnement de production (chacun de ces environnements dispose de jeux de données distincts, il peut exister plus de trois environnements dans un système d'information donné). Cette opération est réalisée par la mise en œuvre d'un "ordre de transport".
ABAP pour quoi faire ?
ABAP jusqu'à l'apparition de NetWeaver était la brique constituante des systèmes SAP R/3. Il permet de réaliser :
ABAP a évolué pour intégrer la programmation objets. Tous les concepts de la programmation objets se retrouvent dans ABAP Objects. ABAP Objects constitue une extension du langage ABAP, avec lequel il est totalement compatible : ainsi il est possible qu'un programme comporte à la fois une partie procédurale et une partie orientée objets, car le déroulement procédural du programme peut à tout moment instancier une classe puis appeler les méthodes de l'objet qu'il vient de créer.
Exemples de programmes ABAP.
Le grand classique:
Ce qui donne pour l'écran de selection :
Et pour le résultat :

</doc>
<doc id="344812" url="http://fr.wikipedia.org/wiki?curid=344812" title="ABCL/1">
ABCL/1

ABCL/1 (Actor-Based Concurrent Language) est un langage à prototype et concurrent créé en 1986 par Akinori Yonezawa, of the "Department of Information Science" de l'Université de Tokyo.
ABCL/1 utilise des envois de messages asynchrone entre les objets afin d'implémenter la concurrence. Il nécessite Common Lisp.

</doc>
<doc id="119866" url="http://fr.wikipedia.org/wiki?curid=119866" title="Tk (informatique)">
Tk (informatique)

Tk est une bibliothèque d'interfaces graphiques multiplate-forme. Conçu à l'origine pour un langage de script inventé par John Ousterhout et connu sous le nom de Tcl, il s'interface aujourd'hui avec d'autres langages tels que Perl, Python, Ruby, Lua, Common Lisp, REXX, Ada, Prolog, OCaml, R ou APL.
Tk existe aussi pour les navigateurs web sous la forme d'un "plugin", Tcl plugin, qui permet d'exécuter des tclets (applets écrits en Tcl-Tk).
Les "widgets".
Chaque "widget" possède des propriétés modifiables selon le type (taille, relief, couleur, contenu, état, événement).
Gestion de la géométrie.
Pour contrôler la dimension et agencer graphiquement les "widgets", il existe trois 
gestionnaires de géométrie :
Tant qu’un "widget" n’est pas associé à un gestionnaire de géométrie, il n’apparaît pas 
à l'écran.
Gestion des événements.
À la différence d'un programme en ligne de commande où l'interaction avec l'utilisateur 
est séquentielle, l'interface graphique fait intervenir la notion de "programmation événementielle" avec une autre logique. À tout moment, chaque "widget" est susceptible d'être affecté par l'action de l'utilisateur (l'événement).
Il existe des événements simples (clic de souris sur un bouton, saisie au clavier dans un champ) et des événements plus complexes (navigation dans un menu ou une liste 
déroulante).
À chaque "widget" est attaché par défaut un certain nombre de réponses automatiques à des événements. Celles-ci correspondent à une gestion des événements de bas niveau où le programmeur n'a que très peu à intervenir. Une "boucle événementielle" les prend en charge et les répartit.
Ensuite, par l'intermédiaire de l'option codice_1, on peut lier un "widget" 
à un appel de procédure ou une commande extérieure ("callback").
Si l'on souhaite associer à un "widget" une réponse particulière non définie par défaut, 
Tcl-Tk dispose d'un mécanisme très flexible grâce à la commande codice_2.
Bibliothèque standard.
Tk dispose d'une bibliothèque standard appelée Tklib (le pendant pour Tcl étant la Tcllib) exclusivement écrite en Tcl. Elle contient divers modules pour la représentation graphique de données, la gestion et l'affichage de textes, les tables, les champs d'entrée spécifiques ainsi que les BWidget (une bibliothèque de "widgets" de haut niveau).
Histoire de Tk.
John Ousterhout a commencé à concevoir cette IHM à la fin de l'année 1988 parallèlement au développement de Tcl. Tk a subi l'influence du système HyperCard d'Apple. Il a été développé en C et était basé sur Xlib en fournissant une dizaine de composants IHM appelés "widgets" (contraction de "window gadget"). À cette époque, ils ne fonctionnaient que sous UNIX.
La combinaison de Tcl et Tk (appelé Tcl-Tk ou Tcl/Tk) fut présentée la première fois en janvier 1991 à la "Conférence USENIX". Il permettait de s'affranchir de la complexité et du temps de développement accru d'une application écrite avec la bibliothèque Motif. Par la suite, le développement de Tk était suffisamment découplé de celui de Tcl pour être utilisé avec d'autres langages. Les versions pour Windows et Macintosh apparurent en 1994 sous l'impulsion des développeurs du laboratoire de Sun Microsystems. Par souci de clarté, en août 1997, la décision fut prise d'aligner les numéros de version de Tk sur ceux de Tcl.
En décembre 2007 sort Tcl-Tk 8.5. Cette version a la particularité d'inclure un moteur de thèmes qui améliore grandement l'aspect visuel de l'interface graphique rompant ainsi définitivement avec l'héritage de la bibliothèque Motif. 
En décembre 2012, sort Tcl-Tk 8.6. Un travail a été effectué sur les coordonnées des objets dans le widget codice_5 et sur le support du format PNG.

</doc>
<doc id="588408" url="http://fr.wikipedia.org/wiki?curid=588408" title="Plankalkül">
Plankalkül

Plankalkül est un langage de programmation, conçu de 1942 à 1946 par l'allemand Konrad Zuse. À l'époque, Zuse ne fit aucune communication scientifique à ce sujet, pour diverses raisons : la Seconde Guerre mondiale faisait rage, et il consacrait tous ses efforts à la conception et à la commercialisation de son ordinateur, le Zuse 3.
La première publication mentionnant Plankalkül date de 1948. En 1975, il fut décrit et implémenté à l'occasion de la thèse de J. Hohmann. Le premier compilateur, proposé par l'université libre de Berlin, a été achevé en 2000, soit cinq ans après la mort de Zuse.
Description.
D'après Zuse, Plankalkül est le premier langage de haut niveau.
Ce langage eut pourtant le même destin malheureux que son créateur. Ainsi il était extrêmement innovant, mais en dehors du courant principal, mondial, du développement de l'informatique. Il demeura donc très largement inconnu. 
Ce langage présente une innovation rare, voire unique, pour un langage informatique : les programmes s'écrivent en deux dimensions, de la même façon que la notation algébrique. Il est donc plus proche des traditions du plan et de la formule que de celles de la prose et du récit.
Pour ces raisons, certains le rapprochent même des langages à objet dont il serait un ancêtre, à un niveau intermédiaire entre ces derniers et l'algèbre classique.
Exemple.
Le programme ci-dessous calcule le maximum de trois variables en appelant la fonction "max":

</doc>
<doc id="627602" url="http://fr.wikipedia.org/wiki?curid=627602" title="Unified Parallel C">
Unified Parallel C

Unified Parallel C (UPC) est une extension du langage de programmation C conçue pour les calculs hautes-performances sur des supercalculateurs parallèles, y compris les architectures à espace d'adressage global (SMP et NUMA) et celles à mémoire distribuée (clusters). Le langage définit un espace d'adressage partagé et partitionné, où les variables peuvent être directement lues et écrites par n'importe quel thread, mais chaque variable est physiquement associée avec un simple processeur. UPC utilise un modèle de calcul de type SPMD (Single Program Multiple Data) dans lequel la quantité de thread est fixée à la compilation, typiquement avec un seul thread d'exécution par processeur.
Pour implémenter le parallélisme, UPC étend la norme C ISO 99 avec les concepts suivants:
Le langage UPC est issu des expériences avec trois autres langages antérieurs qui proposaient des extensions parallèles au C ISO 99 (AC, Split-C, and Parallel C Preprocessor (PCP)). UPC n'est pas un simple agrégat de ces trois langages, mais plutôt une tentative de synthèse des meilleures caractéristiques de chacun. UPC combine les avantages du paradigme de la programmation à mémoire partagée, du contrôle de la disposition des données et des performances du paradigme de programmation par échange de messages.
Support par les compilateurs.
UPC a été implémenté dans certains compilateurs commerciaux et de recherche, dont :

</doc>
<doc id="621044" url="http://fr.wikipedia.org/wiki?curid=621044" title="LSE (langage de programmation)">
LSE (langage de programmation)

LSE est un langage de programmation conçu au début des années 1970 par une équipe de Supélec sous la direction d'Yves Noyelle. À l'instar du BASIC, c'est un langage destiné aux débutants en programmation ; il possède une syntaxe francophone.
Histoire.
LSE est le résultat d'une évolution d'un langage plus ancien, le LSD, conçu lui aussi à Supélec.
Son sigle avait initialement deux significations :
auxquelles sont venues se joindre, parmi bien d'autres :
LSE doit sa diffusion à sa mise à disposition par le ministère de l'Éducation nationale français sur les ordinateurs destinés aux lycées, jusqu'à l'arrivée des PC et compatibles, lesquels n'en ont pas été équipés. Le langage d'origine supportait les procédures (contrairement au BASIC). 
Le langage a été révisé en 1983 par Jacques Arsac, pour enfin intégrer la notion de boucle explicite indispensable à toute bonne programmation structurée, et se débarrasser définitivement de son « ALLER EN » (goto). À noter, l'introduction des exceptions.
Cela n'a pas empêché LSE de sombrer rapidement dans l'oubli à la suite de l'abandon de celui-ci par le gouvernement français. Il existe cependant une petite communauté d'utilisateurs et le langage a fait l'objet d'une révision proposée par Luc Goulet (LSE2000) qui reprend en bonne partie les propositions de 1983 et inclut des améliorations. Notamment elle ajoute au langage la prise en charge de la programmation orientée objet et aspect. Un wikilivre décrit la proposition LSE-2000.
Aspects politiques ?
En fait, les ambitions pédagogiques annoncées n'étaient pas sans arrières-pensées politiques sur la place de la France (et de son industrie informatique) dans le monde, comme le montre le texte suivant, remis au ministère en 1982 par l'EPI (association d'enseignants en informatique) :
Exemples de programme.
Anagramme récursive.
Exemple extrait du papier de Jacques Arsac sur LSE83 :
Voir aussi.
Lien externe.
Compilateur PhoenixLSE (LSE2000)

</doc>
<doc id="360456" url="http://fr.wikipedia.org/wiki?curid=360456" title="RPL">
RPL

Le RPL est un langage de programmation procédural inventé par Hewlett-Packard en 1984 pour ses calculatrices (HP-28, 48, 49).
Origine du nom.
Le seul nom commercial du langage est RPL, et, bien que la transcription officielle d'HP soit « "ROM-based Procedural Language" », de nombreux utilisateurs l'ont traduit par « "Reverse Polish Lisp" » (« "Lisp polonais inversé" ») en raison des ascendants de ce langage : le LISP et le FORTH. Il dérive des langages Forth (langage pour machines de 4 génération) et Lisp, dont le nom signifie « LISt Processor ». Le RPL utilise la notation polonaise inverse.
Fonctionnement.
Ce langage utilise une pile et est pourvu des instructions classiques de boucles et tests. (), qui permet de faire une réelle programmation, similaire au Basic
Évolution.
Le langage RPL/2 est une version améliorée du langage originel disponible sur la plupart des systèmes d'exploitation actuels : tous Unix (Posix 2001 ou SysV), OS/2 et eComStation, Windows avec Interix ou Cygwin.

</doc>
<doc id="239648" url="http://fr.wikipedia.org/wiki?curid=239648" title="PureBasic">
PureBasic

PureBasic est un langage de programmation de type BASIC compilé. La version actuelle stable est la 5.11.
Plusieurs points le caractérisent :
PureBasic possède un jeu de commandes étendues (plus de 1400 commandes internes) auxquelles s'ajoute un accès simplifié à une grande partie de l'API du système d'exploitation. Le programmeur peut appeler les commandes de l'API de Windows, de Linux ou Mac OS directement comme s'il s'agissait des commandes internes à PureBasic, sans avoir à les déclarer au préalable (ainsi que les constantes). Rien de mieux qu'un exemple pratique pour illustrer ceci. Comparons un programme simple en visual basic avec son équivalent en PureBasic : comment obtenir le chemin du répertoire Windows.
Description.
Caractéristiques.
PureBasic gère de nombreux types :
PureBasic supporte de nombreuses fonctionnalités :
PureBasic permet de créer :
Bibliothèques.
Pour information, voici la liste officielle des bibliothèques PureBasic : 
Vous pouvez bien sûr créer vos propres bibliothèques en langage C ou en assembleur, ou encore directement en PureBasic grâce à un utilitaire développé par un utilisateur de PureBasic (Tailbite).
Exemples.
Cette simple ligne de code PureBasic créera un exécutable autonome minuscule de 4,50 Ko (4 608 octets) pour Windows. 
Et ce qui suit est un court mais parfait exemple d'un programme fonctionnel avec PureBasic. La somme des nombres saisis par l'utilisateur est affichée automatiquement. Ce programme montre comment créer une fenêtre, des gadgets supplémentaires, ainsi que la gestion des événements et un calcul mathématique simple. Ce code compile dans un exécutable autonome de 14,5 Ko (14 848 octets) qui peut être utilisé sur n'importe quel PC équipé de Windows 95 au serveur 2003 de Windows en passant par Windows XP, Vista ou Windows 7. 
Outils.
Moebius.
Moebius est un outil open source créé par Progi1984 qui permet de créer à partir de code Purebasic une userlib, sous Windows et Linux.
Lien : http://code.google.com/p/moebius-pb/Lien HS
Tailbite.
Tailbite est un outil créé par ElChoni qui permet de créer à partir de code Purebasic une userlib, uniquement sous Windows.
Lien : http://www.tailbite.com
Visual designer.
L'éditeur visuel de PureBasic (concepteur d'interfaces graphiques utilisateur) a été créé pour le langage de programmation PureBasic et est bien sûr développé en PureBasic.
MADLib.
MADLib est une bibliothèque (UserLib) de fonctions, pour PureBasic. Elle a été compilé par l'utilitaire Tailbite. Développé par MAD.
Lien : http://sourceforge.net/projects/madlibforpb/

</doc>
<doc id="744923" url="http://fr.wikipedia.org/wiki?curid=744923" title="Syp script">
Syp script

Syp Script (Simple Yet Powerful Scripting Language, soit en français langage de script simple pourtant puissant) est un nouveau langage de programmation libre (distribué sous licence GNU/GPL), facile a apprendre, et de haut niveau.
Vous pouvez créer tout type d'applications, y compris des applications consoles, multimedia et pour le réseau en un minimum de lignes de code.
L'interpréteur Syp existe pour la plupart des systèmes d'exploitation les plus utilisés (windows, Linux et autres Unix).
Exemples.
Un grand classique...
Récupération d'une page HTML
Récupération d'un fichier sur Internet
Exécution d'un script sur Internet (programmation distribuée)

</doc>
<doc id="215356" url="http://fr.wikipedia.org/wiki?curid=215356" title="Query by Example">
Query by Example

Query by Example (abr. QBE, en français "interrogation par l'exemple"), est un type d'interface utilisateur servant à effectuer des recherches dans des bases de données relationnelles. Le principe d'une interface QBE est que l'utilisateur présente un "exemple" du résultat de recherche attendu - sous forme d'une matrice, puis le soumet au SGBD. Celui-ci recherchera alors toutes les données qui correspondent à cet exemple. Les tables de la base de données sont présentées à l'écran, et l'utilisateur peut les manipuler en vue de créer l'exemple.
QBE a été inventé par Moshe Zloof pour le compte de IBM, en 1977.
Particularités.
Avec ce système le résultat prime sur les moyens de mise en œuvre. Avec QBE, il ne s'agit pas, pour l'utilisateur, ni le développeur, d'apprendre un langage de requêtes, mais tout simplement de définir une image de la réponse que l'on veut obtenir, pour voir figurer les données répondant à l'interrogation demandée.
Il a été inventé par Moshe Zloof pour le compte de la compagnie IBM, en 1977. Commercialisé à partir de 1978, il a connu un certain succès grâce à son introduction au sein de la première version de Paradox (1.0 pour DOS) en 1985.
QBE est dès l'origine un langage relationnel complet intégrant la division relationnelle, opération décrite dans l'algèbre relationnelle de Codd qui n'est toujours pas présente de manière simple dans les plus récentes normes SQL (SQL:2003). En revanche QBE ne permet pas la récursivité dans les requêtes, alors que la version normative SQL:1999 le permet.
Exemple.
Voici un exemple de requête QBE et son équivalent SQL :
Disponibilité.
Les systèmes de gestion de base de données suivant mettent à disposition une interface QBE:

</doc>
<doc id="762972" url="http://fr.wikipedia.org/wiki?curid=762972" title="Combined Programming Language">
Combined Programming Language

CPL (Combined Programming Language) était un langage de programmation développé conjointement par le "Laboratoire de Mathématiques (Mathematical Laboratory)" de l'Université de Cambridge et lUnité d'Informatique (Computer Unit)" de l'Université de Londres au cours des années 1960. 
Cette collaboration est à l'origine du mot "Combined" dans le nom final du langage (qui était originellement "Cambridge Programming Language"). En 1963 il fut mis en place sur l'ordinateur Titan de Cambridge et l'ordinateur Atlas de Londres.
Il a été grandement influencé par l'ALGOL 60 mais, au lieu d'être extrêmement léger, élégant et simple, CPL était lourd, peu élégant, et complexe. Il était censé être bon à la fois pour la programmation scientifique (à la manière du FORTRAN et de l'ALGOL) et également pour la programmation commerciale (comme le COBOL). Il visait de cette manière un peu le même objectif que le PL/1 ou, plus tard, l'Ada.
CPL s'avéra trop exigeant pour les petits ordinateurs et les technologies de compilateurs de l'époque. Des compilateurs convenables furent probablement écrits à partir de 1970, mais le langage ne fut jamais populaire et semble avoir disparu dans les années 1970.
Plus tard, un langage basé sur le CPL, nommé BCPL (pour "Basic CPL", mais originellement "Bootstrap CPL"), était un langage beaucoup plus simple, visant principalement la programmation système, et particulièrement l'écriture de compilateurs. BCPL mena ensuite au langage B puis au langage C, qui reste dans les années 2010 l'un des langages les plus populaires.

</doc>
<doc id="755392" url="http://fr.wikipedia.org/wiki?curid=755392" title="Query Management Facility">
Query Management Facility

, ou QMF, est un outil développé par IBM pour DB2.

</doc>
<doc id="103552" url="http://fr.wikipedia.org/wiki?curid=103552" title="Restructured Extended Executor">
Restructured Extended Executor

Restructured Extended Executor (REXX) est un langage, qui a été inventé par Mike Cowlishaw, chercheur d'IBM. Il s'appelait initialement REX ("R"evised "EX"ecutor), mais le sigle était déjà déposé. Langage interprété procédural, il est un des seuls héritiers du PL/I, ou du moins de la syntaxe claire du PL/I. 
, en particulier "VM/ CMS", puis plus tard "MVS/ TSO" et "z/OS". 
Il dispose d'une version Open Source, fournie en standard avec certaines distributions Linux. Les interprètes REXX, tant commerciaux qu'open source, sont disponibles sur une vaste gamme de plates-formes et des compilateurs sont disponibles pour toutes les unités centrales IBM.
Sa syntaxe a été conçue dans un but essentiel de faciliter l’apprentissage et la relecture du code.
Voici par exemple un programme REXX :
Son exécution donne 
un autre exemple de programme REXX :
qui peut s'écrire également :
Son exécution donne 
Principes.
Il existe un compilateur Rexx qui permet d'obtenir à la fois des scripts plus stables dans le cas d'une gestion par version, une exécution plus rapide, et une certaine protection contre le vol ou les modifications intempestives du code source.
Dérivés.
REXX a donné deux évolutions différentes, mais restées peu utilisées car incompatibles entre elles :
Regina a davantage de succès : c'est simplement la version de REXX en logiciel libre.

</doc>
<doc id="740258" url="http://fr.wikipedia.org/wiki?curid=740258" title="Frame representation language">
Frame representation language

FRL, pour Frame representation language, est un langage de programmation inventé par Marvin Minsky.
Il repose sur la structure de donnée bénéficiant d'une structure globale standardisée appelée "frame", modèle conçu pour représenter les connaissances et permettant la réalisation de systèmes règles-faits intimement liés, selon un principe similaire aux systèmes experts, mais aussi selon le principe opposé (les données déclenchant alors les règles).

</doc>
<doc id="586605" url="http://fr.wikipedia.org/wiki?curid=586605" title="ICON">
ICON

Icon est associé à un langage de programmation de haut niveau découlant des langages SNOBOL-4, CLU et C (K&R).
C'est un langage impératif et procédural, dont la syntaxe ressemble aux langages C et Pascal (langage).
Histoire.
Icon fut créé en 1980 par Griswold (Université d'Arizona).
L'évolution d'Icon continue, sa version est actuellement la 9.
Son successeur est Unicon crée à l'Université du Nevada, qui intègre en plus une couche objet, une interface plus complète avec Unix et une interface avec SQL.
Exemples de code.
Commençons par le classique "Hello world" :
Voici un exemple de programme Icon qui lit en entrée un fichier et affiche sur la sortie standard le fichier avec les lignes numérotées :
Concepts.
ICON est un langage de haut niveau, ce qui signifie qu'il permet au programmeur d'utiliser des concepts plutôt éloignés du fonctionnement réel d'une machine. De ce fait, il propose différents mécanismes très évolués comme les générateurs ou encore l'évaluation dirigée par le but.
Les générateurs permettent, à partir d'une expression, de fournir une suite de valeurs. Par exemple :
va nous permettre de faire varier "i" de 1 à 3 puis de 3 à 1. Ou encore
permet de tester si l'une des variables "x" ou "y" a la valeur 3 ou 5
Le mécanisme de l'évaluation dirigée par le but permet de lancer une série d'opérations répétitives, sans se soucier du cas d'arrêt. Par exemple dans le cas où nous souhaiterions afficher toutes les valeurs d'un tableau "tab", nous ferions :
ICON permet certaines constructions, souvent plus connues des langages fonctionnels, mais néanmoins fort pratiques :
Voici un autre exemple pour montrer la puissance des différents opérateurs existants dans le cas du mélange d'une tableau :

</doc>
<doc id="7941" url="http://fr.wikipedia.org/wiki?curid=7941" title="Assembleur">
Assembleur

Un langage d'assemblage ou langage assembleur est, en programmation informatique, un langage de bas niveau qui représente le langage machine sous une forme lisible par un humain. Les combinaisons de bits du langage machine sont représentées par des symboles dits « mnémoniques » (du grec "mnêmonikos", relatif à la mémoire), c'est-à-dire faciles à retenir. Le programme assembleur convertit ces mnémoniques en langage machine en vue de créer par exemple un fichier objet ou un fichier exécutable.
Dans la pratique courante, le même terme "assembleur" est utilisé à la fois pour désigner le langage d'assemblage et le programme assembleur qui le traduit. On parle ainsi de « programmation en assembleur ».
Histoire.
Les programmes de l'EDSAC (1949), premier calculateur à programmes enregistrés, étaient rédigés en utilisant des mnémoniques alphabétiques d'une lettre pour chaque instruction. La traduction était alors faite à la main par les programmeurs, une opération longue, fastidieuse et entachée d'erreurs.
Le premier programme assembleur a été écrit par Nathaniel Rochester pour l'IBM 701 (le premier ordinateur commercialisé par IBM) en 1954.
Les langages d'assemblages ont éliminé une grande partie des erreurs commises par les programmeurs de la première génération d'ordinateurs, en les dispensant de mémoriser les codes numériques des instructions et de faire des calculs d'adresses. La programmation en assembleur était alors utilisée pour écrire toutes sortes de programmes.
Dans les années 1970-80, l'utilisation de l'assembleur pour écrire des applications a été très largement supplantée par l'emploi de langages de programmation de haut niveau : FORTRAN, COBOL, PL/I, etc.
Les systèmes d'exploitations ont été écrits en langage d'assemblage jusqu'à l'introduction de MCP de Burroughs, en 1961, qui était écrit en ESPOL, un dialecte d'Algol.
L'assembleur est revenu quelque peu en faveur sur les premiers micro-ordinateurs, où les caractéristiques techniques (taille mémoire réduite, puissance de calcul faible, architecture spécifique de la mémoire…) imposaient de fortes contraintes, auxquelles s'ajoute un facteur psychologique important, l'attitude « hobbyiste » des premiers utilisateurs de micro-ordinateurs, qui ne se satisfaisaient pas de la lenteur des programmes écrits avec le BASIC interprété généralement fourni avec l'ordinateur.
Des gros programmes ont été écrits entièrement en assembleur pour les micro-ordinateurs, comme le système d'exploitation DOS de l'IBM PC (environ 4000 lignes de code), et la tableur Lotus 1-2-3 (son rival Multiplan, qui existait déjà sous CP/M, était écrit en C). Dans les années 1990, c'était aussi le cas pour la plupart des jeux pour consoles vidéo.
Particularités de l'assembleur.
Un langage spécifique à chaque processeur.
Le langage machine est le seul langage qu'un processeur puisse exécuter. Or chaque famille de processeurs utilise un jeu d'instructions différent.
Par exemple, un processeur de la famille x86 reconnaît une instruction du type
En langage assembleur, cette instruction est représentée par un équivalent plus facile à comprendre pour le programmeur :
(10110000 = movb %al
01100001 = $0x61)
Ce qui signifie : « écrire le nombre 97 (la valeur est donnée en hexadécimal : 61 = 97) dans le registre AL ».
Ainsi, le langage assembleur, représentation exacte du langage machine, est spécifique à chaque architecture de processeur. De plus, plusieurs groupes de mnémoniques ou de syntaxes de langage assembleur peuvent exister pour un seul ensemble d'instructions, créant ainsi des macro-instructions.
Désassemblage.
La transformation du "code assembleur" en langage machine est accomplie par un programme nommé assembleur. L'opération inverse, à savoir retrouver l'assembleur équivalent à un morceau de code machine, porte un nom : il s'agit de "désassemblage".
Contrairement à ce que l'on pourrait penser, il n'y a pas toujours de correspondance un à un (une bijection) entre le code assembleur et le langage machine. Sur certains processeurs, le désassemblage est donc impossible à réaliser de façon certaine. L'impossibilité d'un désassemblage peut avoir diverses raisons : usage de code auto-modifiant, instructions de taille variables, impossibilité de faire la différence entre code et données, etc.
Qui plus est, de nombreux éléments présents dans un code assembleur sont perdus lors de sa traduction en langage machine. Lors de la création du code en assembleur, le programmeur peut affecter des noms aux positions en mémoire, commenter son code, utiliser des macro-instructions ou utiliser du code généré sous conditions au moment de l'assemblage. Tous ces éléments sont réduits lors de l’assemblage à ce qui est strictement nécessaire pour la machine et n'apparaissent donc pas clairement lors du désassemblage : par exemple, une position en mémoire n’est repérée que par son adresse numérique ou par un offset.
Instructions machine.
Certaines opérations fondamentales sont disponibles dans la plupart des jeux d'instructions.
Et on trouve des instructions spécifiques avec une ou quelques instructions pour des opérations qui auraient dû en prendre beaucoup. Exemples :
Directives du langage assembleur.
En plus de coder les instructions machine, les langages assembleur ont des directives supplémentaires pour assembler des blocs de données et affecter des adresses aux instructions en définissant des étiquettes ou labels.
Ils sont capables de définir des expressions symboliques qui sont évaluées à chaque assemblage, rendant le code encore plus facile à lire et à comprendre.
Ils ont habituellement un langage macro intégré pour faciliter la génération de codes ou de blocs de données complexes.
Exemples simples.
Voici quelques exemples simples :
Exemples simples, syntaxe Intel x86.
Voici les mêmes exemples, avec quelques différences :
Usage du langage assembleur.
Il y a des débats sur l'utilité du langage assembleur. Dans beaucoup de cas, des compilateurs-optimiseurs peuvent transformer du langage de haut niveau en un code qui tourne aussi efficacement qu'un code assembleur écrit à la main par un très bon programmeur, tout en restant beaucoup plus facile, rapide (et donc moins coûteux) à écrire, à lire et à maintenir.
L'efficacité était déjà une préoccupation dans les années 1950, on en trouve trace dans le manuel du langage FORTRAN (sorti en 1956) pour l'ordinateur IBM 704:
" Object programs produced by Fortran will be nearly as efficient as those written by good programmers."
Les compilateurs ayant entre-temps fait d'énormes progrès, il est donc évident que l'immense majorité des programmes sont maintenant écrits en langages de haut niveau pour des raisons économiques, le surcoût de programmation l'emportant très largement sur le gain résultant de l'amélioration espérée des performances.
Cependant, il reste quelques cas très spécifiques où l'utilisation de l'assembleur se justifie encore :
Certains compilateurs transforment, "lorsque leur option d'optimisation la plus haute n'est pas activée", des programmes écrits en langage de haut niveau en code assembleur, chaque instruction de haut niveau se traduisant en une série d'instructions assembleur rigoureusement équivalentes et utilisant les mêmes symboles ; cela permet de voir le code dans une optique de débogage et de "profilage", ce qui permet de gagner parfois beaucoup plus de temps en remaniant un algorithme. En aucun cas ces techniques ne peuvent être conservées pour l'optimisation finale.
La programmation des systèmes embarqués, souvent à base de microcontrôleurs, est une « niche » traditionnelle pour la programmation en assembleur. En effet ces systèmes sont souvent très limités en ressources (par exemple un microcontrôleur PIC 16F84 est limité à 1024 instructions de 14 bits, et sa mémoire vive contient ). et requièrent donc une programmation de bas-niveau très optimisée pour en exploiter les possibilités. Toutefois, l'évolution du matériel fait que les composants de ces systèmes deviennent de plus en plus puissants à un coût et à une consommation électrique constants, l'investissement dans une programmation « tout assembleur » beaucoup plus coûteuse en heures de travail devient alors un non-sens en termes d'efforts. Typiquement, la programmation en assembleur est beaucoup plus longue, plus délicate (car le programmeur doit prendre en compte tous les micro-détails du développement dont il s'abstient en langage évolué) et donc considérablement plus coûteuse que la programmation en langage de haut niveau. Il ne faut donc la réserver qu'aux situations pour lesquelles on ne peut pas faire autrement.
Macro-assembleur.
Beaucoup d'assembleurs gèrent un langage de macros. Il s'agit de regrouper plusieurs instructions afin d'avoir un enchaînement plus logique et moins fastidieux.
Par exemple (en assembleur Microsoft MASM) :
est une macro qui affiche un caractère sous MS-DOS. On l'utilisera par exemple ainsi :
Et cela générera :
Pseudo-instructions.
Une pseudo-instruction est un type particulier de macro-instruction. Elle est prédéfinie par l'éditeur du logiciel assembleur et sa fonction est d'émuler une instruction manquante du processeur ou de faciliter l'usage d'une instruction existante. Comme la pseudo-instruction a un nom très ressemblant à celui d'une vraie instruction du processeur, il est possible à première vue de la confondre avec une de ces dernières. Par exemple, un processeur RISC peut ne pas posséder d'instruction JMP, instruction permettant de sauter à un point particulier du programme et de continuer son exécution en séquence. L'éditeur du logiciel aura dans ce cas créé à l'intention du programmeur une pseudo-instruction « JMP <paramètre> », qui sera remplacée à l'assemblage par une instruction « mov "pc", <paramètre> », "pc" étant le pointeur de l'instruction sur le point d'être exécutée. Autre exemple, une pseudo-instruction « PUSH <paramètre> » sera remplacée par un stockage de <paramètre> à l'adresse pointée par "sp" avec pré-décrémentation de celui-ci, "sp" étant le pointeur de pile du processeur.
Sur des microprocesseurs ou microcontroleurs RISC tels que ceux de la famille ARM, il n'existe pas d'instruction assembleur permettant de charger n'importe quelle constante immédiate dans un registre, quelle que soit sa valeur. La plupart des assembleurs disposent d'une pseudo-instruction permettant un tel chargement de la façon la plus efficace possible en termes de temps d'exécution, épargnant cette tâche au programmeur.
Programmation structurée en assembleur.
Support pour programmation structurée : quelques éléments de programmation structurée ont été intégrés pour encoder le flux d'exécution par Dr. H.D. Mills (), et mis en œuvre par Marvin Kessler qui a étendu l'assembleur S/360 macro avec if / else / endif et même des blocs de contrôle de flux. Cela a été un moyen de réduire ou d'éliminer l'utilisation des opérations de GOTO dans le code assembleur.

</doc>
<doc id="856805" url="http://fr.wikipedia.org/wiki?curid=856805" title="Identificateur">
Identificateur

En programmation informatique, un identificateur ou identifiant est un mot reconnu par le langage (concrètement par un compilateur ou interpréteur) qui permet, tel une étiquette, de désigner une donnée du programme : variable, constante, procédure, type
On peut distinguer les langages de programmation suivant les jeux de caractères autorisés pour l’écriture des identifiants : ASCII uniquement, jeux de caractères locaux, ou Unicode.
Langages à identifiants Unicode.
Unicode définit dans une de ses annexes, une base pour spécifier les identificateurs, tout en permettant à chaque langage de fonctionner sur des variantes de cette base.
Les langages Ada, Java, Microsoft .NET, Perl 5.16, Perl 6, StarOffice Basic sont compatibles avec des identificateurs Unicode.
Les langages Clisp, Delphi devraient/pourraient être compatibles avec des identificateurs Unicode.
Le langage Python ambitionne de pouvoir supporter des identificateurs dans des langues autres que la seule langue anglaise avec le PEP 3131 .
Règles de nommage.
Les développeurs ont parfois besoin d’exprimer les concepts qu’ils utilisent avec des mots et des symboles qui leur sont familiers, en particulier pour les non anglophones.
Par ailleurs, avec l’usage croissant d’Internet, l’usage d’Unicode se répand. En programmation, il est présent :
Les langages s’interfaçant avec Java et .NET nécessitent le support d’identifiants Unicode, pour être interopérables. Sans cela, une portion de l’espace de noms ne serait pas accessible.
Relation avec les métadonnées.
Dans les langages de balisage, mais également dans tous les types de ressources informatiques et tous les types d’application, on peut employer des métadonnées pour décrire les données. L’identifiant est l’un des éléments couramment employés pour l’accès aux ressources (URI). L’identifiant peut faire l’objet de règles de nommage.

</doc>
<doc id="414797" url="http://fr.wikipedia.org/wiki?curid=414797" title="DarkBASIC">
DarkBASIC

DarkBasic est un langage de programmation orienté 3D servant à la création de jeux vidéo. Dérivé du BASIC, il permet de réaliser tout type de jeux de façon assez simple. Mais attention, ce n'est pas un logiciel "pointer et cliquer". Ainsi, pour pouvoir exprimer sa créativité, l'utilisateur aura besoin d'apprendre un langage de programmation. Ce langage a été conçu pour être facilement appris, et une rubrique d'aide complète est proposée avec tous les éditeurs de Dark Basic.
Le logiciel se compose d'un IDE (environnement de développement), de quelques exemples de jeux, ainsi que d'un manuel contenant la description et la syntaxe de chaque commande. La communauté du Dark Basic étant motivée, des éditeurs de texte à soulignement syntaxique "libres" ont vu le jour, nécessitant quand même l'installation du compilateur.
Pour réaliser les environnements (objets 3D, sols, ...) ainsi que les textures et les sons, deux solutions s'offrent à un utilisateur de Dark Basic. Il peut soit développer ses propres outils de création ou utiliser des logiciels pouvant exporter les données dans des formats compatibles avec Dark Basic.
Une nouvelle version de Dark basic, DarkBasic Professional, reprend les bases du DarkBasic original, mais tout a été repensé. C'est un moteur de jeu très puissant et facile à programmer tout en étant très flexible grâce notamment à l'ajout de DLL et de plug-ins. Les programmes ne sont plus transformés en bytecode, mais compilés en langage machine. Cette nouvelle version est mise à jour régulièrement, et une version utilisant DirectX 10 verra peut-être jour. Néanmoins, ce langage reste critiqué par sa lenteur d'exécution comparé a C++ ou a d'autre langages non spécialisés. La vitesse de traitement des données est extrêmement lente.
Jeux réalisés avec ce langage :
Distribution.
DarkBasic et DarkBasic Professional ont été distribués en France par Focus Home Interactive, sous le nom de 3D Games Creator et 3D Games Creator Pro. Il était dès lors possible de se procurer l'IDE, en version boîte, dans n'importe quel centre commercial au rayon jeux vidéo. Cependant le nombre de produit mis a disposition était relativement faible, ce qui fait qu'il est maintenant impossible de se procurer une version boîte par les circuit de distribution classique. Il est cependant possible de se procurer des exemplaires sur le marché de l'occasion, ou bien directement sur le site de l'équipe The Game Creators.
Il n'existe pas à ce jour de compilateur alternatif pour le langage DarkBasic, malgré certaines lacunes des compilateurs officiels (portabilité inexistante, consommation de ressources...). Un projet de compilateur alternatif a été lancé en 2005 par un utilisateur du DarkBasic, mais semble pour le moment en stand-by.
Communauté.
Darkbasic étant un langage essentiellement «commercial», la plus grande partie de la communauté se retrouve sur les sites des éditeurs. Concernant la communauté Française, celle-ci se regroupait sur le forum du site officiel de Focus Home Interactive. Cependant, ce forum, bien que mine d'information, ne semble aujourd'hui plus disponible.

</doc>
<doc id="904004" url="http://fr.wikipedia.org/wiki?curid=904004" title="Scala (langage)">
Scala (langage)

Scala est un langage de programmation multi-paradigme conçu à l'École polytechnique fédérale de Lausanne (EPFL) pour exprimer les modèles de programmation courants dans une forme concise et élégante. Son nom vient de l'anglais "Scalable language" qui signifie à peu près « langage adaptable » ou « langage qui peut être mis à l'échelle ». Il peut en effet être vu comme un métalangage.
Scala intègre les paradigmes de programmation orientée objet et de programmation fonctionnelle, avec un typage statique. Il concilie ainsi ces deux paradigmes habituellement opposés (à de rares exceptions près, telle que le langage OCaml) et offre au développeur la possibilité de choisir le paradigme le plus approprié à son problème.
Il est prévu pour être compilé en bytecode Java (exécutable sur la JVM), ou .Net. Ces deux plateformes sont supportées officiellement par l'EPFL.
Si on souhaite l'utiliser exclusivement avec la JVM, il est alors possible d'utiliser les bibliothèques écrites en Java de façon complètement transparente. Ainsi, Scala bénéficie de la maturité et de la diversité des bibliothèques qui ont fait la force de Java depuis une dizaine d'années. De plus, il est possible d'invoquer du code écrit en Scala à partir de programmes écrits en Java ce qui facilite la transition de Java à Scala.
Les développeurs habitués à un seul paradigme (par exemple ceux ayant utilisé principalement Java qui, lui, repose sur la programmation orientée objet) peuvent trouver ce langage déroutant et difficile car il nécessite l'apprentissage de concepts différents si on veut pouvoir exploiter tout son potentiel. Néanmoins, il est tout à fait possible de l'utiliser dans un premier temps comme remplaçant de Java, en profitant alors de sa syntaxe épurée, puis d'utiliser les différents "nouveaux" concepts au fur et à mesure de leur apprentissage.
Exemple Hello World.
Le programme Hello world écrit en Scala, à la manière de Java :
ou bien simplement sans déclaration de classe et de méthode statique, avec un simple objet singleton :
Un de ces deux exemples peut être enregistré dans un fichier codice_1 et compilé en ligne de commande :
codice_2
puis exécuté :
codice_3
En utilisant Scala à la manière d'un langage de script :
est enregistré dans un fichier codice_4, puis exécuté directement en ligne de commande :
codice_5
Le code source peut aussi être fourni directement à l'interpréteur avec l'option -e :
codice_6

</doc>
<doc id="656050" url="http://fr.wikipedia.org/wiki?curid=656050" title="Sequential function chart">
Sequential function chart

Le Sequential function chart (SFC) est un langage graphique de programmation des Automates Programmable Industriel défini dans la norme CEI 61131-3.
Ce langage est une interprétation assez libre et plus permissive du grafcet dont il est inspiré : le grafcet est dédié à la spécification, alors que SFC est plus appliqué à la programmation.

</doc>
<doc id="347391" url="http://fr.wikipedia.org/wiki?curid=347391" title="Bytecode">
Bytecode

Le bytecode (signifiant en anglais, « code octal », en référence à l'octet informatique) est un code intermédiaire entre les instructions machines et le code source, il n'est pas directement exécutable. Le bytecode peut être créé à la volée et résider en mémoire (compilation à la volée, JIT en anglais) ou bien résider dans un fichier, généralement binaire qui représente le programme, tout comme un fichier de code objet produit par un compilateur.
Il est appelé "bytecode" du fait de son format où chaque instruction est codée en binaire.
Puisque c'est un code qui n'est pas exécutable directement par un processeur (à l'exception de certains processeurs gérant le bytecode Java nativement), il est utilisé par les créateurs de langages de programmation en guise de code intermédiaire réduisant la dépendance vis-à-vis du matériel et facilitant son interprétation sur plusieurs architectures.
Certains compilateurs, comme LLVM, et langages de scripts, comme SmallTalk, Java ou certaines implémentations de Ruby (telles que JRuby, Ruby.NET ou SmallRuby) utilisent le "bytecode" comme représentation intermédiaire avant la transformation en code machine vers l'architecture cible (x86, amd64, ARM, MIPS, PowerPC, etc...) 
Certains systèmes, appelés « traducteurs dynamiques » ou « compilateurs à la volée » ("JIT (just-in-time) compilers" en anglais), traduisent le "bytecode" en code machine au fur et à mesure de l’exécution, cela permet d’accélérer l’exécution sur les boucles ou les fonctions appelées plusieurs fois tout en évitant de stocker sur disque ou de transférer via les réseaux des données précompilées. Cette technique est notamment utilisée dans le langage Java et dans les émulateurs de systèmes (ordinateurs ou consoles de jeu par exemple), retranscrivant les instructions d'un langage machine à un autre et plus généralement d'une architecture matérielle à une autre.
Un programme à base de "bytecode" est exécuté par un interpréteur appelé machine virtuelle, car elle exécute le code tout comme un microprocesseur. L'avantage est la portabilité : le même "bytecode" peut être exécuté sur diverses plates-formes ou architectures pour lesquelles un interpréteur existe. Un programme sous forme de "bytecode" peut donc être transmis d'une machine à une autre, et être interprété puis exécuté sans modification de celui-ci par différents types d'architectures matérielles. L'avantage est le même que pour les scripts, qui sont directement interprétés (et non compilés en "bytecode"). Cependant, le "bytecode" est plus concret, plus compact et plus facile à manipuler qu'un script, prévu pour être intelligible par l'homme. Les performances des interpréteurs de "bytecode" sont généralement bien meilleures que celles des interpréteurs de scripts pour ces raisons.
Pour bénéficier de ces avantages, aujourd'hui de nombreux langages interprétés sont en fait compilés en "bytecode" avant d'être exécutés par un interpréteur. C'est le cas par exemple de PHP (lorsqu'il est utilisé pour des applications), de Tcl, de Python. Un programme Java est habituellement transmis sous forme de "bytecode" à une machine hôte qui utilisera une compilation à la volée pour traduire le "bytecode" en code machine avant exécution. Les implémentations actuelles de Perl et de Ruby utilisent non pas du "bytecode", mais une structure en arbre qui se rapproche de la représentation intermédiaire des compilateurs.
Les "p-Codes" diffèrent des "bytecodes" par le codage de leurs opérations, qui peut être de plusieurs octets avec une taille variable, tout comme les "opcodes" de nombreux processeurs. Ils ont un plus haut niveau descriptif, comme « afficher cette chaine de caractères » ou encore « effacer l'écran ». Le BASIC et quelques versions de Pascal utilisent un "p-Code".

</doc>
<doc id="176973" url="http://fr.wikipedia.org/wiki?curid=176973" title="Pro*C">
Pro*C

Le Pro*C est un outil permettant d'inclure des commandes SQL dans un programme C. Il s'agit en fait d'un précompilateur : le code source Pro*C est traduit en source C avec des appels aux bibliothèques ORACLE.
La compilation complète se fait donc en plusieurs étapes:
Un point important : lors de la première phase (précompilateur Pro*c), une connexion au serveur ORACLE est effectuée afin de valider les requêtes SQL du code Pro*C.
Exemple.
Exemple de syntaxe Pro*C :
codice_1

</doc>
<doc id="930169" url="http://fr.wikipedia.org/wiki?curid=930169" title="Microsoft Macro Assembler">
Microsoft Macro Assembler

Le logiciel <dfn lang="en">Microsoft Macro Assembler</dfn> (Macro Assembleur de Microsoft, plus connu sous l'acronyme <dfn>MASM</dfn>) est un assembleur pour la famille de processeurs x86. Il fut à l'origine développé par Microsoft pour le développement de leur système d'exploitation MS-DOS.
MASM supporte une grande variété de macros aidant à la programmation en langage assembleur ainsi que des idiomes de programmation structurée, incluant des constructions de haut niveau pour les boucles, les appels de procédures, les branchements, etc. ce qui fait de MASM un assembleur à programmation de haut niveau. Les dernières versions de MASM ont la possibilité de produire des programmes pour le système d'exploitation Windows. MASM fut un des rares outils de développement de Microsoft pour lequel il n'y eut pas de versions 16 et 32 bits séparées.
Compétition entre assembleurs.
Dans les premières années de la décennie 1990 d'autres assembleurs alternatifs prirent une certaine part de marché à MASM, parmi lesquels TASM de Borland, le partagiciel A86 et NASM vers la fin de la décennie. Toutefois, deux évènements à la fin des années 1990 permirent à MASM de garder un solide support de la communauté des programmeurs en assembleur : en premier lieu, MASM, qui était jusqu'alors un logiciel commercial, fut distribué gratuitement comme partie du "Driver Development Kit" ou DDK. Dans un deuxième temps, le "pack" MASM32 maintenu par Steve Hutchesson ainsi que les tutoriaux d'Iczelion apparurent permettant de programmer directement et relativement aisément des applications 32 bits fonctionnant sous Windows. Ces deux événements combinés assurèrent à MASM sa continuité dans le temps.
MASM reste encore aujourd'hui un assembleur phare de la communauté des programmeurs en assembleur pour la plateforme Win32, mais d'autres assembleurs comme GAS, NASM, TASM, FASM, GoAsm, RosAsm ou HLA rassemblent chacun une communauté importante.
Versions de MASM.
Bien que MASM ne soit plus un produit commercial, Microsoft continue à assurer son support du fait d'une utilisation assez importante du langage assembleur en développement interne chez Microsoft. Depuis que Microsoft a arrêté la vente de MASM, de nombreuses mises à jour ont été produites pour la lignée de MASM 6.x (la dernière mise à jour de cette lignée est la version 6.15 qui était incluse dans le "Visual C++ 6.0 Processor Pack"). MASM 7.0 fut inclus avec Visual C++ .NET 2002, MASM 7.1 avec Visual C++ .NET 2003 et MASM 8.0 avec Visual C++ .NET 2005 (cette dernière version est la première à pouvoir assembler du code 64 bits).
Pour les versions de MASM incluses avec Visual C++, l'exécutable de MASM s'appelle "ml.exe" et se situe dans le répertoire "bin". La version 64 bits de MASM incluse avec Visual C++ 2005 se nomme "ml64.exe" et se situe dans le même répertoire. La documentation de MASM pour ces versions est incluse avec la documentation de Visual C++.
Projets reconnaissant MASM.
De nombreux projets reconnaissant MASM ont vu le jour. Ainsi, des environnements de développement intégrés permettent un développement plus aisé avec MASM (qui s'utilise habituellement en ligne de commande) parmi lesquels Qedit, Radasm ou WinAsm Studio. On notera aussi des débogueurs comme OllyDbg qui reconnaît la syntaxe MASM, ou des désassembleurs comme IDA.
De nombreux forums ou sites internet proposent des codes sources, de la documentation ou de l'aide concernant cet assembleur, qui reste un assembleur de référence.
La prise en charge officielle de MASM par Microsoft se résume aujourd'hui à ajouter des instructions lorsque de nouveaux processeurs voient le jour et à améliorer la prise en charge du 64 bits.

</doc>
<doc id="955582" url="http://fr.wikipedia.org/wiki?curid=955582" title="Ponie">
Ponie

Ponie, acronyme de "Perl On a New Internal Engine", était un projet démarré par la société Fotango pour porter Perl 5 au-dessus de la machine virtuelle Parrot. Au départ gérée par Arthur Bergman, Ponie a ensuite été développé par Nicholas Clark, actuel pumpking de Perl 5.8, qui en a profité pour effectuer un travail de nettoyage remarquable dans les entrailles de Perl. 
Le projet Ponie a été interrompu en fin août 2006. Ses effets, le nettoyage de Perl 5, ont été bénéfiques même si le but escompté n'a pas été atteint. D'autres stratégies sont explorées pour l'exécution de code Perl 5 au-dessus de Perl 6.

</doc>
<doc id="951227" url="http://fr.wikipedia.org/wiki?curid=951227" title="Pugs">
Pugs

Pugs est une mise en œuvre expérimentale de Perl 6 en langage Haskell, et utilisant les spécificités les plus avancée de GHC.
Selon le dorsal de génération et d'exécution de code, Pugs peut être considéré soit comme un compilateur, soit comme un interprète.
Les développeurs de Pugs se désignent comme "lambda camels" (chameaux lambda) pour marquer leur double appartenance : le chameau est la mascotte du langage Perl, et le lambda (λ) est une référence au lambda calcul qui est à la base de la programmation fonctionnelle.
La distribution Pugs contient du code source de diverses origines et donc sous différentes licences Open Source :
La licence artistique 2.0b5, la licence du Glasgow Haskell Compiler [http://www.haskell.org/ghc/license.html], la GPL 2, la LGPL 2.1 et la licence MIT.
Conformément à la tradition du monde Perl, Pugs tourne sur de nombreuses plates-formes logicielles dont UNIX, Mac OS X et Windows.
Vue d'ensemble.
Le projet Pugs a pour but de bootstrapper Perl 6 en mettant en œuvre la totalité de la spécification de Perl 6, détaillée à Synopses. Il est écrit en Haskell et utilise les fonctionnalités les plus récentes du Glasgow Haskell Compiler.
<br>Ainsi la mise en œuvre de la mémoire transactionnelle logicielle pour la programmation concurrente qui permet d'exploiter au mieux les architectures multi cœur ou multiprocesseurs.
<br>Ou les types algébriques de données généralisés.
Pugs inclut deux exécutables principaux :
Numéros de version.
Les numéros de version de Pugs convergent vers 2 × "π" (cela rappelle TeX et METAFONT, qui utilisent un système similaire); 
Chaque chiffre significatif de la version mineure représente une étape franchie avec succès. Les étapes anticipées sont :
La version actuelle de Pugs est la 6.2.13.11.
Compatibilité avec Perl 5.
Depuis la version 6.2.6, Pugs peut inclure la machine virtuelle Perl 5 et donc utiliser les modules CPAN. 
Le JAPH ci-dessous montre l'utilisation de Perl DBI, un module populaire, pour gérer une base de données SQLite :
Modèle de développement.
Pugs est un projet open source très productif.
Démarré en 2005, ses progrès ont été rapides pour les raisons suivantes :

</doc>
<doc id="271474" url="http://fr.wikipedia.org/wiki?curid=271474" title="Clips (langage)">
Clips (langage)

CLIPS "(C Language Integrated Production System)" est un environnement et un langage de programmation créés en 1985, faisant partie du paradigme des langages déclaratifs et logiques.
Il s'agit avant tout d'un outil de construction de systèmes experts à base de règles et d'objets. Ses caractéristiques notables sont:
Historique.
Les origines de CLIPS se situent en 1984 au Johnson Space Center de la NASA. À cette époque, les outils de systèmes expert étaient développés en LISP, ce qui les rendait incompatibles avec les contraintes de le NASA. En effet, LISP n'était pas disponible pour toutes les architectures, ne s'intégrait pas bien avec les autres langages de programmation ; les coûts des outils LISP étaient élevés, et enfin le langage n'offrait pas les performances nécessaires en termes de rapidité d'exécution. Un langage tel que C semblait un bon candidat pour pallier ces problèmes. Malheureusement, le temps et le coût d'adaptation des outils existants annoncés par les fournisseurs étaient bien trop élevés. La section d'intelligence artificielle décida alors de développer son propre outil de système expert en C.
Un prototype de CLIPS apparut au printemps 1985, avec une syntaxe fortement inspirée de l'outil de système expert ART développé par Inference Corporation afin de le rendre compatible avec les autres outils existants. La version 1.0 de CLIPS prouva la faisabilité du projet, et seulement un an plus tard, en 1986, sortit la version 3.0 qui fut rendue disponible en dehors de la NASA.
Exemple.
Prenons tout d'abord les faits suivants :
Que nous traduisons en CLIPS :
Et la règle suivante :
Qui se traduit en CLIPS par:
Avant la première exécution la base de faits contient donc ceci :
En lançant la résolution, la règle est appliquée une fois avec les faits 1 et 2 :
La base de fait contient maintenant ceci :
La règle ne peut plus être appliquée à aucun fait, l'exécution s'arrête. Nous remarquons qu'un seul nouveau fait a été introduit dans la base de faits (Socrate est mortel). En effet, on ne peut pas en déduire que "Socrate est un chien", comme dans le fameux sophisme.
Licence.
CLIPS et sa documentation sont dans le domaine public. 
Plus précisément, les sources, les exécutables et la documentation téléchargée
à partir de la page de téléchargement de CLIPS sont soumis à la présente licence :
La permission est accordée, gratuitement, à tout personne obtenant une copie du logiciel et de sa documentation associée (le ""Logiciel""), d'utiliser le "Logiciel" sans restriction, incluant sans aucune limitation, le droit d'utiliser, copier, modifier, inclure, publier, distribuer et/ou vendre des copies du "Logiciel", et de permettre à ceux à qui le Logiciel est fourni d'en faire autant.
Attention, au 11 septembre 2010 à 21h52, la page http://www.ghgcorp.com/clips/Download.html n'existe plus.

</doc>
<doc id="510228" url="http://fr.wikipedia.org/wiki?curid=510228" title="OpenLaszlo">
OpenLaszlo

OpenLaszlo est une plateforme de développement pour des applications web. Elle permet de créer des applications riches (Rich Internet Applications) comprenant une interface riche en fonctionnalités (drag & drop, onglet, menu déroulant, animation etc.) tout en offrant un déploiement facilité par le biais du navigateur web. OpenLaszlo est compatible avec la majorité des navigateurs web et des systèmes d'exploitation disposant soit d'un plugin Flash, soit simplement du support Javascript. OpenLaszlo se base sur une grammaire XML appelée LZX.
Quelques compléments à propos de LZX et du serveur OpenLaszlo :
Historique du projet.
OpenLaszlo était originellement appelé Laszlo Presentation Server (LPS). Le développement de LPS a débuté originellement en automne 2001. Les versions de démonstration sont mises sur pieds pour acquérir des partenaires, courant 2002. Plusieurs d'entre eux ont déployé des applications. La première version officielle sort dans le début 2002.
En octobre 2004, Laszlo Systems libère l'ensemble du code de Laszlo Presentation Server sous licence "CPL open source license" et démarre le projet OpenLaszlo. En 2005, parallèlement à la sortie de la version 3.0, le nom de Laszlo Presentation Server est changé en OpenLaszlo.
Jalons :
Déploiement.
Une application Laszlo peut être déployée comme un servlet Java traditionnel. Celui-ci est compilé et renvoyé au navigateur dynamiquement. Ce procédé exige que le serveur OpenLaszlo tourne sur le serveur web.
Une autre manière de faire est de compiler une application LZX en un binaire SWF ou en HTML/AJAX. Cette méthode est appelée le déploiement SOLO. Les applications déployées de la sorte ont certaines fonctionnalités en moins, bien que les dernières versions ont essayé de remédier à ce problème.
Licence.
OpenLaszlo est proposé sous Common Public License, érigée par IBM.

</doc>
<doc id="358122" url="http://fr.wikipedia.org/wiki?curid=358122" title="Iota (langage)">
Iota (langage)

Le langage Iota est un langage de programmation Turing-complet conçu par Chris Barker. Il possède seulement deux symboles.

</doc>
<doc id="1006531" url="http://fr.wikipedia.org/wiki?curid=1006531" title="Alef (langage de programmation)">
Alef (langage de programmation)

Le langage de programmation Alef a été conçu par Phil Winterbottom des Bell Labs dans le cadre du système d'exploitation Plan 9.
Lors une présentation en février 2000, Rob Pike déclara : .

</doc>
<doc id="8234" url="http://fr.wikipedia.org/wiki?curid=8234" title="COBOL">
COBOL

COBOL est un langage de programmation de troisième génération créé en 1959 (officiellement le 18 septembre 1959). Son nom est l'acronyme de qui révèle sa vocation originelle : être un langage commun pour la programmation d'applications de gestion.
Le langage COBOL était de loin le langage le plus employé des années 1960 à 1980, et reste très utilisé dans des grandes entreprises, notamment dans les institutions financières qui disposent (et développent encore) de nombreux logiciels et applications en COBOL.
Histoire et spécifications.
Le COBOL a initialement été créé en 1959 par le "Short Range Committee", un des trois comités proposés à une rencontre au Pentagone en mai 1959 organisée par Charles Phillips du département de la défense des États-Unis. Le comité a été formé pour recommander une approche à court terme pour un langage commun, indépendant des constructeurs, pour les applications de gestion de l'administration américaine. Il était constitué de membres représentant six constructeurs d'ordinateurs et trois agences gouvernementales. Les six constructeurs informatiques étaient Burroughs Corporation, IBM, Minneapolis-Honeywell, RCA, Sperry Rand, et Sylvania Electric Products. Les trois agences du gouvernement étaient le "US Air Force", le "David Taylor Model Basin", et l'"Institut national des standards". Ce comité était présidé par un membre du NBS. Des comités à moyen et long terme ont également été proposés au Pentagone. En revanche, même si le premier a été fondé, il n'a jamais été opérationnel, et le dernier n'a jamais été fondé. En fin de compte, un sous-comité du "Short Range Committee" a été formé avec six membres : 
Ce sous-comité a terminé les spécifications de COBOL fin 1959. Elles étaient largement inspirées par le langage FLOW-MATIC inventé par Grace Hopper, surnommée « la mère du langage COBOL »,
et par le langage "Commercial Translator" (COMTRAN) d'IBM, inventé par Bob Bemer.
Ce langage ayant été conçu aux débuts de l'informatique, sa relative lourdeur rebutait nombre de programmeurs dès les années 70, ce qui a valu deux interprétations ironiques à son acronyme : "Complies Only Because Of Luck" ("fonctionne uniquement par chance") et "Completly Obsolete Business Oriented Language" ("Langage orienté gestion complètement obsolète").
Histoire des standards COBOL.
Ces spécifications furent approuvées par le comité complet, puis par le comité exécutif (CODASYL) en janvier 1960 et envoyées au bureau d'impression du gouvernement qui les édita et imprima en les nommant COBOL 60. Le langage fut développé en moins de six mois de travail, et il est toujours utilisé aujourd'hui, après plusieurs révisions standardisées par l'ANSI (American National Standards Institute), dont
Traits principaux.
La totalité des variables et des structures de données utilisées sont définies au début du programme, avant la division procédurale contenant les instructions. La manière dont sont définies les variables, c'est-à-dire les espaces de stockage temporaire, est très particulière. C'est une structure arborescente définie par une suite de lignes de code. Chaque ligne commence par un nombre qui définit le niveau d'imbrication du champ ou du groupe de variables.
Par exemple :
qui définit une structure NomPrenom contenant les champs Prenom et Nom sur 20 caractères.
Autre exemple :
qui définit un code postal de France, et qui permet d'utiliser le département sans aucun MOVE.
Comme défini dans la spécification originale, COBOL possédait déjà les nombreuses fonctionnalités qui ont fait son succès : d'excellentes capacités d'auto-documentation, des méthodes pratiques de gestion des fichiers et des types de données variés, dont le format est précisé par la clause PICTURE. Comme la plupart des autres langages de l'époque, il ne permet pas de définir de variables locales, de fonctions récursives et d'allouer de la mémoire dynamiquement.
La gestion des décimales en COBOL (nombres en virgule fixe), et la maîtrise des arrondis et des dépassements, permettent d'éviter les nombreux problèmes qui arriveraient en utilisant des nombres à virgule flottante pour les calculs financiers. Ce sont ses capacités arithmétiques en virgule fixe, notamment pour les traitements par lots où il présente d'excellentes performances, qui ont rendu le COBOL particulièrement populaire pour les traitements comptables. 
Il intègre également un générateur de rapports, défini de la même manière que les autres structures de données. Sont intégrées des fonctions de tri, de fusion et de communication. Un module optionnel permettait également une forme de communication inter-processus par file de messages.
Le parti-pris initial de définir un langage de programmation proche du langage naturel (comme pour FLOW-MATIC) devait faciliter, sinon la programmation, du moins l'audit des programmes COBOL par des gestionnaires non-informaticiens. Ce choix a eu pour conséquence une syntaxe complexe (le langage naturel n'est pas simple), avec de nombreux mots réservés, et de nombreuses options (les opérations de gestion ne sont pas simples non plus) qui valent à COBOL une réputation de verbosité, qui n'est pas forcément fondée sur des faits.
Par exemple en Cobol l'instruction
s'exprimerait, en C ou autres langages dérivés, par 
Comme d'autres langages de l'époque (par exemple Fortran 2), COBOL offrait la possibilité de modifier du code pendant l'exécution à l'aide de la fameuse instruction ALTER X TO PROCEED TO Y (altérer X pour aller vers Y). Cette possibilité dangereuse, qui transposait une technique courante de la programmation en langage machine, a été éliminée des spécifications du langage. Rendant possible la modification à la volée de l'exécution d'un programme, cette commande permettait d'outrepasser des ordres GO TO, complexifiant ainsi la maintenance.
Les versions successives du standard ont modernisé le langage, par exemple en ajoutant des structures de contrôle améliorées et le support de la programmation objet, tout en préservant au maximum la compatibilité avec les versions précédentes, de façon à éviter d'avoir à modifier l'énorme stock de programmes COBOL en service.
Le poids de l'héritage.
Le langage COBOL était de loin le langage le plus employé des années 1960 à 1980, et reste toujours en utilisation dans des grandes entreprises (en 2010), notamment dans les institutions financières qui disposent d'une vaste bibliothèque d'applications COBOL. Écrites à une époque où les octets coûtaient cher, et où l'an 2000 était encore fort loin, ces applications ont fait craindre le fameux bogue de l'an 2000. Souvent, en effet, par mesure d'économie de mémoire, les services informatiques et programmeurs avaient codé les années et les tests d'année sur 2 chiffres plutôt que sur 4. De sorte que la préparation du passage à l'an 2000 coûta au final d'énormes moyens humains, matériels et financiers. Bien que, cependant, les banques, assurances et autres institutions financières gérassent depuis très longtemps des dossiers sur 10, 20 voire 30 ans (prêts, par exemple), mais sans systématiquement, toutefois, prendre en compte dans les tests de date la notion de siècle.
En 2005, le Gartner Group estimait que 75 % des données du monde des affaires étaient traitées par des programmes en COBOL et que 15 % des nouveaux programmes développés le seraient dans ce langage. On retrouve le COBOL en 27e position dans l'Index TIOBE. Ce dernier mesure 229 langages de programmation selon leur popularité. 
Structure d'un programme en COBOL.
Un programme comporte quatre divisions. La norme COBOL-85 ne rend obligatoire que la première.
Chaque division est composée de 'sections', formées de 'paragraphes' composés de 'phrases' qui peuvent être des phrases impératives ou des clauses. Chaque phrase doit être terminée par un point.
Les six premières colonnes de chaque ligne de programme sont considérées comme une zone de commentaire, servant autrefois à numéroter les cartes perforées (en cas de chute du paquet, il suffisait de les passer sur une trieuse pour reconstituer la version correcte du programme).
La septième colonne contient un caractère de contrôle : espace pour les lignes actives, étoile pour les commentaires, tiret comme caractère de continuation.
La huitième colonne est le début des titres de paragraphes.
La douzième colonne est le début des instructions. 
Les compilateurs COBOL modernes permettent l'emploi d'un format libre qui n'impose plus le colonnage.
Exemple de programme (Bonjour !).
Écrit dans le style typique des programmes sur cartes perforées (années 1960-70), avec lignes numérotées
Note : ERASE EOS signifie « 'Erase End Of Screen' » La commande ligne 100300 a donc pour effet d'effacer l'écran.
Exemple en format libre.
Autre version du même exemple en COBOL-85 format libre :
Return codes à l'exécution.
Return code 203: vérifier l'emplacement de l'ordre d'ouverture du fichier.

</doc>
<doc id="22582" url="http://fr.wikipedia.org/wiki?curid=22582" title="Objective-C">
Objective-C

L'Objective-C est un langage de programmation orienté objet réflexif. C'est une extension du C ANSI, comme le C++, mais qui se distingue de ce dernier par sa distribution dynamique des messages, son typage faible ou fort, son typage dynamique et son chargement dynamique. Contrairement au C++, il ne permet pas l'héritage multiple mais il existe toutefois des moyens de combiner les avantages de C++ et d'Objective-C.
Aujourd'hui, il est principalement utilisé dans les systèmes d'exploitation d'Apple : Mac OS X et son dérivé iOS, basés sur la bibliothèque de classes Cocoa mais il existe aussi une bibliothèque de classes libre GNUstep sous GNU/Linux. Cocoa et GNUstep sont les successeurs de l'API OpenStep, utilisée dans les systèmes d'exploitation NeXTSTEP et OPENSTEP.
Historique.
La fin des années 1970 est marquée par la popularité naissante et rapide du langage C inventé plus tôt dans la décennie par Dennis Ritchie aux Laboratoires AT&T Bell. Cette popularité est entretenue par une autre encore plus grande, celle du système d'exploitation UNIX totalement écrit en C. À la charnière des décennies 1970-1980, la pratique courante du génie logiciel est basée sur la programmation structurée. L'implémentation de la programmation structurée est utilisée dans le but de scinder de gros programmes en des parties plus petites, de complexité moins grande et donc plus faciles à programmer. Cependant, alors que la résolution de problèmes devient de plus en plus grande et compliquée, la programmation structurée devient moins utile au fur et à mesure que de plus en plus de procédures doivent être écrites, ce qui mène à des structures de contrôle complexes et à une faible réutilisation de code. À l'époque, beaucoup voient dans l'orienté-objet une possible solution à ce problème. 
Plusieurs personnes créent alors des extensions au C pour y ajouter l'orienté-objet. C'est le cas de Bjarne Stroustrup qui développe le C++ en 1979 dans les mêmes laboratoires que ceux dans lesquels le C de Dennis Ritchie a vu le jour. La naissance de l'Objective-C arrive dans le même contexte. Brad Cox le met au point au début des années 1980. Le langage est basé sur un autre, le Smalltalk-80, et est destiné à être une couche supplémentaire au C pour permettre la création et la manipulation d'objets.
Le code compilé Objective-C s'exécute dans un environnement d'exécution (runtime) léger écrit en C, qui ajoute peu à la taille de l'application.
Le premier système d'exploitation à utiliser Objective-C fut NeXTSTEP, de la société NeXT, fondée par Steve Jobs.
Objective-C est beaucoup utilisé sur Macintosh, notamment pour les API Cocoa de Mac OS X et, plus récemment, pour le développement d'applications iPhone, le smartphone d'Apple.
Il existe également une implémentation libre du framework d'OpenStep, appelée GNUstep, qui est multiplateforme et fonctionne notamment sous GNU/Linux, Microsoft Windows et la plupart des UNIX.
Descriptif du langage.
En Objective-C, tout est objet tout comme en Smalltalk dont il s'inspire fortement. C'est donc un langage fortement orienté objet. L'héritage simple induit un arbre d'héritage avec une racine : la classe NSObject, dans le cas de Cocoa/NeXTSTEP, ou Object dans le cas de GNUstep. C'est à partir d'elle que vont dériver toutes les classes. Par exemple, un objet de classe NSString, ou NSArray, dérive de la classe NSObject (indirectement). NSMutableArray dérive de la classe NSArray, qui est donc sa superclasse. D'après certains de ses utilisateurs, c'est là que la puissance d'Objective-C apparaît : au contraire de C++ ou autres langages ne l'incluant pas, le typage faible permet de manipuler plus simplement des données.
En effet, plutôt que de devoir manipuler de nombreux types, il n'y en a que quelques-uns, par exemple dans le cas de Cocoa :
De plus, toutes les variables d'instances de classe sont par défaut protégées, et les méthodes de classe publiques. Il permet donc aux programmeurs d'avoir une programmation plus rigoureuse, tout en étant plus rapide, et en respectant les concepts de la POO. 
Un autre aspect est celui du modèle de conception KVC (Key-Value Coding), lui aussi inspiré de Smalltalk, qui définit l'accès à une variable par son nom. Par exemple, dans le cas d'une classe Personne, avec une variable d'instance Surname, de type NSString : 
Objective-C permet la création rapide d'objet NSString grâce au @"", de la même manière que le C avec les chaînes de caractères "". Les NSString sont encodés en unicode, c'est-à-dire que, contrairement au C, les caractères ne sont pas limités aux codes ASCII. Nous pouvons donc fixer la valeur de la variable surname d'une instance de Personne de cette façon :
Messages.
En Objective-C, tout appel de méthode d'une classe est un passage de message. Pour appeler un message sur un objet, on place entre crochet l'objet puis le message. On peut chaîner les appels très facilement. Ainsi dans l'exemple, "methode" renvoie un objet et sur cet objet on appelle "methode2".
La syntaxe des méthodes, un peu déroutante au premier abord, a été pensée pour qu'elle ressemble plus au langage humain. Chaque argument est séparé par « : » ainsi qu'un commentaire.
Chaque instance d'objet possède un pointeur isa, c'est-à-dire un pointeur sur un objet metaclass qui décrit les méthodes accessibles par l'objet. Une class ayant un parent, les metaclass représentent un arbre avec toute la hiérarchie des classes actuellement en mémoire. Ainsi lorsqu'on tente de passer un message, l'environnement Objective-C récupère le pointeur isa de l'objet, ensuite parcourt l'arborescence de la metaclass pour obtenir le pointeur de la méthode appelée. Ce mécanisme est évidemment coûteux mais un dispositif de mise en cache lors du premier appel le rend très performant.
Variantes du langage.
Objective-C++.
Objective-C++ est un frontal pour GCC, lequel compile une combinaison de code C++ et Objective-C. Objective-C++ ajoute à C++ les extensions que le langage Objective-C ajoute au C.

</doc>
<doc id="1050015" url="http://fr.wikipedia.org/wiki?curid=1050015" title="Linotte (langage)">
Linotte (langage)

Linotte est un langage de programmation interprété de type L4G. Sa particularité est sa syntaxe en français. 
Ce langage est libre et a été créé dans le but de permettre aux enfants et aux personnes n'ayant pas une connaissance approfondie de l’informatique d’apprendre la programmation facilement. 
Comme sa devise l'indique : « Tu sais lire un livre, alors tu peux écrire un programme informatique », ce langage se veut très simple ; une variante de la devise dit aussi « tu sais écrire une phrase, donc tu sais écrire un programme ».
Il est adapté à l'apprentissage de l'algorithmique au lycée.
Le vocabulaire.
Linotte a la particularité d'utiliser un vocabulaire non technique plutôt proche de termes utilisés, soit dans le monde cinématographique, soit dans la littérature. 
Un programme devient un livre, une variable, un acteur et l'écran, une toile. On n'exécute pas un livre, mais on le lit.
Linotte n'introduit pas de nouveaux concepts mais les renomme tout simplement.
Le livre.
Le livre est la structure mère d'un programme écrit en Linotte. Un livre est représenté par un fichier texte dont l'extension est ".liv".
La première fonction d'un livre est la première lue lors du lancement de la lecture d'un livre.
Les acteurs et les rôles.
L'association d'une valeur à un nom s'effectue par l'instanciation dans la mémoire de l'ordinateur d'un acteur. 
Chaque acteur est un objet caractérisé par une valeur, un nom et un rôle (son type).
L'acteur porte la sémantique d'une expression en langage Linotte.
L'acteur peut être comparé au mot variable que l'on retrouve dans les autres langages de programmation.
Les rôles disponibles en Linotte sont : nombre, texte, drapeau, casier, espèce.
Les actions.
Un programme informatique est une suite d'opérations, un livre en langage Linotte, une suite d'actions. Une action est constituée d'un verbe et d'acteurs ; elle est destinée à lancer un traitement particulier :
Caractéristiques du langage.
Programmation impérative.
Historiquement implémentée dans le langage, elle offre un accès rapide à la compréhension des bases de la programmation.
Exemple d'utilisation de paramètres et de fonctions : 
Il est également possible d'utiliser des acteurs locaux aux fonctions (n'étant visibles à l'exécution que dans cette fonction).
Programmation objet.
Les espèces sont un type d'acteur complexe caractérisé par des attributs. Elles permettent au développeur de créer ses propres "objets" :
Programmation événementielle.
Les événements sont attachés à des composants graphiques lors de la construction d'IHM :
Programmation de pages Web dynamiques.
À partir de la version 1.2.2, le concept de "weblivre" est introduit. Il mélange, dans un même fichier, du langage HTML et du langage Linotte. Ce dernier est intégré directement dans le HTML par un balisage précis à l'instar des langages PHP ou JAVA (JSP).
L'interprète "L'atelier Linotte".
Linotte est un langage interprété. Pour l'instant un seul interprète est disponible, mais il reste néanmoins libre. Il est développé en Java, son code source est distribué sous la licence GNU-GPL.
Il existe également en version packagée pour les plateformes MS-Windows, Ubuntu, Fedora, Archlinux et la clé USB Framakey
Le webonotte.
Le Webonotte est un serveur HTTP intégré à l'Atelier Linotte basé sur Jetty. Il produit des pages web dynamiques développées en langage Linotte.

</doc>
<doc id="1063042" url="http://fr.wikipedia.org/wiki?curid=1063042" title="RapidQ">
RapidQ

RapidQ (aussi connu sous le nom de "Rapid-Q") est une variante gratuite et semi-orientée objet du langage de programmation BASIC. 
Le compilateur est fourni avec des API permettant de développer aussi bien des applications console, graphiques ou des CGI. Il est également fourni avec un environnement de développement intégré qui permet la création d'interfaces utilisateur par glisser-déposer ou encore la coloration syntaxique.
Il est désigné comme "semi-orienté objet" par son auteur parce qu'il ne supporte que deux types de classe : les classes primitives, intégrées au langage, et les classes dérivées de celles-ci. Il n'est pas possible de créer des classes non dérivées des classes primitives. Le langage intègre en revanche des fonctions peu communes aux langages BASIC, dont les fonctions de rappels et la gestion des bibliothèques partagées.
Le compilateur RapidQ génère un bytecode qu'il lie avec son interprète pour former un exécutable qui ne nécessite pas l'installation d'un autre logiciel. Ceci a pour conséquence que les programmes RapidQ ont une taille minimale d'environ 150 kibioctets. 
RapidQ est disponible pour Microsoft Windows, GNU/Linux, Solaris et HP-UX. 
Commandes de Rapid-Q.
Création.
La création des programmes s'effectue avec des IDE complets comme RQWork ou Easy-Rapid qui permettent de gérer aussi bien les fenêtres que tous les autres types d'objet.

</doc>
<doc id="1073773" url="http://fr.wikipedia.org/wiki?curid=1073773" title="Boo (langage)">
Boo (langage)

Boo est un langage de programmation objet, avec typage statique dont le développement a commencé en 2003, cherchant à faire usage de la gestion de l'Unicode, de l'internationalisation et des applications web de la Common Language Infrastructure, tout en utilisant une syntaxe inspirée de Python et en ayant une insistance sur l'extensibilité du langage et du compilateur. Parmi les caractéristiques du langage figurent l'inférence de types, les générateurs, les multiméthodes, le "duck typing" optionnel, les macro-définitions, les vraies fermetures, la curryfication et les fonctions de première classe.
Boo est sous une licence libre à la MIT/BSD.
Boo peut être utilisé avec Microsoft .NET et Mono.

</doc>
<doc id="1111779" url="http://fr.wikipedia.org/wiki?curid=1111779" title="C-- (langage intermédiaire)">
C-- (langage intermédiaire)

C-- est un langage intermédiaire, conçu pour être émis par
un compilateur au lieu du langage C ou d'un langage assembleur. La syntaxe du langage emprunte beaucoup à C, d'où le
nom qui suggère que c'est essentiellement un sous-ensemble de C, de la
même manière que C++ est un surensemble du C.
Le langage est conçu comme un langage intermédiaire entre des outils de compilation de haut niveau et des outils de bas niveau comme des
optimiseurs. Les fonctionnalités qui ont été changées ou omises comparé au C, comme les fonctions variadiques, les pointeurs et les parties « avancées » du système de types, auraient entravé les fonctionnalités essentielles de C--, telles que la récursion terminale ou la facilité avec laquelle les outils de génération de code peuvent produire du code.
C-- est la cible du Glasgow Haskell Compiler (GHC) et sera finalement sa plate-forme principale. Certains des développeurs de C--, dont Simon Peyton Jones, travaillent aussi sur GHC. Le développement a lieu à Microsoft Research à Cambridge, bien que ce ne soit pas un projet Microsoft.

</doc>
<doc id="1117260" url="http://fr.wikipedia.org/wiki?curid=1117260" title="Csound">
Csound

Csound désigne un langage de programmation pour la création sonore, ainsi que son compilateur sonore. Le nom "Csound" provient du langage C, avec lequel il fut écrit au MIT par Barry Vercoe. Ce langage est inspiré de MUSIC, une série de programmes plus anciens développés par Max Mathews. C'est un logiciel libre disponible sous la licence LGPL. Son développement s'est poursuivi durant les années 1990 et 2000 sous la conduite de John Fitch à l'université de Bath, donnant ainsi naissance à la version Csound 5 en février 2005. Beaucoup de développeurs ont contribué à ce projet, notamment Istvan Varga, Gabriel Maldonado (qui a développé une variante "CsoundAV"), Robin Whittle, Richard Karpen, Michael Gogins, Matt Ingalls, Steven Yi et Victor Lazzarini.
Dans son utilisation la plus simple, le programmeur rédige deux fichiers texte selon un modèle spécifié et prédéfini : le fichier "orchestra" (orchestre) qui décrit la nature des instruments et le fichier "score" (partition) qui décrit les notes, ainsi que d'autres paramètres temporels. Csound procède ensuite à la compilation de ces fichiers et génère un fichier audio. Les versions récentes de Csound peuvent recevoir, traiter et produire, éventuellement en temps réel, des flux audio et des flux MIDI.
Les fichiers "orchestra" et "score" peuvent être réunis dans un seul et même fichier en utilisant une structure avec des balises XML. Voici un exemple très simple d'un fichier Csound unifié, lequel produit après compilation un fichier Wave contenant un signal sinusoïdal d'une durée de 1 seconde, et d'une fréquence de 1 kHz à un taux d'échantillonnage de 44,1 kHz :
La dernière version, Csound 5, est disponible sous forme de fichier binaire ou de code source pour Linux, Windows et MacOSX. Elle peut également être utilisée sous forme de bibliothèque logicielle ou d'API,
pouvant donc être partie intégrante d'un autre logiciel. Les bibliothèques logicielles sont disponibles en C, Python, Java, LISP, Tcl, et C++.

</doc>
<doc id="272801" url="http://fr.wikipedia.org/wiki?curid=272801" title="Miva Script">
Miva Script

Miva Script est un langage de programmation propriétaire, et il est utilisé en grande partie pour des applications de commerce électronique (mais pas seulement). Il a été développé initialement par la société HTML Script Corporate, qui par la suite est devenue la Miva Corporation, basée à San Diego, Californie. Miva Script a été rachetée par FindWhat Corporation en 2003 (réf.: en) qui a changé pour le coup le nom en Miva Corporation. Le 06/08/2007 FindWhat (nouvellement Miva Corporation) revend la société une équipe de management, dirigée par Russell Carroll et Rick Wilson (ancien executive de Miva Corporation) sous le nom de Miva Merchant (réf.: en)
Malgré le fait que beaucoup de sociétés d’hébergement offrent Miva Script sur leurs serveurs, le langage n’est pas si populaire que son principal concurrent PHP.
Histoire.
Le langage a été développé initialement sous le nom de htmlscript par Joe Austin et autres en 1995 et tout de suite après au bout d’un an ils ont constitué la société HTML Script Corporation.
En 1997, John Burchmore a réécrit intensivement le langage pour lui rendre plus de consistance syntaxique. Le nouveau moteur allait supporter les deux versions de langage : l’ancien Html Script et le tout nouveau baptisé Miva Script.
Des sources non officielles indiquent que le nom (Miva) vient d’un hôtel en Tchéquie où les fondateurs auraient séjourné pendant leur vacances.
En 1998 la société devient Miva Corporation, et, fin 1998, la première version de l’application de commerce électronique Miva Merchant a été lancée. Cette application va développer très rapidement la corporation qui se voit augmenter considérablement le chiffre d’affaires au bout d’un an. Miva Merchant devient alors le produit phare de la corporation.
Au 1 janvier 2004 Miva Corporation a été rachetée par FindWhat par une transaction de 8 millions de dollars. Joe Austin reste alors le PDG de la société.
Une autre caractéristique de Miva c’est le soin qu’elle apporte à ses développeurs. Une très fidèle communauté tourne autour du langage Miva Script et des produits Miva depuis la création de HTML Script. Depuis 2000 Miva Corporation tient aussi une conférence internationale qui rassemble tous les partenaires Miva mais aussi les développeurs. Dernièrement plusieurs « anciens » développeurs Miva se sont réunis et ont mis en ligne le site Internet de la communauté www.mivascript.org . Pour information, l’initiative part d’un développeur qui vit en France.
Le langage.
Miva Script est souvent décrit comme étant « un langage de script basé sur le XML » ce qui est mal approprié. Miva Script est construit des tags qui sont proches du (x)html et qui commencent par le préfixe <Mv. Les deux langages ont une syntaxe quasiment identique et nous retrouvons aussi des expressions dites « vides ». À partir de la version 3.9 le HTML est « parsée » par le moteur et on peut ajouter des valeurs Miva dans le tags html (ex. : <img src= "{g.source}"> ).
Dans les versions antérieures de l’interprétateur Miva Script nous pouvions utiliser des macros (ex : &). Suite a des nombreuses problèmes de sécurité, les macros ont été supprimés des versions suivantes (ex . : désormais on utilise {g.value} à la place de &[g.value)
Une des plus importantes caractéristiques du langage est le support natif de la vénérable plate-forme de données : dBase. De plus, les index propriétaires ont rendu ces bases de données très rapides et solides.
Miva Script ne demande pas que les variables soient pré déclarées, ce qui facilite l’écriture des programmes. 
La programmation en Miva Script est très facile et l’apprentissage du langage est très rapide.
Implémentations.
Miva Empresa.
Dans les versions antérieures à la version 4.0, Miva Empresa était le moteur qui faisait fonctionner Miva Script sur le web. Ce moteur était disponible sur les serveurs *ix et Windows. La dernière version de ce moteur s’arête à 3.96. Les versions suivantes (jusqu'à 4.0) ce sont des versions de transition vers le nouveau et puissant moteur qui va comprendre beaucoup plus de fonctionnalités (comme par exemple les arrays).
À partir de la version 4.0, Miva Empresa devient une Machine Virtuelle qui permet le fonctionnement du nouveau Miva Script compilé. Ce moteur est disponible pour les serveurs *ix, Windows, Bsdi, FreeBSD, Solaris et Sgi. La nouveauté est que le moteur est gratuit (ce qui n’était pas le cas avant).
En 2005 Miva Corporation sort la version 5 du moteur Empresa (toujours gratuite). Ce nouveau né est désormais celui qui a souffert le plus de modification de toutes les versions et les plus attendues de tous les développeurs. Cette version utilise des nouvelles basse de données : Miva-SQL, MySQL et DBFIII. À part les améliorations de la plate-forme des données, le langage a été amélioré et a reçu un set de nouvelles fonctions tant attendues par les développeurs (comme les structures par ex.)
Miva Mia.
Miva Mia c’est la version locale du moteur Miva. Ce petit moteur a été développe pour une utilisation sous Windows. Très simple a installer, il met en place un petit serveur sur le port 80 (ou autre). Aucun autre logiciel est demandé pour faire fonctionner un site html ou miva sur l’ordinateur. Ce système est parfait pour le développement des sites Miva Script en interne.
Pour chaque version de moteur Empresa, il y a sa petite sœur Mia qui sort. À partir de la version 4 Miva va permettre que le fonctionnement des scripts compilés.
Miva Script Compiler.
Le tant attendu Miva Script Compiler a vu le jour en 2002. Le compilateur a fait gagner énormément en vitesse et performance sans oublier qu’il a enlève l’éternel problème du vol de code source. La compilation demande un peu de reformatage du code. Ce dernier ne supporte plus les macros (ex : &[g.value] ) considérés comme étant un risque de sécurité important. En faisant une petite parenthèse, une chose très intéressante est l’influence de la petite communauté Miva sur les décisions d’amélioration du langage par la Corporation. Le problème des macros a été évoqué à plusieurs reprises par les « gurus » de la communauté sans qu’il reste sans écho auprès de Miva. Cette petite victoire démontre aussi l’importance vitale pour Miva Corporation d’avoir une communauté solide autour du langage Miva Script.
Le compilateur est disponible sur *ix, Windows, BSDI, FreeBSD et Solaris. Le fichier compilé fonctionne sur tout serveur qui à le moteur Empresa VM (ou Mia VM ) installé. Son extension est .mvc.
Un geste important de la part de la corporation Miva pour les développeurs est la version 5 du compilateur qui devient gratuit. Cela renforce l’importance que Miva donne à ses développeurs et à l’évolution du langage. Désormais écrire et utiliser Miva Script devient 100 % gratuit.

</doc>
<doc id="1159285" url="http://fr.wikipedia.org/wiki?curid=1159285" title="XLispStat">
XLispStat

xLispStat est un logiciel libre multi-plateformes d'analyse statistique. Il a été réalisé par Luke Tierney à la fin des années 80. Luke Tierney s'est basé sur l'interpréteur Lisp de Thomas Almy xLisp-Plus. Il a connu un grand essor dans la communauté scientifique dans les années 90 et jusqu'à récemment. Plusieurs plateformes de statistique en sont issues comme Arc. L'intérêt de la communauté scientifique semble s'être émoussé ces dernières années au profit de R, lui-même en open source.
Ce logiciel permet de réaliser un grand nombre de traitements statistiques : régressions linéaires, anova, modèle linéaire généralisé, détection des outliers, graphes dynamiques, etc.
C'est un logiciel libre distribué sous une licence de type BSD.

</doc>
<doc id="33799" url="http://fr.wikipedia.org/wiki?curid=33799" title="Visual Basic for Applications">
Visual Basic for Applications

Visual Basic for Applications (VBA) est une implémentation de Microsoft Visual Basic qui est intégrée dans toutes les applications de Microsoft Office, dans quelques autres applications Microsoft comme Visio et au moins partiellement dans quelques autres applications comme AutoCAD, WordPerfect, MicroStation, Solidworks ou encore ArcGIS. Il remplace et étend les capacités des langages macro spécifiques aux plus anciennes applications comme le langage WordBasic intégré à une ancienne version du logiciel Word, et peut être utilisé pour contrôler la quasi-totalité de l'IHM des "applications hôtes", ce qui inclut la possibilité de manipuler les fonctionnalités de l'interface utilisateur comme les menus, les barres d'outils et le fait de pouvoir personnaliser les boîtes de dialogue et les formulaires utilisateurs.
Comme son nom l'indique, VBA est très lié à Visual Basic (les syntaxes et concepts des deux langages se ressemblent), mais ne peut normalement qu'exécuter du code dans une "application hôte" Microsoft Office (et non pas d'une application autonome, il requiert donc une licence de la suite bureautique Microsoft). Il peut cependant être utilisé pour contrôler une application à partir d'une autre (par exemple, créer automatiquement un document Word à partir de données Excel).
Le code ainsi exécuté est stocké dans des instances de documents, on l'appelle également macros.
VBA est fonctionnellement riche et extrêmement flexible, mais il possède d'importantes limitations, comme son support limité des fonctions de rappel ("callbacks"), ainsi qu'une gestion des erreurs archaïque, utilisation de handler d'erreurs en lieu et place d'un mécanisme d'exceptions.
Même si ces limitations rendent ce langage très peu utilisé par les développeurs informaticiens soucieux d'utiliser des outils avant tout performants, sa simplicité et sa facilité d'accès ont séduit certaines professions, notamment dans la finance.
Obsolescence.
Depuis le 1er juillet 2007, Microsoft ne distribue plus de licences VBA à ses nouveaux clients car ils essayent de les remplacer par Visual Studio Tools for Applications (VSTA), un toolkit de customisation d'application basé sur la plateforme Framework .NET. De Dr Ex's article :
"VSTA remplace maintenant VSA Studio for Applications comme technologie ISVs utilisée pour fournir des fonctionnalités de customisation dans leurs applications. […] VSA était un client léger, alternative gérée par serveur de VBA compilé sous Visual Studio. L'approche serveur a été vue par l'ISVs comme moins utile qu'un modèle de client riche, donc, en se basant sur leur retour, Microsoft a commencé le développement de VSTA. Des ISVs utilisent VSA aujourd'hui, mais nous trouvons que son applicabilité était limitée. Certaines des technologies développées pour VSA sont reprises dans VSTA. VSTA application customisation tire un meilleur profit des fonctionnalités du client riche que VSA, offrant un environnement hautement optimisé pour la customisation d'application à la fois sur le client et le serveur."
"VSTA now replaces VSA Studio for Applications as the technology ISVs will use to provide customization capabilities in their applications. […] VSA was a thin-client, server-driven alternative to VBA built on Visual Studio. The server approach was viewed by ISVs as less useful than a rich-client model, so based on their feedback, Microsoft began development of VSTA. There are ISVs successfully using VSA today, but we found that its applicability was limited. Some of the technology developed for VSA is incorporated within VSTA. VSTA application customization takes better advantage of rich client functionality than VSA, offering a highly optimized environment for application customization on both the client and the server."
Office 2007 continue à utiliser l'ancien moteur VBA; cependant, Visual Studio Tool pour Office (VSTO) est disponible. La prise en charge de VBA dans Microsoft Office pour Mac a été abandonnée avec la distribution de la version 12, en 2008 puis réintroduit dans la version 2011. Voir aussi VB.NET.
La première version de VSTA a été fournie en avril 2006 et a été intégrée dans différents ISV, y compris InfoPath 2007 et ABB Robotics. La prochaine version de VSTA (basée sur Visual Studio 2008 connu sous le nom de "Orcas") sera distribuée vers février 2008. La seconde version de VSTA est très différente de la première, avec des fonctionnalités comme la programmation dynamique et la compatibilité WPF, WCF, WF, LINQ, et .NET 3.5.
Toutefois, en raison de la dépendance de certaines entreprises à VBA, VBA sera encore disponible dans Office 2007 et 2010 (Office 14).
Historique.
La popularité incroyable de Visual Basic après son lancement amena Microsoft à inclure une version simplifiée dans ses applications de bureautique afin de remplacer les différents langages de macro. Cependant, comme le démontre la chronologie, ce changement s’est fait sur une longue période.
Interopérabilité.
Une prise en charge minimale de VBA est également disponible dans OpenOffice.org, à partir de la version 3.0.
Applications.
Dans Excel.
L'enregistreur de macro sous Microsoft Excel (Onglet Développeur / Enregistrer une Macro) permet de générer facilement du code VBA dans une procédure.
Toute la séquence d'action effectuée entre le début et la fin de l'enregistrement est enregistrée dans une procédure VBA, qui pourra être réexécutée à l'identique. Il est possible de modifier ce code ou de programmer directement dans la VBE (Onglet Développeur / Visual Basic).
C'est la meilleure méthode pour apprendre à se servir de VBA pour les programmeurs néophytes.
Tout d'abord on enregistre une séquence en appuyant sur le bouton d'enregistrement, et ensuite on peut l'exécuter pas à pas (touche F8) dans l'outil VBA afin de savoir les actions effectués par chaque ligne de code.
Les principales collections d'objets du tableur Excel sont WorkBook (classeur), Sheets (feuille de calcul) et Range (cellules). Elles sont utilisables selon une hiérarchie descendante :
Une fois un objet désigné :
Les références aux cellules peuvent être :
Microsoft Excel permet de créer des fonctions personnalisées programmées en code VBA et placées dans un module. Elles sont ensuite accessibles dans la bibliothèque de fonction (Insertion / Fonction / Personnalisée) :
"Function NomFonction (Argument1, Argument2 As TypeDonnées, Optional Argument3=valeur_defaut)
...(actions programmées)
NomFonction = valeur renvoyée
End Function"
Ces fonctions peuvent recevoir des arguments en entrée, dont le type peut être spécifié (Argument2 ci-dessus) ou qui peuvent être optionnels, avec une valeur par défaut (Argument3 ci-dessus).
Dans Word.
Comme pour Excel, l'enregistreur de macro sous Microsoft Word (Onglet Développement / Nouvelle Macro) permet de générer facilement du code VBA dans une procédure.
Toute la séquence d'action effectuée entre le début et la fin de l'enregistrement est enregistrée dans une procédure VBA, qui pourra être réexécutée à l'identique. Il est possible de modifier ce code ou de programmer directement dans la VBE (Onglet Développement / Visual Basic Editor).
L'enregistreur de macro est la meilleure méthode pour d'apprentissage VBA pour les programmeurs néophytes.
Tout d'abord on enregistre une séquence en appuyant sur le bouton d'enregistrement, et ensuite on peut l'exécuter pas à pas (touche F8) dans l'outil VBA afin de vérifier les actions effectués par chaque ligne de code.
Les principales collections d'objets du traitement de texte Word sont Documents (les documents), BookMarks (les signets du document), Range (le contenu des signets). Elles sont utilisables selon une hiérarchie descendante :
Une fois un objet désigné :
Dans Access.
Le VBA est grandement utilisé dans les macros et formulaires Microsoft Access.

</doc>
<doc id="934274" url="http://fr.wikipedia.org/wiki?curid=934274" title="Limbo (langage)">
Limbo (langage)

Le langage de programmation Limbo a été créé vers 1995 par Rob Pike, Sean Dorward, Phil Winterbottom avec l'aide de Dennis Ritchie pour le système d'exploitation Inferno.
C'est un langage hybride empruntant des fonctionnalités au C, au Pascal, au Alef de Winterbottom, au CSP de Tony Hoare et au Newsqueak de Robert Pike.
Le Limbo est un langage qui a été initialement conçu pour Inferno. Le compilateur Limbo génère des objets qui sont interprétés par la machine virtuelle Dis. Ces objets sont exécutables sur n'importe quelle plateforme disposant de Dis. À l'exception de la machine virtuelle, Inferno est intégralement écrit en Limbo.
Le Limbo est cité dans le livre de Dan Brown "Forteresse Digitale". Dans l'intrigue, il sert à écrire un pisteur pour retrouver l'adresse d'un compte de messagerie électronique.

</doc>
<doc id="482832" url="http://fr.wikipedia.org/wiki?curid=482832" title="Rational Modeling Language">
Rational Modeling Language

Ce langage est une abstraction et une modélisation de langage de programmation libre sous licence GNU General Public License, se basant sur la théorie des graphes et la théorie des groupes. Il utilise également les travaux réalisés par le consortium OMG qui vient d'éditer UML2. Ce modèle utilise abondamment la notion de récursivité.
Ce langage, à la différence d'UML, est basé sur la théorie des graphes et la relation entre chaque représentation. Il a une vocation pédagogique et mathématique.
Ce langage définit un système complet par ses représentations. Il définit en premier lieu la famille génératrice et les variables libres du système.
Les variables libres du système sont le temps, la structure, les états, les prédicats.
Pour définir une représentation il est nécessaire de combiner au moins deux dimensions (variables libres) du système : classe, objet, prédicat, temps, état, etc.
Les vues.
Vue tri-dimensionnelle.
Pour définir une représentation tri-dimensionnelle, il est nécessaire de sélectionner trois variables libres du système.
Exemple une vue constitué des variables libres : temps, prédicat et classe.
Vue matricielle.
Pour définir une représentation matricielle, il est nécessaire de combiner deux dimensions du système.
Pour avoir une vue d'ensemble du système, il faut croiser toutes les combinaisons possibles de ces dimensions.
Le système doit être vu comme un système matriciel qui ne peut être vu que par des "vues", c’est-à-dire des observables sur ce système. Il peut être intéressant de faire le lien avec les observables en mécanique quantique. 
Le premier groupe défini est celui des objets. Il énumère les objets que le système comporte.
Le second groupe défini l'espace des prédicats. Il énumère les prédicats du système. En informatique un groupement de prédicats est appelé interface.
La gestion concurrente est déterminée par la variable libre "temps" et nécessite une projection.
Les couches d'abstraction (abstraction layers).
Pourquoi des couches d'abstraction ? Car il est impossible de définir un système par énumération. Toutes les fonctionnalités (prédicat ou objet) du système n'ont pas les mêmes valeurs et n'ont pas les objectifs. Il faut faire un tri abstrait.
Lorsque le système est défini, il se positionne dans un environnement spécifique. Les acteurs du système sont positionnés dans la couche N du modèle. 
La couche N défini tous les acteurs, objets et interactions qu'elle peut manipuler par ce niveau d'abstraction.
Nota : Ce concept de couche peut être apparenté à la notion de "domain" en executable UML, mais sans la dimension récursive.
Nota2 : un prédicat est vu comme un "use case" en UML.
Définition : Un prédicat peut être public ou privé. Un prédicat privé n'est vu que par l'objet qui le manipule. Un prédicat public est vu des acteurs de la couche d'abstraction qui le définit. Un prédicat peut faire appel à un autre prédicat d'une autre couche d'abstraction. Le passage d'une couche d'abstraction N à une autre N-1 est vu comme un paradigme. 
Chaque couche à sa propre ontologie et tout l'art réside dans la connexion des couches entre elles.
Par exemple s'il faut modéliser un logiciel de gestion commerciale, il faut définir des prédicats orienté commerce ("business activity"). Dans ce type de système, une base de données régit les transactions et le stockage des informations. Le logiciel commercial utilise une base de données mais n'est pas là pour définir ce qu'est une base de données, c'est-à-dire la modéliser.
C'est notion d'utilisation est très importante car elle conduit à la notion d'interface. Cette Interface est proposée par une autre couche (N-1 par exemple).
S'il faut modéliser une base de données, il faut définir les prédicats orientés base de données. Elle définit comment est stocké logiquement l'information et non physiquement. Ici le logiciel utilisera le système d'exploitation pour le stockage physique des données.
Il est possible d'aller plus en profondeur pour voir que les fabricants de système d'exploitation modélisent les prédicats spécifiques à l'OS et se base sur les possibilités du micro-processeurs. Les fabricants de micro-processeurs se basent sur les possibilités physiques et mécaniques. Les physiciens étudient les siciles, etc.
Même si dans cet exemple la décomposition du système est simpliste, elle a le mérite de présenter objectivement le besoin de couches d'abstraction. Le périmètre d'une couche d'abstraction à l'heure actuelle ne peut pas être calculé (au sens calculabilité et preuve mathématique).
Les groupes.
RML repose sur quatre groupes :
Groupe des classes.
Ce groupe identifie chaque élément comme une classe. Ce groupe est fini.
Groupe des objets.
Ce groupe identifie chaque élément comme un objet. Ce groupe est infini.
Chaque objet est une instance d'une classe.
Groupe des prédicats.
Ce groupe identifie chaque élément comme un prédicat. Ce groupe est fini.
Un prédicat regroupe les notions UML de cas d'utilisation et opération. Un cas d'utilisation est un prédicat. Une opération est un prédicat.
Groupe des méthodes.
Ce groupe identifie chaque élément comme une méthode. Ce groupe est infini.
Chaque objet est une instance d'un prédicat.
Portée des noms.
Le nom des prédicats et des classes est lié à la couche d'abstraction. Le RML n'a pas de grammaire ambiguë. 
En Java comme en UML pour les classes, l'ambiguïté est levée grâce à la notion de "package" (ou paquetage). Chaque package à son propre ensemble de nom. Les noms des classes sont préfixés par le nom de package.
Pour les couches d'abstraction il faut bien 
Pour les prédicats en langage orienté objet, l'espace des noms est défini par la classe sur laquelle le prédicat porte. Un prédicat ne peut exister seul alors qu'une classe oui :
Classe1 c; // existe 
Classe2.prédicat1(); // existe
prédicat1(); // n'existe pas 
Pour pallier l'impossibilité de créer un prédicat seul, on passe par une interface, qui est une classe ne contenant que des prédicats.
Un nom hors de son contexte peut avoir plusieurs sens.
Exemple : un prédicat dans deux couches d'abstraction
predicat1 : définition 1 (dans la couche 1)
prédicat1 engendre 2 méthodes méthode1 (orienté temps de traitement) et méthode2 (orienté espace alloué).
méthode1 et méthode2 sont équivalentes.
predicat1 : définition 2 (dans la couche 2)
prédicat1 engendre 2 méthodes méthode3 (orienté temps de traitement) et méthode4 (orienté espace alloué).
méthode3 et méthode4 sont équivalentes.
méthode1 et méthode3 ne sont pas équivalentes.
méthode2 et méthode4 ne sont pas équivalentes.
Les graphes.
Les graphes se reposent en partie sur les concepts d'UML. Ce n'est pas une copie des diagrammes d'UML mais une reconstruction, brique par brique de façon rationnelle (d'où le terme "Rational") les dépendances entre arc et sommet.
Il faut prendre, a minima, deux variables libres pour constituer un graphe. L'ordonnée représentant les sommets et l'abscisse les arcs.
Par exemple, les graphes suivants :
Assis ---10 secondes--→ Debout ---20 secondes--→ Assis
Assis ---seLever()--→ Debout ---sassoir()--→ Assis
seLever() ---10 secondes--→ sassoir() ---20 secondes--→ seLever() 
Homme ---10 secondes--→ Femme ---20 secondes--→ Homme
Chapeau ---tranformer()--→ Chapeau de paille ---tranformer()--→ Casquette
Un des points à aborder est la dualité des graphes, comme on peut le voir dans le tableau ci-avant, 
Par exemple, les graphes suivants :
Assis ---10 secondes--→ Debout ---20 secondes--→ Assis
10 secondes ---Assis--→ 20 secondes ---Debout--→ .
Récursivité.
Notion de récursivité apparaît dans le fait qu'un graphe est constitué :
- d'un ensemble d'arcs
- d'un ensemble de sommets
Un sommet est soit une variable libre soit un graphe.
Un arc est soit une variable libre soit un graphe.
Pour les prédicats :
Par exemple, le graphe G1 "ouvrir la porte" est composé de la manière suivante : (les états et les arcs ne sont pas forcément nommés)
--- chercher clé -→ . --- insérer clé dans la serrure --→ . --- tourner clé --→
G2 "rentrer chez soi" 
--- prendre métro ---→ . --- arriver maison --→ . --- ouvrir porte --→ . --- entrer maison --→
Pour les classes :
chien ---estun() --→ animal
labrador --estun() -→ chien
Les itérations du système.
Un système est "vivant" dans le sens où un programme informatique évolue sans cesse. Le système par de la première itération S(1) et est itéré jusqu'à n-ième itération S(n). Soit I(i) l'opérateur (au sens mathématique) qui fait passer de S(i) à S(i+1), on obtient :
formula_1
La version v du système correspond à la n-ième itération pour laquelle le système est jugé correspondre aux spécifications définit.
formula_2
Plusieurs types de version existent : 

</doc>
<doc id="685803" url="http://fr.wikipedia.org/wiki?curid=685803" title="ROM BASIC">
ROM BASIC

ROM BASIC est un langage informatique contenu dans le BIOS des ordinateurs (celui qui est conservé en ROM), et qui permettait de programmer certaines fonctions de l'ordinateur au niveau du boot ou des entrées sorties physiques.

</doc>
<doc id="793098" url="http://fr.wikipedia.org/wiki?curid=793098" title="Graph Modelling Language">
Graph Modelling Language

Graph Modelling Language (GML) est un format de fichier hiérarchique basé sur l'ASCII et décrivant les graphes.
Il est convertible en format graphviz (.dot, .gv) sous Linux avec la commande "gml2gv".

</doc>
<doc id="107028" url="http://fr.wikipedia.org/wiki?curid=107028" title="Run-time type information">
Run-time type information

En informatique, est utilisé pour signaler la capacité d'un langage de programmation à déterminer le type d'une variable pendant l'exécution d'un programme.
Bien que disponible dans la plupart des langages de programmation, le terme RTTI est souvent utilisé en référence au C++ qui par défaut, détermine le type à la compilation. Ce typage dynamique explicite en C++ – déclaré par l'utilisation de l'opération codice_1 – diffère de celui automatique de l'Objective-C pour lequel le typage et l'édition de liens sont réalisés lors de l'exécution.
Exemple.
Voici un exemple d'utilisation de la RTTI en C++ :
Comme on peut le voir, le but de la dernière fonction est de trouver le point d'intersection de deux traits dont les types (arc ou segment) ne seront connus qu'à l'exécution du programme (c'est tout l'intérêt de l'héritage : avoir des pointeurs de la classe mère sur des instances de classes filles). Le polymorphisme règle le problème pour la première variable (codice_2) puisque codice_3 appellera codice_4 ou codice_5 suivant le type de codice_2. Il reste cependant le problème du type de l'argument codice_7 puisqu'un simple appel à codice_8 génère une erreur du compilateur ne sachant quelle fonction utiliser à l'édition de lien.
Si le typage échoue (ce qui est forcément le cas dans cet exemple, soit pour codice_9, soit pour codice_10), le programme peut générer une exception codice_11.

</doc>
<doc id="1192867" url="http://fr.wikipedia.org/wiki?curid=1192867" title="Adobe Flex">
Adobe Flex

Flex est une solution de développement créée par Macromedia en 2004 puis reprise par Adobe en 2006, permettant de créer et de déployer des applications Internet riches (RIA) multiplate-formes grâce à la technologie Flash et particulièrement son lecteur. Son modèle de programmation fait appel à MXML (basé sur XML) et ActionScript 3.0, reposant sur ECMAScript.
La technologie Flex produit un fichier .swf intégré dans une page html. La richesse de l'interface graphique ainsi créée présente l'inconvénient, comme toute applet, de créer ici un fichier .swf sur le serveur un peu long à télécharger sur le poste client lors du chargement de la page.
Le 26 avril 2007, Adobe annonçait choisir la licence libre MPL 1.1 pour sa solution de développement Flex. Adobe Flash Player, le lecteur multimédia sur lequel les applications Flex sont lues, et Adobe Flex Builder, l'IDE construit sur la plate-forme libre Eclipse utilisé pour développer des applications Flex, restent propriétaires.
Le 17 novembre 2011, Adobe place Flex sous l'égide de la Fondation Apache.
Vue d'ensemble.
Il était difficile pour les développeurs d'applications traditionnelles de travailler avec la plate-forme Flash en elle-même. En effet, celle-ci sert à la base à créer des animations. Flex cherche à minimiser ce problème en fournissant un modèle de programmation qui est familier à ces développeurs. MXML, un langage de description basé sur XML, offre la possibilité de créer rapidement une interface utilisateur. L'interactivité est créée par l'utilisation d'ActionScript 3.0, reposant sur le standard ECMAScript.
Le SDK Flex fournit de nombreux composants graphiques, dont des boutons, des listes, des arbres, des tableaux de données, et plusieurs conteneurs utilisés pour la mise en page de l'interface. Les graphiques (Flex Charting) sont disponibles en tant qu'extension. D'autres fonctionnalités comme les services Web, le glisser-déposer, les effets ou la validation de formulaires viennent compléter ce framework applicatif.
Dans une architecture trois tiers, les applications Flex représentent la couche présentation. Contrairement aux applications HTML, les applications Flex fournissent un client "stateful", c'est-à-dire que les changements de la vue ne requièrent pas le chargement d'une nouvelle page. De la même manière, Flex et le Flash Player offrent la possibilité d'envoyer et de recevoir des données depuis et vers un serveur sans que le client ne doive recharger la vue.
Versions.
Macromedia Flex Server 1.0 et 1.5.
Macromedia a au départ ciblé le développement d'applications entreprise avec ses versions de Flex 1.0 et 1.5. Dans ces premières versions qui ne sont désormais plus disponibles, la compilation des fichiers SWF se faisait au niveau serveur. La licence par CPU était de 15000$US et comprenait 5 licences pour l'IDE Flex Builder.
Adobe Flex 2.
Avec la sortie de Flex 2, Adobe a complètement modifié sa ligne de produit Flex. Le SDK Flex 2 a été mis à disposition gratuitement. Il contient un compilateur en ligne de commande (mxmlc) ainsi qu'une bibliothèque de composants graphiques et d'utilitaires. Les applications Flex peuvent être construites et déployées uniquement avec le SDK Flex 2.
Adobe a basé sa nouvelle version de Flex Builder sur la plate-forme Eclipse open-source. Flex Builder 2 était distribué en deux versions: Standard et Professionnelle. La version Professionnelle contient la bibliothèque de composants Flex Charting, utilisée pour la création de graphiques.
La composante serveur reste encore disponible grâce à Flex Data Services 2. Contrairement à Flex 1.0 et 1.5, Flex Data Services n'est pas requis pour déployer des applications Flex.
Avec la sortie de Flex 2, Adobe a introduit la nouvelle version de son langage de programmation ActionScript, ActionScript 3. L'utilisation d'ActionScript 3 et de Flex 2 requiert la version 9 ou ultérieure de Flash Player.
Adobe Flex 3.
Le 25 février 2008, Adobe a annoncé la sortie du SDK Flex 3 sous licence Mozilla Public License ainsi qu'Adobe AIR 1.0, sa solution RDA. Dans le même temps, Adobe a sorti le nouveau Flex Builder 3, toujours basé sur Eclipse, permettant de développer des applications Flex et Air.
Adobe Flex 4.
Version disponible depuis décembre 2009. Cette version apporte une nouvelle bibliothèque de composants personnalisables nommée Spark ainsi que le support de fichiers FXG. Une nouvelle version du compilateur conçu par Adobe accompagne sa sortie, renommée en Flash Builder 4.
Adobe Flex 4.5.
Sortie début mai 2011, Flash Builder 4.5 intègre la version 4.5 du SDK Flex. La principale nouveauté réside dans la possibilité de compiler des applications mobiles pour Google Android, Apple iOS ou encore BlackBerry Tablet OS.
Une version d'évaluation de 60 jours est disponible en téléchargement sur le site officiel.
Exemple.
Voici un exemple d'application Flex 3 utilisant MXML et ActionScript :
codice_1
Ce code dessine un formulaire permettant à un utilisateur de saisir son nom puis d'afficher "Hello + nom saisi" lorsque l'on clique sur le bouton "Dis Bonjour!".
Le même exemple avec Flex 4 et en utilisant les composants Spark:
codice_2

</doc>
<doc id="896854" url="http://fr.wikipedia.org/wiki?curid=896854" title="Perl 6">
Perl 6

Perl 6 est la sixième version majeure du langage de programmation Perl. Il s'agit aussi d'une refonte profonde du langage, aussi bien dans sa conception que dans son implémentation, rompant avec l'exigence de rétrocompatibilité qui avait primé pour les versions majeures précédentes.
Cette refonte garde tout de même l'esprit du langage qui laisse une grande liberté au programmeur et lui permet une expression concise. Perl 6 reste un langage générique et permet toujours de programmer des unilignes, mais il facilite aussi l'écriture de programmes importants, grâce à des fonctionnalités telles que le typage statique des données et un meilleur support de la programmation orientée objet.
Contrairement aux versions antérieures de Perl, Perl 6 n'est pas défini par une implémentation de référence, mais par des spécifications en langage naturel, dont la rédaction a commencé en avril 2001. Ces spécifications sont publiques et par conséquent tout développeur est libre de créer son implémentation. Perl 6 ne dispose donc pas d'une implémentation unique et en 2012, au moins trois projets tentent d'implémenter le langage. En 2013, aucun d'entre eux n'implémente la totalité de la spécification.
La fondation Perl détient le "copyright" d'une de ces implémentations: "rakudo", ciblant la machine virtuelle Parrot. Rakudo est elle-même en grande partie écrite en Perl 6, ce qui lui fait jouer un rôle particulièrement important au sein de la communauté de développeurs en Perl6.
Le logo de Perl 6 est appelé Camelia. C'est un papillon, sur les ailes duquel on peut lire la lettre "P" et le chiffre "6".
Il est complètement intégré au système objet.
Le système objet, minimaliste en Perl 5, supporte maintenant le dispatch multiple, les rôles et la réflexion via un Protocole à méta-objets inspiré de CLOS.
La programmation orientée prototype et la programmation orientée objet sont toutes deux possibles car le programmeur peut modifier le comportement par défaut des métaclasses et du mécanisme de dispatch vers les méthodes et multiméthodes.
Les rôles sont un système de composition de code similaire aux mixin mais de granularité inférieure à la classe.
Les concepteurs de Perl 6 ont apporté un soin tout particulier à la syntaxe du langage qui avait été notablement alourdie en Perl 5 avec l'ajout du support des références. Les principes directeurs dans la conception du
langage sont : le principe de Huffman, la lisibilité, l'extensibilité.
Chaque aspect du langage est hautement paramétrable via des constructions lexicales ou syntaxiques appelés adverbes ou modificateurs. Certains opérateurs sont des caractères Unicode mais souvent un alias plus verbeux en ASCII est disponible. L'interopérabilité avec les bibliothèques d'autres langages dynamiques de haut niveau est un but à terme grâce à la mise en œuvre de ces langages par le même moteur (Pugs ou Parrot).
Le typage explicite du contenu d'une variable est optionnel. Le typage des données est donc statique lorsqu'il est explicite ou inferré, dynamique sinon.
Le programmeur dispose donc d'un continuum entre la programmation lâche typique des langages de script et la rectitude et les performances d'un langage à typage statique. Typiquement, un programme évoluera au cours du temps vers un typage plus "serré".
Perl 6 devrait être un langage rapide car, outre le typage statique, le support de la parallélisation, ses implantations supportent la compilation à la volée en code natif.
FIN "A RECYCLER"
Motivations.
Le langage Perl était au départ très modeste et a grossi en respectant la rétrocompatibilité. Créé en 1987, Perl a accumulé beaucoup de scories qui rendent son apprentissage difficile et complexifient inutilement l'interpréteur. Il fallait s'en débarrasser. Les comportements par défaut du langage étaient conçus pour des programmes de quelques lignes. Même si le langage avait évolué (variables lexicales, orientation objet…) pour supporter de gros programmes, une grande partie des programmeurs n'avaient pas adapté leur style, ce qui a donné à Perl une réputation de langage sale.
L'interpréteur de Perl 5 n'utilise pas au mieux les architectures multiprocesseurs ou multi cœur dont la mémoire est lente par rapport au processeur. De plus, pour la programmation en grand, il est nécessaire d'avoir un système puissant de passage de paramètres. De même il était important de donner la possibilité au programmeur, mais non l'obligation, d'un typage statique des données. Ce typage constitue à la fois une documentation, une forme d'assertion exécutée à la compilation et une amélioration des performances par rapport au typage dynamique.
Historique.
Le processus de conception de Perl 6 a été annoncé pour la première fois le 19 juillet 2000, par Larry Wall le jour de la conférence annuelle OSCON dans son discours sur l'état de l’oignon 2000 (« State of the Onion 2000 »). À cette date, les principaux objectifs étaient de débarrasser le langage de verrues historiques ("historical warts") et de nettoyer d'une manière générale la conception interne et les API. Le tout était alors résumé par la phrase: « les choses faciles doivent rester faciles, les choses difficiles doivent être plus faciles, et les choses impossibles ne devraient pas être difficiles ».
Le processus a commencé avec une série de demandes de changements ou « RFC » (par analogie aux "Request for comments" d'internet). Ce processus était ouvert à tous les contributeurs et ne laissait aucun aspect du langage à l’abri du changement. Alors que Larry Wall s'attendait à recevoir une vingtaine de RFC, 361 demandes de changements furent émises par les membres de la communauté PERL.
Une fois le processus des RFC terminé, Wall a revu et classé chaque demande. Il a alors commencé la rédaction de ce qu'il a alors appelé les Apocalypses. Bien que le but initial était d’écrire une Apocalypse pour chaque chapitre du manuel de référence en perl intitulé « Programmation en Perl », il est devenu évident à la rédaction de chacune des Apocalypses que les précédentes apocalypses devenaient invalides de par les derniers changements. Pour cette raison, un ensemble de synopsis ont été publiés, chacun relatif au contenu d’une Apocalypse, mais mis à jour suivant les modifications apparues. Aujourd’hui, les spécifications de Perl 6 continuent presque entièrement à travers les Synopsis.
Au fil des ans, Perl 6 a connu plusieurs changements de direction. L’introduction de concepts provenant de Python et Ruby ont influé au début, mais lors de l’écriture de l’interpréteur pugs dans le langage Haskell, on a pu noter une large influence de la programmation fonctionnelle sur l’équipe de conception de Perl 6.
Pugs est historiquement la première mise en œuvre expérimentale de Perl 6. Pugs peut exécuter du code Perl 6 directement, ainsi que compiler du Perl 6 vers du JavaScript, du Perl 5 ou du bytecode Parrot. Écrit essentiellement par Audrey Tang, maintenant peu active, Pugs utilise des fonctionnalités avancées de Haskell, ce qui est un obstacle à la reprise du projet par d'autres programmeurs.
Durant 2006, Pugs était suffisamment avancée pour permettre d'écrire des jeux de tests, de valider, de corriger et d'affiner les spécifications.
Mises en œuvre.
En 2013, au moins deux projets implémentent un sous-ensemble conséquent de Perl 6.
Niecza.
Niecza est un compilateur ciblant la machine virtuelle du Framework .NET.
Rakudo.
Rakudo est une implémentation utilisant la machine virtuelle Parrot, et visant à terme l'auto-hébergement de Perl 6.
Parce qu'il est lui-même essentiellement écrit en Perl 6, Rakudo est susceptible d'être porté relativement facilement vers d'autres machines virtuelles. Le portage vers la Machine virtuelle Java a commencé en 2013, ainsi que vers MoarVM, une machine virtuelle conçue spécialement pour faire tourner Rakudo.
La communauté Perl n'a pas la main d'oeuvre pour maintenir une machine virtuelle moderne avec des optimisations dynamiques de code telles que celles fournies par CrankShaft de V8, il est donc probable que d'autres machines virtuelles lui succéderont.
Rakudo, dont le copyright est détenu par la fondation Perl, sera probablement la première mise en œuvre substantielle de Perl 6. Pour le bootstrap de Perl 6, Rakudo utilise NQP (Not Quite Perl), un sous-ensemble de Perl 6 avec qui comporte le moteur d'analyse syntaxique.
Une distribution spéciale de rakudo, appelée "Rakudo Star", incluant divers modules afin de la rendre "utile et utilisable" est publiée mensuellement depuis juillet 2006.
Changements incompatibles.
Perl 6 est la première version majeure de Perl qui n'est pas rétrocompatible avec les versions précédentes. Cela signifie qu'un code écrit en Perl5 échouera probablement à la compilation ou à l'exécution si on tente de l'exécuter ou de le compiler sans modification comme s'il s'agissait de code Perl6.
Les changements incompatibles sont nombreux, mais les plus notables sont l'invariance du sigil, les simplifications syntaxiques et le passage d'arguments.
Invariance du sigil.
En Perl 5, le sigil — le caractère non alphanumérique qui précède un nom de variable — pouvait changer selon son contexte d'utilisation
(scalaire ou tableau) :
En Perl 6, l'abondance des contextes possibles nécessite un mécanisme différent
des sigils. Le sigil ne désigne plus le contexte d'accès. Perl 6 propose des opérateurs spécialisés pour ce faire. Le sigil d'une variable est donc invariant. Il est plus pédagogique d'avoir
deux mécanismes syntaxiques pour deux fonctions grammaticales différentes (le
typage faible de la variable et son contexte d'accès).
Passage de paramètres.
Les versions antérieures de Perl définissent les sous-routines sans liste formelle de paramètres.
Les arguments de sous-routines entrant dans une sous-routine devenaient des alias dans les éléments du tableau @_. Si @_ était modifié, les changements étaient reflétés dans les données originales :
Même en tenant compte de l'invariance du sigil, la plupart des déclarations de fonctions en Perl5 échoueront si on cherche à les exécuter comme du code Perl6, car Perl 6 utilise un système très différent de passage de paramètres, grâce à un formalisme dans le langage qui va au-delà des signatures de types. En Perl 6, une déclaration de sous-routine ressemble à :
Comme en Perl 5, les paramètres formels (exemple, les pseudo-variables dans la liste de paramètres) sont aliasés en leurs paramètres effectifs (valeurs d'entrées), mais par défaut, les alias sont marqués is readonly signifiant qu'ils sont en lecture seule et donc constants :
Si un paramètre formel est suivi par is copy ou is rw, cependant, il "peut" être modifié. Dans le cas is copy, Perl 6 copie les paramètres actuels plutôt que des les aliaser ; ainsi ils peuvent être modifiés, mais les changements restent locaux à la sous-routine. Dans le cas is rw (rw signifie lecture-écriture, "read-write" en anglais), l'alias n'est pas marqué readonly. Ce changement détecte aussi, lors de la compilation, des erreurs telles que :
De nouvelles fonctionnalités de Perl 6 dans les listes de paramètres rendent le passage de paramètres beaucoup plus puissant qu'en Perl 5 :
Par exemple :
Perl 6 supporte aussi la curryfication.
Simplification syntaxique.
Les changements de syntaxe entre Perl5 et Perl6 sont nombreux et parfois subtils. Par exemple une règle fondamentale en Perl6 est l'interdiction absolue d'avoir deux termes consécutifs. C'est pourquoi la syntaxe d'une fonction telle que codice_1 fait désormais apparaître une virgule. Ainsi un code Perl5 tel que:
échouera à la compilation si on cherche à l'exécuter comme du code Perl6. Il faudra ajouter une virgule entre la fonction anonyme et la liste:
Pour les mêmes raisons, la notation objet indirecte (qui était de toute façon déconseillée par la communauté) a disparu.
Nouveaux concepts et fonctionnalités.
Syntaxe auto-hébergée.
La syntaxe de Perl 6 est elle-même définie en Perl 6. Ce point qui peut paraître anodin a des conséquences très profondes sur la structure et les possibilités offertes par le langage.
En particulier, cela signifie que Perl 6 obéit syntaxiquement aux même règles que celles imposées par les fonctionnalités d'analyse textuelle du language. Ainsi, l'analyse lexicale satisfait aux mêmes priorités que celles imposées par le traitement des expressions régulières en Perl 6. En l'occurrence, cette règle est, en simplifiant, celle de la plus longue unité lexicale ("longuest token matching"). Cette règle est fondamentale en Perl 6 et possède une grande portée sur de nombreux aspects du langage. Par exemple, la règle de la plus longue unité lexicale permet aux noms de variables de contenir le caractère '-', sans que celui-ci soit confondu avec la soustraction.
Une autre conséquence est la possibilité pour le langage de modifier sa propre syntaxe en cours d'exécution, ce qui constitue une performance accomplie par de très rares langages de programmation, le plus emblématique étant Lisp.
Types de données.
Le système statique de typage de Perl 5 comporte peu de types. Lors de la déclaration d'une variable, son sigil détermine si elle est de type scalaire, tableau ou hash (métonyme pour table associative). Un scalaire peut contenir un entier, un flottant ou
une chaîne de caractères. Puisque le type du contenant ne détermine que partiellement
le type du contenu, on parle de typage semi-dynamique.
En Perl 6, les sigils et le typage dynamique de Perl 5 ont été étendus par l'addition de types statiques. Cela consiste en la déclaration explicite du type du
contenant. Par exemple :
Cependant, tout comme en Perl 5, les programmeurs peuvent se passer de typage explicite :
Le typage statique est une forme de documentation et de tests intégrée au code source. Il améliore la maintenance, spécialement dans les grands projets logiciels. Mais le typage statique alourdit le code de scripts courts ou d'unilignes. Ce style concis sans déclaration explicite de type autre que par les sigils est une force du Perl lorsque utilisé pour l'écriture de code à usage
unique.
Perl 6 introduit aussi des sigils secondaires appelés twigils.
Orientation objet.
Perl 5 supportait l'orientation objet via un mécanisme propre à Perl et nommé
bénédiction. N'importe quelle référence pouvait être bénie comme étant un objet d'une classe particulière, comme :
Un objet béni pouvait alors avoir des méthodes invoquées en utilisant la « syntaxe flèche » :
L'invocation identifie la sous-routine appropriée de nom codice_2, et l'appelle avec codice_3 comme premier argument.
Bien que très puissant — virtuellement n'importe quel autre modèle objet d'un autre langage pouvait être simulé en utilisant cette simple fonctionnalité — il rendait le cas le plus commun d'orientation objet, comme une
structure C associée à du code, inutilement difficile. De plus, Perl ne pouvant faire d'hypothèse sur le modèle objet utilisé, l'invocation de méthode ne pouvait pas être très bien optimisée.
Dans l'esprit de rendre les choses simples plus simples, et les choses compliquées faciles, Perl 6 garde le principe de bénédiction pour créer une instance pour les programmeurs qui désirent des fonctionnalités communes. Cela fournit un modèle objet plus robuste pour les cas communs. Par exemple, une classe pour encapsuler un point cartésien peut être écrite comme :
et utilisée :
Le point remplace la flèche (propre à Perl 5) comme opérateur d'accès au membre d'une instance. C'est la syntaxe propre à
de nombreux langages dont C++, Java, Python, et Ruby.
Notez que les méthodes « codice_4 » et « codice_5 » ne sont pas déclarées explicitement. Elles sont appelées des auto-accesseurs. Le modificateur « is rw » 
dans la définition de la classe permet à tous ses attributs publics d'être écrits par défaut, en utilisant les auto-accesseurs.[http://dev.perl.org/perl6/doc/design/syn/S12.html]
Les données membres d'une instance sont appelés « attributs ». Elles peuvent être déclarées ainsi :
Résolution multiple.
Dans un même champ lexical, on peut définir plusieurs routines ou méthodes du même nom en les
préfixant par le mot-clé multi. On parlera de multi pour désigner l'ensemble des routines
ou méthodes de même nom. Lors de l'appel d'une multi,
la routine ou méthode dont la signature correspond aux arguments passé sera appelé.
Le système de liage entre les arguments de l'appel et les paramètres de l'appelé est très pointu.
Ainsi, pour traverser un arbre n-aire, l'argument attendu est soit un nœud de type Nary
dont les enfants sont un tableau commençant par l'$ainé et suivi éventuellement de @frères,
soit une $feuille. 
Ce système de multiméthodes inclut donc la fonctionnalité de filtrage par motif propre à la programmation fonctionnelle.
Expressions rationnelles.
Les expressions rationnelles
(en anglais, "regex", pour "regular expression") de Perl ont connu tellement de succès qu'elles ont été mises en œuvre par une bibliothèque appelée PCRE (Perl Compatible Regular Expressions). 
Via PCRE, les expressions rationnelles ont été incluses sans amélioration dans beaucoup d'autres langages.
Pourtant, comme le fait remarquer Larry Wall, ce sont les expressions rationnelles qui ont contribué à donner à Perl une réputation de langage peu lisible.
Elles sont trop compactes et trop malignes, les mêmes caractères sont utilisés pour des usages divers. Il y a peu de support pour les captures nommées, peu de support pour les grammaires, et une intégration pauvre avec les langages réels.
Perl 6 fournit un sur-ensemble des fonctionnalités de Perl 5 concernant les expressions rationnelles.
Le mécanisme des regex fournit une puissance comparable aux analyseurs syntaxiques.
Ces regex agissent comme des fermetures par rapport à leur champ lexical. 
Les regex sont introduites avec un des mots-clefs codice_6, codice_7, codice_8.
La définition d'une regex est similaire à une définition de sous-routine et peut admettre des
paramètres. Le choix du mot-clef permet de contrôler si les espaces sont significatifs
ou non dans la regex, et de spécifier s'il peut y avoir retour sur trace ou non.
Comme en Perl 5, on peut aussi définir des regex anonymes ou les utiliser directement dans les opérateurs codice_9 (matching) ou codice_10 (chercher et remplacer).
Seules six fonctionnalités n'ont pas été changées depuis les regex du Perl 5 :
Quelques-uns des ajouts les plus efficaces sont :
Les changements suivants ont grandement augmenté la lisibilité des regexes :
Exemples :
La dernière ligne est identique à :
Comparaisons chaînées.
Les nouveaux programmeurs attendent souvent que les comparaisons chaînées
comme dans l'uniligne ci-dessous fonctionnent :
En Perl 6, ce code fonctionne maintenant naturellement, dans l'esprit du DWIM ("Do What I Mean"), et s'exécute comme :
Évaluation paresseuse.
Perl 6 propose l'évaluation paresseuse de listes qui est une fonctionnalité de certains langages de programmation fonctionnelle tels que Haskell.
L'évaluation paresseuse simplifie des tâches communes en Perl6 comme les opérations d'entrées/sorties, la
transformation de listes et le passage d'arguments à une routine :
Le code ci-dessus ne crashera pas en essayant d'assigner une liste de taille infinie à la table codice_25.
Meta-opérateurs.
Les méta opérateurs sont des opérateurs qui agissent sur un autre opérateur pour obtenir un opérateur au comportement différent.
Opérateurs d'affectation.
Perl5 avait hérité de certains opérateurs emblématiques du langage C tels que '+=', '*=' etc. Perl6 généralise cette notion avec le métaopérateur d'affectation '='. 
Ainsi, pour n'importe quel opérateur binaire "Op", on peut écrire:
Pour:
"Op" peut très bien être un opérateur défini par l'utilisateur.
hyper-opérateurs.
Les "hyper-opérateurs" sont similaires aux opérateurs de manipulation de tableaux dynamiques du langage APL. Ils agissent sur un opérateur et le font opérer sur toutes les valeurs d'un tableau. Ainsi, pour créer un tableau dont tous les éléments sont ceux d'un tableau @a auxquels on a ajouté 1, il suffit d'écrire :
Imbrication de méta-opérateurs.
Les méta-opérateurs peuvent être imbriqués, quitte à utiliser des crochets ('[]') pour désambiguïser.
Jonctions.
Perl 6 introduit le concept de "jonctions".
Nous choisissons ce terme pour le distinguer des jointures, concept propre aux bases de données relationnelles.
Les jonctions sont des valeurs scalaires composites.
Les jonctions ont été initialement appelées superpositions, par analogie au concept de physique quantique de superpositions quantiques — des courbes qui peuvent simultanément occuper plusieurs états jusqu'à ce que leur observation les "effondre". Un module Perl 5 réalisé en l'an 2000 par Damian Conway appelé codice_26 fournissait une preuve de concept initiale. D'abord une curiosité programmatique, les jonctions sont ensuite devenus un concept important de Perl 6.
Dans leur forme la plus simple, les jonctions sont créées par combinaison d'un ensemble de valeurs avec l'opérateur de jonction :
Ces valeurs peuvent être utilisées arithmétiquement :
ou dans des comparaisons :
ou même pour l'accès à un tableau :
Les jonctions peuvent aussi être utilisées pour étendre le système de types :
Les jonctions ne sont pas ordonnées ; codice_27 et codice_28 représentent les mêmes valeurs. Cette absence d'ordre signifie que le compilateur Perl 6 peut choisir d'évaluer les expressions jonctives "en parallèle". En fait, plusieurs dans la communauté Perl 6 croient que les jonctions peuvent surpasser l'explicite multithreading comme manière ordinaire d'accomplir le parallélisme en Perl 6.
Macros.
Dans les langages de bas niveau, le concept de macros a été synonyme de substitutions textuelles du code source à cause de la large utilisation d'un préprocesseur ignorant la syntaxe du langage.
Le langage C utilise la construction codice_29.
Perl 5 utilise des systèmes de filtres sources à cet effet. Ils sont notoirement peu fiables, car leur empilement a des effets aléatoires. En effet, chaque filtre suppose que le code qu'il filtre est du code Perl 5 alors qu'il reçoit du code modifié par ces prédécesseurs.
Lisp est privilégié, car il propose un système de macros qui manipulent directement l'arbre syntaxique correspondant au source du programme. C'est facile car sa syntaxe concrète est identique à sa syntaxe abstraite. A terme, Perl6 vise à intégrer un système de macro tout aussi puissant qu'en Lisp, ce qui constitue l'un des objectifs les plus ambitieux du langage.
Perl 6 proposera les deux types de macro: substitutions textuelles et manipulation de l'AST.
Une définition de macro Perl 6 ressemblera à une définition de sous-routine ou méthode, et peut travailler sur des chaînes non analysées, un arbre de syntaxe abstrait AST représentant du code préanalysé, ou encore une combinaison des deux. Une définition de macro pourrait ressembler à :
Dans cet exemple particulier, la macro n'est pas plus complexe qu'une substitution textuelle en C, mais parce que l'analyse du paramètre de la macro se produit avant que la macro n'opère sur le code appelé, les messages de diagnostic seront beaucoup plus informatifs. Cependant, parce que le corps de la macro est compilé à chaque lancement du programme, diverses techniques d' optimisation peuvent être employées.
Hello world.
En Perl 6 comme en Perl 5, on peut écrire
En Perl 6, on préfèrera écrire le hello world ainsi :
codice_30 est semblable au codice_30 de REXX, au codice_32 de Pascal et au codice_33 de Ruby et C.
JAPH.
Comme en Perl 5, les JAPHs (programmes qui impriment « Just another Perl hacker »), sont de bons moyens d'expérimentation avec Perl 6.
Ici un exemple de curryfication :

</doc>
<doc id="502479" url="http://fr.wikipedia.org/wiki?curid=502479" title="Bistro (langage de programmation)">
Bistro (langage de programmation)

Bistro est un langage de programmation orienté-objet, dynamiquement typé et réflectif. Il a été conçu par Nikolas S. Boyd en 1999. Son langage reprend des concepts présents dans Smalltalk et Java. Bistro se présente ainsi sous la forme d'une variante de Smalltalk s'exécutant grâce à une machine virtuelle Java. Cette dernière doit être en conformité avec les spécifications de Sun Microsystems. 
Selon le concepteur de Bistro, Smalltalk offre une modélisation plus expressive que Java. Le fait que le bytecode issu de Bistro se présente sous la forme de classe Java assure la portabilité des applications et la possibilité d'intégrer le code au sein d'applications Java. Bistro permet aussi de convertir à moindre frais une application en Smalltalk vers un environnement Java. 

</doc>
<doc id="1217631" url="http://fr.wikipedia.org/wiki?curid=1217631" title="Binary Format for Scene">
Binary Format for Scene

BInary Format for Scene (BIFS)
Le langage BIFS est un format binaire pour du contenu multimédia en deux ou trois dimensions.
Le langage BIFS est basé sur le langage de description d'univers virtuels en 3 dimensions VRML auquel on a ajouté des particularités comme la gestion de la 2D et des notions de timing.
Dans le cadre d'une compression au format MPEG-4, un fichier texte écrit en langage BIFS est adjoint aux objets médias. Les objets médias et ce fichier sont ensuite encapsulés dans un même fichier dont l'extension est .mp4.
Ainsi, le langage BIFS permet de gérer les interactions utilisateurs dans le cadre de vidéos au format MPEG-4. Il illustre la partie 11 de MPEG-4.

</doc>
<doc id="1219287" url="http://fr.wikipedia.org/wiki?curid=1219287" title="Fonction de McCarthy n°91">
Fonction de McCarthy n°91

Définition.
La fonction de McCarthy est une fonction récursive définie pour formula_1 par
formula_2.
Elle est en fait constante égale à 91 pour formula_3.

</doc>
<doc id="1177999" url="http://fr.wikipedia.org/wiki?curid=1177999" title="ESRI-Avenue">
ESRI-Avenue

ESRI-Avenue était un langage de programmation du logiciel ArcView de la société ESRI jusqu'à sa version 3.3. Ce langage servait à personnaliser le logiciel ou développer de nouvelles fonctionnalités.
<br>Il est remplacé aujourd'hui par le VBA.

</doc>
<doc id="60102" url="http://fr.wikipedia.org/wiki?curid=60102" title="C sharp">
C sharp

Le C♯ (prononcé []) est un langage de programmation orienté objet à typage fort, créé par la société Microsoft, et notamment un de ses employés, Anders Hejlsberg, le créateur du langage Delphi.
Il a été créé afin que la plate-forme Microsoft .NET soit dotée d'un langage permettant d'utiliser toutes ses capacités. Il est très proche du Java dont il reprend la syntaxe générale ainsi que les concepts (la syntaxe reste cependant relativement semblable à celle de langages tels que le C++ et le C). Un ajout notable au C# est la possibilité de surcharge des opérateurs, inspirée du C++. Toutefois, l'implémentation de la redéfinition est plus proche de celle du Pascal Objet.
Capacités du langage.
Le C♯ est, d’une certaine manière, le langage de programmation qui reflète le mieux l’architecture Microsoft .NET qui fait fonctionner toutes les applications .NET, et en est par conséquent extrêmement dépendant. Les types natifs correspondent à ceux de .NET, les objets sont automatiquement nettoyés par un ramasse-miettes ("garbage collector" en anglais), et beaucoup de mécanismes comme les classes, interfaces, délégués, exceptions, ne sont que des moyens explicites d’exploiter les fonctionnalités de la bibliothèque .NET. Pour achever de marquer cette dépendance, le CLR () est obligatoire pour exécuter des applications écrites en C♯, comme l’est la JVM ( ou Machine virtuelle Java) pour des applications Java.
Le langage compte un certain nombre de changements par rapport au C/C++ ; On notera particulièrement les points suivants :
Capacités introduites avec C♯ 2.0.
Microsoft mit à disposition du public en , après une longue période de beta-tests, la version 2.0 de la bibliothèque .NET, accompagnée d’une nouvelle version de la quasi-totalité des outils associés. C♯ ne fait pas exception à la règle et sort donc en version 2.0, avec les ajouts suivants :
À titre de référence, les spécifications complètes des nouveautés introduites dans la version 2.0 sont disponibles dans les liens externes.
Anders Hejlsberg, le père de Delphi, s’est exprimé sur l’implémentation des génériques dans C♯, Java et C++ dans cette interview .
La fonctionnalité des types nullables fut fixée quelques semaines seulement avant la sortie publique de la version 2.0, car il a été mis en lumière que si la valeur de la variable était bien nulle, cette variable n’était pas nulle au sens traditionnel du terme, c'est-à-dire qu’il ne s’agit pas d’une référence vide. Ainsi, la conversion d’un type primitif de valeur nulle en objet donnait une référence non nulle vers une valeur nulle. Il fallut donc, pour corriger ce problème, corriger le noyau du CLR et effectuer de nombreuses vérifications et corrections sur tous les produits de la gamme .NET 2.0 (Visual Studio 2005, SQL Server 2005, C♯ et VB.NET).
Capacités introduites dans C♯ 3.0.
Le C♯ 3.0 fut présenté au salon PDC 2005. La version finale est disponible depuis le au téléchargement sur le site de Microsoft . Les principales nouveautés sont les suivantes :
Une présentation du C♯ 3.0 et de LINQ peut être trouvée sur la page du centre de développement de .NET Framework.
Le code compilé en C♯ 3.0 est entièrement compatible avec celui du 2.0, étant donné que les améliorations apportées ne sont que purement syntaxiques ou ne consistent qu’en des raccourcis compensés au moment de la compilation. Les nouveautés introduites dans les bibliothèques de la version 3.5 (LINQ…) ne sont cependant pas utilisables avec les versions précédentes de C♯.
Cette version exige Windows XP ou une version supérieure (Vista ou Windows 7). Elle n'est pas disponible pour Windows 2000.
C♯ 4.0.
La version 4 du langage apporte plusieurs nouveautés:
Le framework .NET 4.0 est sorti le , accompagné de Visual Studio 2010.
Il propose entre autres :
C♯ 5.0.
La version 5 du langage permet de programmer plus simplement des programmes asynchrones grâce à l'ajout des mots clés async et await.
Le comportement des closures dans la boucle foreach a été modifié. Il n'est désormais plus nécessaire d'introduire une variable locale dans une boucle foreach pour éviter les problèmes de closure.
À noter également les informations relatives à l'appelant permettent de connaître le nom de la méthode qui a appelé une propriété.
Différences entre Java et C♯.
Bien que le C♯ soit similaire à Java, il existe des différences notables, par exemple :
Standardisation.
Le C♯ a été normalisé par l'ECMA (ECMA-334) en et par l'ISO/CEI (ISO/CEI 23270) en 2003.
Les modifications survenues dans la Version 2.0 ont été normalisées par l'ECMA (ECMA-334) en et par l'ISO/CEI (ISO/IEC 23270:2006) en .
Microsoft a ouvert le code source de certaines bibliothèques utilisées par le C♯ en sous la licence Microsoft Reference License (MS-RL).
Nom du langage.
C♯ est une note de musique dans le système de notation musical américain (cette note correspond à "Do dièse" dans la notation française). Le symbole ♯ signifie en musique que la note doit être augmentée, l'idée de "C augmenté" rappelle la manière dont le langage C++ a été nommé (++ étant l'opérateur d'incrémentation).
Usuellement, un croisillon (#) est utilisé comme second caractère à la place du dièse (♯) car ce dernier est moins accessible sur le clavier et non reconnu dans certaines polices de caractères.
On peut aussi voir dans ce croisillon # quatre signes +, d'où le fait que certains codeurs disent que le nom du C# est en fait C++++ : ce serait une version sur-améliorée du C (C++ étant une première amélioration, C++++ serait la seconde). Cependant, on peut remarquer que l'instruction i++++; est illégale. Cela peut conduire à penser que cette hypothèse est fausse.
Le langage.
Voici un exemple d'un programme typique, écrit en C♯ :
Gestion des exceptions.
C♯ possède les instructions "try" et "catch" permettant de gérer les exceptions (comportement non attendu des instructions du programme), similaires dans la syntaxe à celles du C++.
Exemple de code tentant de créer un fichier "document.txt" sur le serveur "Toto":
Notez l'utilisation d'une chaîne de caractères verbatim : le caractère arobase précède le guillemet donc l'anti-slash n'est pas doublé. Ce genre de chaîne de caractères est pratique pour les chemins sous Windows.
Dans cet exemple, la fonction File.Create retourne un flux (FileStream), ou elle peut lancer une exception si une erreur s'est produite (problème de connexion par exemple).
Dans cet exemple, aucune information sur l'exception n'est obtenue : on cherche juste à savoir si le programme ne s'est pas comporté normalement, auquel cas on arrive dans le bloc catch.
À l'instar de C++ qui a un type d'exception de base (class exception dans l'en-tête <exception>) et dont les autres exceptions héritent, toute exception C# est héritée (ou une instance) du type System.Exception. Ainsi, si on cherche à savoir ce qui s'est passé, une solution simple reste d'obtenir une référence vers l'exception de la manière suivante :
Ainsi, une information complète sera retournée, décrivant la nature de l'exception qui s'est produite.
En fonction des fonctions appelées, le framework .NET fournit la liste des exceptions que l'appel est susceptible de retourner en cas d'erreur. Dans le cas de la fonction 'Create', voici la liste des exceptions possibles:
De la même manière qu'en C++, l'envoi d'une exception se fait avec le mot-clef throw :

</doc>
<doc id="1253888" url="http://fr.wikipedia.org/wiki?curid=1253888" title="Game Maker Language">
Game Maker Language

Le GML (Game Maker Language) est le langage de programmation intégré du logiciel Game Maker, créé par Mark Overmars. Le GML peut être vu comme un dérivé du C++ avec des influences issue du Delphi, (lui-même est un dérivé du C), en version très simplifiée : seulement deux types de données (réel et chaîne de caractères), aucune possibilité de créer de nouveaux types de données, une manipulation peu ergonomique des tableaux et autres structures de données, etc...
Le GML est utilisé avec ce qu'on pourrait appeler sa « bibliothèque standard » : un ensemble assez complet de fonctions utiles à la réalisation de jeux vidéo. Celles-ci touchent à tous les aspects de la réalisation ; manipulation des sons, des images, de l'affichage, fonctions mathématiques, fonctions de dessin, etc...

</doc>
<doc id="1304733" url="http://fr.wikipedia.org/wiki?curid=1304733" title="Turbo Assembler">
Turbo Assembler

Turbo Assembler ou TASM, est un assembleur pour la famille de processeurs x86, créé par Borland. Il est toujours distribué par Embarcadero, dans sa version 32 bits, avec Delphi et C++Builder.

</doc>
<doc id="1333755" url="http://fr.wikipedia.org/wiki?curid=1333755" title="Server Side Includes">
Server Side Includes

Les Server Side Includes, abrégés SSI, sont un langage de programmation fait pour être interprété par un serveur HTTP lorsqu'il sert un document HTML. Ce langage tire son nom de sa principale utilisation : inclure plusieurs fichiers pour construire et servir à la demande un document HTML.
Rôle.
Les SSI facilitent la maintenance des sites web en permettant de conserver dans un seul fichier les parties de page web qui se retrouvent à l'identique dans toutes les pages du site. Il s'agit souvent de l'en-tête et du pied de page, qui contiennent des informations comme le nom du site, les coordonnées de son auteur, etc.
Syntaxe.
Les directives SSI ont la syntaxe suivante : codice_1.
</pre>
On remarque que ces directives sont des commentaires SGML.
Support des serveurs HTTP.
Les SSI sont apparues rapidement dans l'histoire du World Wide Web. Depuis, elles ont été éclipsées par les langages comme et Active server pages.
Le module codice_2 du Apache HTTP Server est fréquemment utilisé pour interpréter les SSI. L'extension de nom de fichier codice_3 est fréquemment utilisée pour identifier les fichiers que le serveur HTTP doit interpréter. Un autre moyen d'identifier les fichiers HTML à interpréter sans changer leur nom consiste à les marquer comme exécutables (directive codice_4 de codice_2).

</doc>
<doc id="1396703" url="http://fr.wikipedia.org/wiki?curid=1396703" title="Fortress (langage)">
Fortress (langage)

Fortress est un langage de programmation conçu et développé par Sun Microsystems, visant à remplacer le langage Fortran dans le domaine du calcul scientifique. La spécification a été élaborée dans le cadre d'un projet financé par le DARPA. Une implémentation partielle basée sur la machine virtuelle Java (JVM) est sortie en avril 2008.
Le langage ne ressemble pas à Fortran. Sa syntaxe est proche de Scala, ML et Haskell. Elle est largement basée sur la notation mathématique traditionnelle. Il est possible d'utiliser les caractères Unicode. Il est possible d'effectuer un rendu du code source à l'aide de diverses feuilles de style, par exemple en ASCII, en Unicode, ou bien en utilisant la notation mathématique via LaTeX.
Fortress est conçu pour être extrêmement parallèle. Par exemple, la boucle « for » est parallèle par défaut : elle n'agit pas toujours de manière linéaire, en fonction du logiciel et du matériel utilisé. Fortress propose également des bibliothèques standards riches en fonctionnalités.

</doc>
<doc id="1351387" url="http://fr.wikipedia.org/wiki?curid=1351387" title="Communicating sequential processes">
Communicating sequential processes

En programmation concurrente, Communicating sequential processes (CSP) est une algèbre de processus permettant de modéliser l'interaction de systèmes.
CSP intègre un mécanisme de synchronisation basé sur le principe du rendez-vous (détaillé plus loin au travers de la commande d'entrée/sortie). Combinant ce mécanisme à une syntaxe simple et concise, CSP permet alors l'implémentation rapide des paradigmes classiques de la concurrence, tels que producteurs/consommateurs ou lecteurs/écrivains. Ce n'est pas un langage de programmation complet.
CSP fut décrit en premier par C. A. R. Hoare dans un article de 1978, mais a depuis évolué de façon substantielle. CSP a été mis en pratique industriellement comme un outil de spécification formelle de l'exécution concurrente de systèmes variés — tels que le T9000 Transputer ou un système informatique de transaction commerciale sécurisé 
. C'est un champ de recherche toujours actif.
Généralités.
Structure d'un programme.
Un programme CSP se présente sous la forme d'une suite de commandes et de déclarations de
variable séparées par des points-virgule :
Hoare distingue alors deux types de commandes :
Les commandes d'entrée/sortie, parallèle, répétitive et alternative seront détaillées par la suite. La commande nulle, par définition, ne fait rien. Elle permet juste de combler les blocs d'instructions vides. La commande d'affectation a quant à elle une syntaxe classique "variable := valeur" :
Échec de commande, terminaison de programme.
L'échec d'une commande (par exemple, dans le cas d'une commande d'entrée/sortie, si le processus visé n'existe pas) entraîne l'échec du processus ou de la commande structurée qui la contient (l'échec d'une commande peut donc entraîner la fin du programme). Notons le cas particulier d'une répétitive dont l'échec d'une commande interne entraîne la terminaison et non la faillite (cf. partie La commande répétitive). 
Un échec n'est donc pas une erreur en soi.
Les signaux.
Une notion de signal a aussi été introduite en CSP. Un signal est en quelque sorte une variable
complexe (ou structurée) composé d'un constructeur (un identifiant libre) ainsi que d'un ensemble
de valeurs. Les valeurs peuvent être soit de type élémentaire (entier, chaîne de caractères, etc.) soit
d'autres signaux.
Exemples :
Notons aussi qu'un signal peut être affecté à une variable (exemple : x := p (4)), et peut aussi être la cible
d'une affectation. Cela permet alors des affectations du type (x, y) := (y, x).
Détails sur les commandes.
La commande parallèle.
Elle permet la mise en concurrence de processus par la syntaxe suivante :
Une telle commande ne se termine que lorsque tous les processus qu'elle définit sont terminés,
l'échec d'un seul entraînant l'échec de la commande parallèle.
Précisons qu'une variable définie avant une commande parallèle est visible par les
processus qu'elle contient. Ceci implique nécessairement que tous les processus définis devront 
avoir accès aux variables déclarées avant la commande parallèle. On assiste donc ici à un partage de ressources, 
dont les contraintes soulevées (accès exclusif, etc.) sont à la charge du programmeur.
On note aussi la possibilité de déclarer plusieurs processus pour une même liste de commandes,
comme le montre l'exemple suivant :
Ici, dix processus ayant la même liste de commandes seront mis en concurrence.
La commande d'entrée/sortie.
Les communications entre processus reposent sur cette commande. Pour expliciter son fonctionnement,
partons du cas simple de deux processus producteur et consommateur, le premier voulant
transmettre une variable x au second. Une telle communication s'effectuera alors au travers des
commandes suivantes :
permettra au processus producteur d'envoyer x au processus consommateur
permettra au processus consommateur de recevoir x depuis le processus producteur
Du point de vue de la syntaxe, on remarque que le ! indique une commande de sortie, tandis
que le ? indique une commande d'entrée. Plus formellement, une commande d'entrée se présentera
sous la forme :
et une commande de sortie sous la forme :
De plus, pour que la communication soit possible entre deux commandes d'e/s, CSP impose que :
Dans ces conditions, la transmission peut avoir lieu, et le contenu de l'expression source est copié
vers la variable cible. Si l'une de ces conditions n'est pas respectée, les processus sont mis en attente,
entraînant par conséquent un interblocage. Si l'un des processus est mort, alors toute commande
d'entrée/sortie impliquant ce processus doit échouer. Enfin, le premier processus demandant la communication
doit être mis en attente jusqu'à ce que le second le rejoigne. On retrouve ici le principe
du rendez-vous.
Notons aussi le cas particulier d'une synchronisation simple, c'est-à-dire sans transmission de
valeur, possible grâce à l'utilisation d'un signal pur.
Exemple :
La commande alternative.
Une commande alternative se présente sous la forme d'un ensemble de sélectives, chacune étant
composée d'une garde ainsi que d'une liste de commandes. Une garde est quant à elle composée
d'une partie expression booléenne et d'une partie commande d'entrée, l'une ou l'autre pouvant
être omise.
Syntaxiquement, une commande alternative se présente sous la forme suivante :
Où "garde1" et "garde2" sont de la forme :
Ce qui donne par exemple :
Lors de l'exécution d'une commande alternative, chacune de ses gardes est testée, afin de déterminer sa 
valeur selon une logique trivaluée (c'est-à-dire qu'une garde peut être vraie, fausse, ou
neutre) :
Ainsi, si une ou plusieurs commandes gardées sont vraies, un choix indéterministe (i.e. aléatoire)
doit être effectué pour n'en sélectionner qu'une. Si aucune n'est vraie mais que certaines sont
neutres, le processus se met en attente des commandes d'entrées correspondantes. Et si toutes les
commandes gardées sont fausses, la commande alternative échoue.
Si une garde est sélectionnée, la liste de commande correspondante doit alors être exécutée.
Il est aussi important de noter que la contrainte d'ordre syntaxique limitant les commandes
d'e/s dans les gardes aux simples commandes d'entrée, provient d'un choix fait par HOARE dans
le but d'éviter les incohérences.
Pour illustrer ce propos, partons de l'exemple suivant (qui suppose possible l'utilisation de
commande de sortie dans les gardes) :
Supposons que les deux processus soient chacun arrivés sur leur commande alternative. Les deux
commandes vont donc être évaluées parallèlement :
Si les deux choix sélectionnent la même communication, aucun problème n'est soulevé. Par contre, si chacun sélectionne une communication différente, on assiste à un cas d'incohérence entraînant nécessairement un interblocage.
Ainsi, la communication entre commandes d'entrée/sortie gardées posant des problèmes, HOARE a décidé de l'empêcher en autorisant uniquement les commandes d'entrée dans les gardes.
Précisons cependant que le compilateur proposé en fin de cet article autorise les commandes de sortie dans les gardes, mais ajoute en contrepartie la condition suivante :
On évite alors bien le problème cité ci-dessus.
La commande répétitive.
La commande répétitive est composée d'une unique commande alternative, dont l'échec entraîne
la fin de la répétition. On peut donc considérer qu'une répétitive ne peut se terminer qu'avec
succès.
Syntaxiquement, elle se présente sous la forme d'une étoile suivie d'une alternative :
Par exemple :
Ici, la commande répétitive se terminera lorsque i aura atteint la valeur 10.
Conventions, pratiques usuelles.
Définition de processus.
On retrouve souvent la syntaxe "PROCESSUS == liste d'instructions" pour définir un processus à l'extérieur d'une commande
parallèle, dans le seul but de clarifier le code. Exemple :
La liste d'instructions "MAIN" est alors celle executée au lancement du programme.
Commande d'affichage (print).
Pour afficher un message à l'écran, on utilise usuellement la commande :
Commande aléatoire (random).
Permet de prendre un nombre au hasard compris dans l'intervalle fin
Commande sleep.
Stoppe le processus qui l'exécute pendant "tps" millisecondes. Permet de simuler des temps d'attente, etc.
Définition de constantes.
On utilise communément la syntaxe :
Exemple :
Exemple de programmes de type producteur/consommateur.
Un producteur, deux consommateurs.
Un producteur envoie une suite de nombre à un processus "délégueur" qui les transmet à deux consommateurs. L'utilisation d'une commande alternative dans le délégueur permet :

</doc>
<doc id="1422225" url="http://fr.wikipedia.org/wiki?curid=1422225" title="PANORAMIC">
PANORAMIC

PANORAMIC est un langage BASIC sous Windows permettant de manipuler des objets Windows (Button, Edit, Combo, Picture, Scene3D, Movie, Track_bar, Scroll_bar, ...) des sprites (dans l'objet SCENE2D) et des objets 3D (dans l'objet SCENE3D), des fichiers textes, des fichiers binaires, des sons MIDI ...etc...
Description.
PANORAMIC est complètement gratuit et l'éditeur possède une documentation intégrée bilingue (anglais - français).
Il n'a besoin d'aucune DLL ni d'aucune bibliothèque logicielle externe pour fonctionner, c'est un logiciel portable qui peut être emporté partout sur une clé USB et qui fonctionne sur la plupart des configurations. Il fonctionne sous Windows XP, Windows 7 et Windows 8.
Il utilise les instructions BASIC classiques.
Le but de l'auteur est de développer un langage pour l'utilisateur, un langage qui est utilisable de la façon la plus simple possible.
La manipulation d'objets est simple : pour créer un objet, il suffit de taper son type suivi d'un numéro. Ce numéro est ensuite utilisé pour toute action sur cet objet, c'est l'identifiant de l'objet.
Exemples.
Gestion 3D.
- Pour créer un monde 3d : codice_4
- Pour y mettre une théière : codice_5
- Pour la faire pivoter de 30 degrés sur son axe Z : codice_6
Caractéristiques.
Il gère des évènements : codice_7.
Il possède actuellement (en 2011) environ 500 mots-clés, et est en constante et régulière évolution. Une nouvelle version sort environ tous les 2 mois.
Il peut aussi piloter Excel, dessiner, gérer des fichiers, la souris, utiliser des objets 3D en format 3DS ou MD2, créer des mélodies musicales en MIDI ...
Il peut créer des exécutables et des applications (une application est un exécutable qui contient tous les fichiers nécessaires à son exécution, comme les fichiers textes, les images, les sons, ...). 
Les logiciels créés avec PANORAMIC sont portables (besoin d'aucune DLL ni d'aucune bibliothèque externe)
Ce langage est présent dans 2 logiciels :
- un environnement de développement intégré pour créer son application avec une interface utilisateur: avec la souris, on place des objets sur une feuille et on les redimensionne. Ensuite on tape le code correspondant aux événements sur ces objets.
- un EDITOR pour créer son application à partir de rien (from scratch). 
Il existe un forum français très actif (plus de 11000 messages) et un forum anglais.
Versions.
La dernière version officielle (0.9.24) date du 28 mars 2013.
Les versions antérieures à la 0.9.13 étaient volontairement limitées dans le nombre d'objets qu'elles pouvaient gérer, mais à partir de la version 0.9.13 (du 15 août 2009) il n'y a plus aucune limite.
Des versions instantanées sont mises périodiquement à disposition, afin de faire bénéficier tout de suite des améliorations et des corrections de bug, sans devoir attendre la sortie de la version officielle.
Il faut noter que l'auteur de ce langage s'efforce de répondre aux demandes des utilisateurs en développant des fonctionnalités qui sont demandées sur le forum.

</doc>
<doc id="103102" url="http://fr.wikipedia.org/wiki?curid=103102" title="Gambas (langage)">
Gambas (langage)

Gambas est un langage de programmation interprété orienté objet utilisant la syntaxe du BASIC, disponible pour GNU/Linux et autres systèmes Unix ou assimilés. Il est accompagné d'un interpréteur et d'un IDE, lui-même écrit en Gambas.
Gambas se donne pour objectif de reproduire la "facilité d'utilisation" de Visual Basic en améliorant ses fonctionnalités. Bien que son interpréteur ne soit pas compatible avec les programmes dont le code source est écrit en Visual Basic, Gambas est lui aussi dérivé du BASIC et orienté objet. Il n'est pas un clone de Visual Basic, son auteur insiste sur ce point, mais constitue une solution pertinente pour les utilisateurs du Visual Basic souhaitant créer des applications pour Linux/Unix sans passer à un environnement totalement différent.
Gambas est un logiciel libre diffusé sous la licence GNU GPL, développé principalement à Paris depuis 1999 par Benoît Minisini.
Gambas est l'acronyme récursif de "Gambas almost means Basic" (en français, « Gambas veut presque dire Basic »). C'est aussi le nom espagnol d'une crevette de mer, l'Aristeidae, dont provient le logo du projet.
La version stable actuelle (5 avril 2013) est la version 3.4.1, qui succède à la précédente version 3.3.4 (18 avril 2012 ). Gambas est amélioré continuellement et peut être conseillé à tous les utilisateurs de Linux/Unix qui souhaitent mettre à profit leurs connaissances BASIC sous licence GNU.
Gambas est disponible sous forme de paquets RPM ou Deb pour de nombreuses distributions Linux, notamment Debian, Ubuntu, SuSE ou encore Mandriva.
Fonctionnalités.
Avec Gambas, il est notamment possible de :
Exemple de programme en Gambas.
Simple programme Hello world écrit en Gambas.
Portage vers d'autres plates-formes/architectures.
Gambas est théoriquement portable vers d'autres plates-formes. Son auteur principal, Benoît Minisini, a déclaré : . Les applications Gambas en ligne de commande fonctionnent sous Windows avec Cygwin.
Gambas fonctionne sous FreeBSD et Mac OS X. 
Gambas fonctionne sur les architectures 64 bits.

</doc>
<doc id="1599709" url="http://fr.wikipedia.org/wiki?curid=1599709" title="XL (langage)">
XL (langage)

XL, dont les lettres proviennent de "eXtensible Language", est un langage de programmation, basé sur la programmation par concepts, développé depuis 2000 par Christophe de Dinechin.
XL offre la possibilité de modifier et programmer la syntaxe et la sémantique du langage. Des plugins compilés peuvent être utilisés pour ajouter de nouvelles fonctionnalités au langage. On peut par exemple noter un ensemble de plugins permettant la mis en œuvre d'un langage impératif. Les utilisateurs peuvent écrire eux-mêmes leurs propres plugins pour permettre l'utilisation de syntaxe spécifiques, par exemple pour la dérivée, qui pourront être utilisés de la même manière que les fonctionnalités originales.
Langage.
XL est défini en quatre niveaux différents :
XL n'a ni type primitif ni mot-clé. Tous les opérateurs et les types de données, tels que les entiers ou les additions, sont définis dans la bibliothèque standard "XL2". "XL1" est portable dans différents environnements d'exécution. Ce qui n'est pas garanti pour "XL2" qui n'offre pas de tels garanties : si un processeur particulier n'implémente pas la multiplication en virgule flottante, la définition de l'opérateur correspondant peut être manquante de la bibliothèque standard, et l'utilisation de cette fonctionnalité peut générer une erreur de compilation.
En XL, le programme Hello World peut s'écrire ainsi :
Une manière plus convenable pour des programmes plus importants serait :
Une implémentation par récurrence de la fonction factorielle : 
Syntaxe.
La syntaxe est définie au niveau "XL0". La phase "XL0" du compilateur peut être configurée en utilisant un fichier de description de la syntaxe, où sont définies des propriétés telles que la représentation du texte et les priorités des opérateurs. Un fichier de syntaxe basique définit les notations mathématiques communes tel que + pour l'addition, ainsi que la priorité des opérations.
L'"arbre syntaxique" est composé de 7 types de nœuds : 4 types de feuilles (entier, réel, texte et symbole) et 3 types de nœuds internes (infixe, préfixe et bloc).
Avec le fichier de syntaxe par défaut, le code suivant est valide pour "XL0", indépendamment de la sémantique :
Il est décomposé en :
Sémantique de "XL1".
Le niveau "XL1" est défini comme une séquence d'opérations sur l'arbre syntaxique du niveau "XL0". Ces opérations sont effectuées par divers plugins du compilateur qui sont appelés suivant la forme de l'arbre syntaxique.
Des constructions particulières, codice_21 et codice_22, sont fournies par un plugin destiné à faciliter l'écriture d'autres plugins. La construction codice_23 génère un arbre syntaxique. Voici comment ces constructions peuvent être utilisées pour implémenter un plugin nommé codice_24, qui supprime les additions et multiplications par zéro : 
Un plugin peut être invoqué sur un fichier complet à partir de la ligne de commande, ou plus localement dans le source du code en utilisant la notation "pragma", comme ici : 
Le niveau "XL1" contient un grand ensemble de plugins, notamment codice_25 qui donne les abstractions communes telles que fonction, type de données et déclaration de variable et définition, et aussi les ordres de base de la programmation structurée que sont les boucles et les conditions.
Système de typage.
"XL1" contrôle le type statique, avec des possibilités de programmation générique qui vont au-delà de celles de C++ ou Ada. Les types comme les tableaux ou les pointeurs, qui sont des types primitifs en C++, sont déclarés dans une bibliothèque dans XL. Par exemple, le type d'un tableau d'une dimension peut être définit par : 
Un "type générique validé" est un type générique où une condition indique comment le type peut être utilisé. De tels types ne doivent pas avoir de paramètres génériques. Par exemple, on peut déclarer un type comme codice_26 (ordonné) si un opérateur "inférieur" est présent :
Ceci s'applique aussi aux types génériques qui ont des paramètres, comme codice_27. Une fonction calculant la somme des éléments dans un tableau peut s'écrire : 
Type protégé de liste de variable d'arguments.
Les fonctions peuvent être surchargées. Une fonction peut être déclarée avec un nombre variable d'arguments grâce au mot codice_28 dans la liste des paramètres. Dans une telle fonction, codice_28 permet de passer un nombre variable d'arguments à une autre fonction :
Quand ce genre de fonction est appelée, le compilateur invoque les fonctions de manière récursive pour correspondre à la liste :
Réduction d'expression (surcharge d'opérateur).
Les opérateurs peuvent être définis en utilisant la forme codice_30 de déclaration de fonction. Voici un code qui déclare l'addition d'entiers :
De telles "formes écrites" peuvent avoir plus de deux paramètres. Par exemple, une transformation de matrice linéaire peut s'écrire :
Une forme écrite peut utiliser des constantes, et ce type de forme est plus spécialisée que sans constantes. Par exemple :
Ce mécanisme est utilisé pour décrire tous les opérateurs de base. Une expression est progressivement réduite à des appels utilisant des formes écrites. Pour cette raison, ce mécanisme est appelé "réduction d'expression" plutôt que surcharge d'opérateur.
Itérateurs.
Les itérateurs de XL permettent de programmer à la fois des générateurs et des itérateurs.
Sémantique de "XLR".
"XLR" est un langage dynamique, conçu dès l'origine comme un exécutant "(back-end)" pour le compilateur "XL1" (d'où le nom, qui représente le runtime de XL). Il partage la syntaxe de base "XL0" avec "XL1", mais son comportement est plus proche de celui d'un langage fonctionnel, même si "XL1" est censé ressembler plus à un langage impératif. "XLR" n'a pratiquement qu'un seul opérateur de construction, "→", qui indique une réécriture. La notation à gauche de la notation de la réécriture est transformée en notation à droite de la réécriture.
Ce mécanisme est utilisé pour implémenter les notations standards : 
État du développement et historique.
Le design de XL a commencé aux alentours de 1992, sous le nom LX (Langage eXpérimental). Le projet a été mis dans le domaine du logiciel libre en 2000, dans le cadre du projet "Mozart" qui visait à fournir des capacité de métaprogrammation multi-langage. Les premiers compilateurs étaient écrits en C++, mais cela rendait l'écriture d'extensions de compilateurs compliquée, car C++ ne permettait pas d'offrir le niveau d'abstraction voulu (par exemple un équivalent de codice_21). Les aspects multi-langage rendaient les arbres syntaxiques difficile à manipuler en respectant la sémantique de chaque langage.
Une réécriture complète du compilateur a commencé en 2003, abandonnant l'idée de support multi-langage qui avait montré ses limites, et focalisant sur la facilité d'écriture des extensions. L'arbre syntaxique abstrait a été réduit à sept types de nœud seulement pour représenter tous les programmes. Ce nouveau compilateur s'est auto-compilé en 2004 (bien qu'avec des capacités réduites et une dépendance à C++ dans le code généré). Depuis, tout le développement se fait en XL.
En 2007, le langage offre un grand nombre de fonctionnalités avancées, mais manque encore d'une bibliothèque fonctionnelle.
Prédécesseurs.
XL a été inspiré par un grand nombre d'autres langages. Dans l'ordre alphabétique :

</doc>
<doc id="396817" url="http://fr.wikipedia.org/wiki?curid=396817" title="Clarion (langage)">
Clarion (langage)

Clarion est un langage de quatrième génération et un environnement de développement intégré propriétaire développé par Softvelocity, facilitant le développement d'applications de gestion (orientés principalement sur la manipulation des bases de données).
La dernière version de Clarion est la 7.2
Particularités.
C'est un langage procédural et orienté objet. Clarion fournit un environnement de développement intégré (IDE).
Il permet à la fois d'écrire des applications 16 et 32-bits. La manipulation des données peut se faire à travers des fichiers XML ou des bases de données SQL ou autres (comme Excel).

</doc>
<doc id="1666164" url="http://fr.wikipedia.org/wiki?curid=1666164" title="XProc">
XProc

XProc est une recommandation du W3C qui vise à définir un langage de transformation XML permettant de construire des pipelines XML.
Implémentations.
Il existe déjà des implémentations de la norme :
Ouvrage.
Un livre disponible librement est en cours d'écriture en anglais sur le site http://xprocbook.com/

</doc>
<doc id="1561554" url="http://fr.wikipedia.org/wiki?curid=1561554" title="Phrogram">
Phrogram

Phrogram (anciennement nommé Kid's Programming Language ou KPL) est un langage de programmation informatique conçu afin d'être compréhensible et accessible pour les débutants et les enfants. La première version est sortie en août 2005. L'actuelle version 2, conçue et publiée par Morrison Schwartz inc, est sortie en mai 2007.
Survol technique.
Phrogram est un langage de programmation procédurale ayant quelques similitudes avec le Visual Basic. Les codes sources en Phrogram peuvent aussi être portés automatiquement en VB.NET ou en C# par l'intermédiaire d'un IDE particulier. Le langage gère de nombreuses données de type : scalaires ou complexe, incluant leurs structures. 
Phrogram est pour le moment supporté uniquement par les systèmes d'exploitation Windows, à partir de Windows 2000. 
Un programme en Phrogram se présente sous la forme de blocs imbriqués les uns dans les autres.
Phrogram est organisé sous forme d'un unique bloc, où les blocs de méthodes et fonctions sont définis. Lesdites fonctions et méthodes en KPL sont réutilisables. Les fonctions renvoient toujours une valeur, tandis que les méthodes n'en renvoient pas forcément. Les structures de données sont définies par l'intermédiaire du "Program scope". Les variables doivent quant à elles, être définies et typées au moment de leur déclaration. 
Le langage est étroitement liée à Microsoft Framework .NET, et fournit beaucoup de fonctions et méthodes runtime pour communiquer avec cette plate-forme. . La compagnie qui distribue le langage (Morrison-Schwartz), est en partie possédée par Jon Schwartz, un ancien gestionnaire de programmes pour Microsoft.
Graphismes en KPL.
Le KPL est un langage éloigné du langage machine. Pour créer un jeu par exemple, KPL dispose d'une bibliothèque graphique de manipulation de sprites. Un grand nombre de format d'images y sont supportés, seuls 65 images sont fournies par défaut avec KPL.
Un moteur 3D succinct est aussi à disposition.
Historique.
Jonah Stagner a commencé le développement de KPL quand il a voulu enseigner à ses enfants la programmation, insatisfait des solutions disponibles. Dès lors, Jon Schwartz et Walt Morrison ont pris en main le projet. 
Le but premier de KPL a été de créer un langage neuf pour faire des programmes ludiques et petits. Phrogram a immédiatement attiré l'intérêt de novices grâce à la facilité d'écriture de programmes aux interfaces, musiques et animations attirantes. 
Le second but pour Phrogram est de fournir un nouveau langage avec quelques recettes de grands langages (comme le C++, le Java, Visual Basic ou encore le C#) et une syntaxe similaire à Visual Basic pour permettre un changement vers ces langages le plus facilement possible. 
En 2007, la version 2 est créée, et le langage renommé Phrogram. Il se base sur la seconde version du Framework .NET. Phrogram prétend être totalement compatible avec les autres langages qui utilisent .NET Framework, ainsi les bibliothèques compilées peuvent être utilisés par des applications .NET, et inversement. Il supporte donc la Programmation orientée objet (POO), permettant la définition de classes, leurs propriétés et les méthodes associées, ce qui donne aux débutants une introduction à la Programmation Orientée Objet.
Utilisateurs.
L'interface Utilisateur de Phrogram est disponible en 18 langues : anglais, espagnol, russe, chinois, allemand, français, italien, néerlandais, suédois, thaïlandais, grec, polonais, roumain, norvégien, portugais, danois, tchèque et catalan.
Toutes les traductions de l'anglais ont été faite par des volontaires et la compagnie continue à les encourager à continuer les traductions.
Bien que le KPL a été créé pour les 8-14 ans (d'où le nom Kid's Programming Language), il est approprié pour les débutants en programmation de tout âge, c'est pourquoi le nom a changé. Il est actuellement utilisé par des personnes plus âgées l'ayant téléchargé pour eux-mêmes plutôt que pour leurs enfants ou élèves. Phrogram est proposé pour les premiers cours de programmation à tous niveaux scolaires et est utilisé ou a été utilisé par des collèges, lycées et universités dans plusieurs pays, comme les États-Unis, la Grande Bretagne, le Canada, le Mexique, la Colombie, la Russie, l'Islande, la Suède, la République Tchèque, la Slovaquie, le Portugal, le Brésil, la Chine, Guam, les Philippines et la Nouvelle Zélande.
Phrogsoft, LLC.
La version 2 du KPL a été réalisée et renommée Phrogram, maintenue par The Phrogram Company sur le site du même nom, puis Phrogsoft, LLC. 
L'environnement de développement, qui inclut le compilateur, est propriétaire et vendu dans de multiples versions et modules complémentaires.

</doc>
<doc id="1578286" url="http://fr.wikipedia.org/wiki?curid=1578286" title="AT&amp;T (assembleur)">
AT&amp;T (assembleur)

AT&T est le nom donné à une forme de codage en assembleur pour l'architecture x86. Cette forme de codage est apparue avec les (AT&T est la société à l'origine d'UNIX). Cette forme est surtout utilisée sous UNIX. Cette syntaxe est utilisée par GAS, l'assembleur du projet GNU.
Concepts.
Par opposition à la syntaxe Intel, la syntaxe AT&T place les opérandes dans l'ordre "Source" avant "Destination".
Les principales caractéristiques de cette syntaxe sont :
Exemples.
Par exemple, une instruction en norme Intel :
Donnera en norme AT&T
L'équivalent en AT&T de
Est

</doc>
<doc id="29305" url="http://fr.wikipedia.org/wiki?curid=29305" title="Parrot (machine virtuelle)">
Parrot (machine virtuelle)

Parrot est une machine virtuelle à base de registres développée par la communauté Perl. Parrot sera la cible de l'interpréteur de Perl 6 en cours de spécification.
La plupart des autres machines virtuelles sont à base de piles. Les développeurs de Parrot considèrent comme un
avantage la ressemblance avec l'architecture des processeurs actuels. Cela permettra d'utiliser la littérature sur ce sujet pour le développement de la machine virtuelle Parrot. Parrot est aussi destiné à supporter d'autres langages dynamiques tels que
Ruby, Python, Tcl ou JavaScript.
Conformément à la tradition de cette communauté, Parrot est un logiciel libre distribué sous licence artistique (Perl) et sur de nombreuses plates-formes logicielles, parmi lesquelles GNU/Linux.
Historique.
Le projet a commencé comme un poisson d'avril. Simon Cozens a annoncé que Larry Wall et Guido van Rossum (les auteurs respectifs de Perl et de Python) unifiaient leurs efforts pour créer Parrot un langage synthèse de Perl et de Python. Ce nom fut ensuite adopté pour un projet au but similaire. Déjà, des petits langages sont supportés par Parrot et permettent de tester ses capacités.
Il est probable que Parrot vient du Sketch "Dead Parrot" des "Monty Python" (Comme le langage)
Techniques.
Parrot utilise des techniques éprouvées mais peu répandues en dehors du monde Lisp telles que le COW (ou Copy-On-Write), les continuations.
Le Copy-On-Write, c’est-à-dire copie sur écriture, permet de partager la mémoire d'objets différents tant qu'ils gardent la même valeur.
Extensibilité.
Parrot est conçu pour être extensible et pour être la cible de divers langages. On peut inclure l'interpréteur Parrot dans du code C. On peut appeler du code C de l'interpréteur. On pourra étendre dynamiquement les opérateurs. Parrot supportera l'objet.
Parrot Polymorphic Containers.
Parrot supporte dynamiquement et de manière efficace de nouveaux types grâce aux PMC ("Parrot Polymorphic Containers"). Lorsqu'on crée un type nouveau que l'on veut implémenter en C, on implémente les méthodes nécessaire pour ce type supportées par l'interface PMC. Certaines méthodes ont un nom et interface prédéfini. Elles sont accessibles rapidement car
le PMC se comporte alors comme une vtable à la C++. Mais un PMC peut avoir des méthodes qui lui sont propres et définir des
attributs. Chaque instance d'un PMC contiendra lesdits attributs.
Il ne faut pas confondre les PMC avec le support objet de plus haut niveau dont l'implémentation sera spécifique à tel ou tel langage utilisant Parrot mais qui utilisera des PMC prédéfinis par Parrot ou chargés dynamiquement.
Assembleurs.
Parrot comprend actuellement deux assembleurs : PASM ("Parrot ASseMbly" - Assembleur Parrot) et PIR ("Parrot Intermediate Representation" - Représentation Intermédiaire Parrot). Ces assembleurs sont partiellement orientés objet pour permettre de supporter nativement un nombre indéfini de types.
Historiquement, le premier assembleur sur Parrot, PASM est destiné à terme à devenir une représentation lisible du format binaire PBC (Parrot Bytecode).
PIR, un macro assembleur est l'assembleur de choix.
PIR est de plus haut niveau que PASM car il expose la fiction d'un nombre illimité de registres soulageant le programmeur qui n'a plus à associer manuellement variables et registres. Les registres peuvent être de type entier, numérique, chaîne de caractères ou PMC.
Exemples.
Opérations arithmétiques:
Chaîne de compilation.
Parrot supporte une chaîne de compilation assez complète. La classe HLLCompiler pilote cette compilation. Le programmeur peut définir les passes de la compilation. Une passe peut être appelée plusieurs fois de manière consécutive.
Passes typiques de compilations.
Patrick Michaud a écrit un moteur d'analyse syntaxique appelé PGE ("Parrot/Perl Grammar Engine") qui implante l'essentiel des règles Perl 6 telles que spécifiées dans le synopsis 6. PGE génère typiquement un arbre syntaxique en format PAST ("Parrot Abstract Syntax Tree"). Cet arbre sera typiquement transformé par TGE ("Tree Grammar Engine"), outil de manipulation d'arbre. Finalement du code PIR sera émis.

</doc>
<doc id="1874735" url="http://fr.wikipedia.org/wiki?curid=1874735" title="Urbi">
Urbi

Urbi est une plate-forme logicielle, sous licence libre BSD, utilisée pour le développement d'applications dans les domaines de la robotique et des systèmes complexes.
Urbi intègre une architecture distribuée de composants en C++ appelée UObject, ainsi qu'un langage de script parallèle et événementiel appelé urbiscript. UObject facilite l'intégration d'objets C++ ou Java dans le langage, et permet leur exécution locale ou distante, tandis qu'urbiscript agit comme un outil d'orchestration pour coordonner les différents composants et leurs interactions.
Le langage urbiscript.
Urbi a été initialement développé depuis 1999 par Jean-Christophe Baillie au laboratoire de Robotique Cognitive de l'ENSTA ParisTech, à Paris. Il est maintenant développé par la société Gostai, fondée en 2006.
Le langage urbiscript est un langage de script qui peut être décrit comme un langage d'"orchestration" : de même que Lua dans le domaine du jeu vidéo, Urbi peut intégrer des composants C++, les parties algorithmiques gourmandes en CPU étant allouées aux composants C++/Java, tandis que la description des modèles comportementaux généraux restent du domaine du langage de script, qui est plus flexible, plus facile à maintenir, et qui permet des interactions dynamiques durant l'exécution du programme. Le langage urbiscript apporte de nouvelles abstractions utiles lors du développement, les concepts de programmation parallèle et de programmation évènementielle faisant partie intégrante du langage. La spécification de comportements concurrents et la réaction à des évènements étant des exigences clefs de la plupart des applications de robotique et d'intelligence artificielle, Urbi est de fait particulièrement adapté à ce type d'applications.
Outre sa flexibilité et sa modularité, le point fort du langage urbiscript est sa simplicité, offrant une interface intuitive aux débutants, mais également des fonctions avancées aux développeurs confirmés.
Exemples.
L'exemple ci-dessous montre comment écrire une boucle vision/action de suivi de balle en Urbi : "headYaw" et "headPitch" représentent deux objets moteurs (des composants matériels, c'est-à-dire des drivers), "ball" est l'objet (composant logiciel) représentant la balle détectée :
"whenever" est utilisé pour déclencher un bloc de code de façon répétée tant que la condition associée reste vraie. Le signe « & » est utilisé pour spécifier que deux commandes (ou groupes de commandes) doivent être lancées exactement au même instant et exécutées en parallèle.
Un autre mot-clef événementiel est "at", qui déclenche le code associé une fois seulement, lorsque la condition invoquée devient vraie :
Toute commande (ou groupe de commandes) est « marquable », ce qui permet plus tard si besoin de l'annuler, de la bloquer ou de la geler :
Dans l'exemple ci-dessus, la virgule à la fin de la commande permet l'exécution en tâche de fond de la commande qui la précède, entrainant la poursuite de l'exécution du programme et en particulier à la commande 'at' qui suit de s'exécuter sans attendre la fin de la boucle infinie.
Architecture de composants UObject.
L'architecture de composants UObject, actuellement basée sur la bibliothèque C++ UObject, permet d'interfacer n'importe quel objet C++/Java avec Urbi/urbiscript, rendant les méthodes et les attributs sélectionnés du code C++ visibles directement depuis le langage de script. Des indicateurs peuvent être positionnés pour permettre de prévenir le composant C++ de tout changement effectué sur les attributs de l'objet par le langage urbiscript. 
Un UObject peut être utilisé localement, soit en le liant statiquement lors de la compilation, soit par chargement dynamique ultérieur. L'objet C++ partage alors directement la mémoire du noyau Urbi, permettant une intégration efficace. Il s'agit d'une utilisation typique pour les composants critiques tels que les drivers de moteurs ou de capteurs. Ce même objet C++ peut également être utilisé sans modifications en tant que composant distant. Dans ce cas, il devient un programme autonome qui est exécuté avec comme paramètre l'adresse IP du moteur Urbi. Dans les deux cas, l'objet apparaitra et sera traité dans Urbi comme s'il était un objet natif.
Les composants développés par la communauté peuvent être trouvés et échangés sur le site web communautaire Urbiforge.
Robots et simulateurs compatibles Urbi.
Livrés :
Non maintenus :
Environnement de développement.
Urbi permet d'utiliser Gostai Studio qui intègre un éditeur de comportements pour créer graphiquement des machines à états finies hiérarchiques. Gostai Lab est une autre application permettant de réaliser rapidement des interfaces utilisateur par simple glisser-déposer de widgets sur une page de composition.

</doc>
<doc id="1876473" url="http://fr.wikipedia.org/wiki?curid=1876473" title="X++">
X++

X++ est un langage de programmation orienté objet proche du C++ et du Java.
MorphX est une plateforme pour construire les systèmes complexes de gestion de comptabilité et d'entreprise, la langue X++ inclut un certain nombre de commandes communes de SQL comme partie intégrée du langage.
Les programmeurs employant X++ peuvent accéder aux classes existantes de Dynamics AX de Microsoft qui fournit la fonction qui s'étend de l'entrée-sortie de base et de la demande de transferts aux commandes de modification dans le temps d'exécution graphique de l'interface utilisateur. Ces classes peuvent être prolongées pour fournir le nouveau comportement.
X++ fournit la vérification étendue, suivie d'un deuxième niveau de la vérification d'exécution. Si aucune référence ne se rapporte à un objet particulier, cet objet est supprimé.

</doc>
<doc id="1884878" url="http://fr.wikipedia.org/wiki?curid=1884878" title="HAL/S">
HAL/S

HAL/S (High-order Assembly Language/Shuttle) est un langage de programmation temps réel utilisé par la NASA pour la navette spatiale.

</doc>
<doc id="6824" url="http://fr.wikipedia.org/wiki?curid=6824" title="YaBasic">
YaBasic

YaBasic, qui signifie "Yet Another Basic", est un interprète du langage BASIC pour les plateformes Unix, Windows et PlayStation 2. Similaire au Commodore BASIC du Commodore 64, il supporte le mode graphique couleur et a des possibilités d'impression. Il est aussi relativement petit : environ 200 kilooctets.
Variables.
Types.
Le langage yabasic utilise deux types de variables :
On notera aussi les choses suivantes :
Déclarations.
En règle générale, les variable ne sont pas déclarées en yabasic mais il y a des exceptions :
Un tableaux global se déclare avec dim ou redim (ces deux mots-clés sont synonymes).
Qu'il s'agisse ou non d'un tableau, une variable locale se déclare avec local.
Qu'il s'agisse ou non d'un tableau, une variable statique se déclare avec static.
Exécutables.
Yabasic permet la création d'exécutables mais, lors d'une telle action, le fichier n'est pas compilé mais combiné à l'interpréteur. Par conséquent, le code source ne peut pas être caché et peut toujours être visualisé à l'aide d'un éditeur de texte adapté (comme SciTE ou Notepad++).
Exemple de programme.
Un programme de type "Hello world" en YaBasic :
codice_1
Versions.
YaBasic fut créé par Marc-Oliver Ihm, qui a annoncé en août 2007 que la version 2.763, sortie deux ans plus tôt, serait probablement la dernière version du logiciel. Cela dit, ce logiciel étant open source, une version 2.764 a été publiée depuis et une version 3 est en cours de développement.
La version PlayStation 2.
La version pour PlayStation 2 est incluse gratuitement avec les consoles vendues en Europe, Asie et Océanie. Le disque de démo contenant l'interprète YaBasic est un disque PAL et n'est pas prévu pour les marchés américains et japonais. Les programmes peuvent être enregistrés sur des cartes mémoires et ainsi échangés entre amis.

</doc>
<doc id="1997055" url="http://fr.wikipedia.org/wiki?curid=1997055" title="General algebraic modeling system">
General algebraic modeling system

General Algebraic Modeling System (GAMS) est un logiciel de modélisation mathématique.
GAMS a été le premier langage de modélisation algébrique (Algebraic modeling language ou AML) et est formellement similaire aux langages de programmation utilisés communément.
Les modèles sont décrits en formulations algébriques concises qui sont lisibles à la fois par les humains et par les machines.
GAMS est largement utilisé en modélisation économique et en particulier pour implémenter des modèles d'équilibre général calculable, tel que GTAP.

</doc>
<doc id="2007625" url="http://fr.wikipedia.org/wiki?curid=2007625" title="Lustre (langage)">
Lustre (langage)

Lustre est un langage de programmation synchrone, déclaratif, et par flots. Il possède une définition formelle, et est utilisé pour la programmation des systèmes réactifs. Son développement a commencé au début des années 1980, dans le cadre d'un projet de recherche. Il est entré dans le monde industriel en 1993, lorsque la société Esterel Technologies a publié l'environnement commercial SCADE, dont il constitue le cœur. Lustre est désormais utilisé pour la conception de logiciel critique dans l'aéronautique (Airbus, Eurocopter, Dassault, Pratt & Whitney), le ferroviaire (Eurostar) et les centrales nucléaires (Schneider Electric).
SCADE.
SCADE est un environnement de développement intégré diffusé par Esterel Technologies, dont le nom signifie "Safety Critical Application Development Environment". Il est destiné à la conception de systèmes critiques.
Il est basé sur le langage Lustre, et permet de générer du code en langage C ou Ada.
Il peut être qualifié DO-178B niveau A par ses utilisateurs, ce qui explique sa popularité en aéronautique.

</doc>
<doc id="2093132" url="http://fr.wikipedia.org/wiki?curid=2093132" title="C Intermediate Language">
C Intermediate Language

C Intermediate Language (CIL) est un langage intermédiaire, sous-ensemble simplifié du langage de programmation C.
C'est également un ensemble d'outils libres publiés sous licence BSD pour:
CIL est utilisé par CCured, un compilateur qui compile un programme écrit en C en un code offrant un typage sûr en analysant l'utilisation des pointeurs et en insérant des vérifications à l'exécution là où le typage ne peut pas être déterminé statiquement.

</doc>
<doc id="1153870" url="http://fr.wikipedia.org/wiki?curid=1153870" title="CLU (langage)">
CLU (langage)

CLU est un langage de programmation créé au Massachusetts Institute of Technology (MIT) par Barbara Liskov et ses étudiants entre 1974 et 1975.

</doc>
<doc id="2181596" url="http://fr.wikipedia.org/wiki?curid=2181596" title="Algol 68">
Algol 68

Algol 68 est un langage de programmation universel dérivé du langage Algol 60, principalement conçu par des Européens.
Principe.
Au-delà d'Algol 60, l'objectif des concepteurs d'Algol 68 était d'offrir un langage de programmation universel, résolument innovant, dérivant sa puissance d'une conception orthogonale.
En Algol 68,
Niklaus Wirth qui faisait à l'origine partie du groupe de travail a refusé l'innovation extrême d'Algol 68 et a fait sécession pour proposer Algol W qui deviendra par la suite Pascal.
Syntaxe.
La syntaxe a été définie à l'aide d'une grammaire indépendante du contexte, à deux niveaux, qui porte le nom de son concepteur Adriaan van Wijngaarden. Le Rapport Révisé (1973) a montré que la grammaire d'Algol 68, proposée par van Wijngaarden, reconnaît tout programme Algol 68 valide. En effet, elle formalise aussi les contraintes contextuelles et/ou sémantiques du langage, décrites antérieurement en langue naturelle de façon plus ou moins ambiguë. 
Réalisation.
L'analyse syntaxique d'Algol 68 a été implantée dans les premiers compilateurs par du code "ad hoc" ajouté à un analyseur lexical traditionnel. 
Algol 68R est le dialecte traité par le premier compilateur, réalisé en 1970 au Royal Radar and Signal Establishment de Malvern (UK).
Voir aussi.
Bibliographie.
Groupe Algol de l'AFCET. "Définition du langage algorithmique ALGOL 68" ; présent. et trad. française du Report on the algorithmic language Algol 68 éd. par J. Buffet, P. Arnal, A. Quéré - 1972 - Hermann (Actualités scientifiques et industrielles) - VII-222 p. ; 24 cm
Lindsey C.H., "Informal Introduction to Algol 68", 1977, North Holland Publishing Cy. 
Woodward P.M. and S. G. Bond S. G., "Algol 68-R Users Guide", (2nd Second edition), 1974, Her Majesty's Stationary Office.
Cleveland & Uzgalis "Grammars for Programming Languages", 1977, Computer Science Library, Elsevier. 

</doc>
<doc id="733518" url="http://fr.wikipedia.org/wiki?curid=733518" title="ATLAS Transformation Language">
ATLAS Transformation Language

ATLAS Transformation Language (ATL) est un langage de transformation de modèles plus ou moins inspiré par le standard QVT de l'OMG. Il est disponible en tant que plugin dans le projet Eclipse . On peut trouver plus d'informations sur le langage ATL, sur son environnement de développement ainsi que sur les bibliothèques de transformations sur le site de l'université de Nantes.
ATL est un prototype académique de composant de transformation de modèles du projet Eclipse Modeling. Sont également annoncés deux autres composant, l'un en provenance de Compuware, l'autre de Borland. Des ponts entre ces trois composants sont prévus.
Pour toute information sur la transformation de modèles à modèles, on consultera le groupe de news suivant: M2M newsgroup qui donne les dernières informations sur l'évolution de la pratique dans ce domaine. Rappelons que la fondation Eclipse est désormais (janvier 2007) membre de l'OMG.
Les plugins Eclipse sont distribués sous la licence libre EPL.

</doc>
<doc id="2481026" url="http://fr.wikipedia.org/wiki?curid=2481026" title="High Level Assembly">
High Level Assembly

HLA est un programme assembleur pour l'architecture IA-32. Le nom signifie "High Level Assembly". HLA est écrit en langage assembleur et existe pour les systèmes Windows, Mac OSX, GNU/Linux, et FreeBSD.
Il a été écrit par Randall Hyde dans le but d'enseigner l'assembleur dans les meilleures conditions possibles, aujourd'hui c'est un assembleur qui n'a pas à envier aux équivalents commerciaux.

</doc>
<doc id="2244544" url="http://fr.wikipedia.org/wiki?curid=2244544" title="LCM (langage)">
LCM (langage)

LCM (Logic Control Modeler) est un langage de programmation de type synchrone. Il est développé par la société Dassault Systèmes.

</doc>
<doc id="2727558" url="http://fr.wikipedia.org/wiki?curid=2727558" title="JRuby">
JRuby

JRuby est une implémentation de l'interpréteur de Ruby en Java développé par la JRuby team. C'est un logiciel libre à sources ouvertes, sous la triple licence CPL/GNU GPL/GNU LGPL.
Il permet d'améliorer les applications existantes en Java en y apportant la souplesse et rapidité du prototypage et du developpement du langage Ruby. Il est utilisé notamment dans le secteur bancaire, dans lequel Java a eu un fort impact.

</doc>
<doc id="2802173" url="http://fr.wikipedia.org/wiki?curid=2802173" title="Qi (langage)">
Qi (langage)

Qi est un langage de programmation fonctionnelle créé par Mark Tarver, introduit en avril 2005 et 
distribué sous licence GPL. Qi est écrit en Lisp. Il inclut la plupart des fonctionnalités communes 
à la programmation fonctionnelle: le filtrage, la curryfication, inférence de types, typage statique, 
typage dynamique, la garde et l'application partielle.
Ce langage a remporté en 2003, le prix "Promising Invention Award" de l'Université d'État de New York.
La base du langage Qi.
Par certains côtés, Qi se veut une simplification du langage Lisp. Les fonctions utilisent la notation préfixée. 
Un programme qui affiche "Hello World" sur la sortie standard :
Les listes se construisent avec [ ... ] et les éléments sont séparés par un espace.
La fonction factorielle définie en utilisant le "filtrage" :
Une fonction "anonyme" qui multiplie par 2.
Une fonction "membre" utilisant le filtrage sur les listes. (Qi suit la syntaxe conventionnelle 
du Edinburgh Prolog pour le filtrage, sauf que des espaces sont utilisées au lieu de la virgule pour 
séparer les éléments.)
Une fonction utilisant la garde qui cherche le premier nombre plus grand que N dans une liste.
Qi Prolog.
Qi Prolog est une version du langage Prolog mise en œuvre en Qi, en utilisant la syntaxe standard d'Edinburgh. 
Voici un exemple de base en Qi Prolog:
Et pour interroger la base de connaissance Prolog:

</doc>
<doc id="2817965" url="http://fr.wikipedia.org/wiki?curid=2817965" title="DialogOS">
DialogOS

DialogOS est une plateforme de développement pour système informatique capable de parler avec l’utilisateur. DialogOS utilise un organigramme de programmation, il est donc possible d'utiliser DialogOS sans avoir de profondes connaissances informatiques. Le programme comprend aussi une extension pour commander les robots de type Lego Mindstorm NXT avec la voix. Actuellement l'anglais et l'allemand sont directement supporté par DialogOS.
DialogOS est principalement utilisé dans les cours informatiques des écoles ou dans des universités, pour apprendre la programmation ainsi que les principes de la création d'un dialogue électronique.
Lego Mindstorm NXT.
DialogOS supporte directement les robots de la gamme Lego Mindstorm NXT. Les capteurs suivants fonctionnent directement avec le système:
Il est également possible « d'émuler » d'autre capteurs, comme le capteur de couleurs, en les utilisant par exemple en tant que capteur ultrasonique.

</doc>
<doc id="2843208" url="http://fr.wikipedia.org/wiki?curid=2843208" title="Vala (langage de programmation)">
Vala (langage de programmation)

Vala est un langage de programmation compilé, dont l'objectif est de fournir les bénéfices des langages de programmation modernes (comme la POO) aux développeurs de la plateforme GNOME qui utilisent GLib et son système GObject.
Sa syntaxe est basée sur celle de C# mais il ne nécessite pas d'environnement d'exécution. Vala est transformé en code C, lui-même compilé en code machine natif. Les avantages d'une telle chaîne de compilation sont de produire des logiciels qui requièrent moins de mémoire vive et qui s'exécutent plus rapidement.
De plus, ce passage par l'étape C rend possible l'utilisation des bibliothèques C au moyen d'interfaces définies dans les fichiers Vapi. Des fichiers Vapi sont fournis avec Vala pour une grande partie de la plateforme GNOME, ainsi que pour d'autres bibliothèques.
Par exemple, le logiciel Shotwell ou le greffon Arte+7 pour Totem sont écrits en Vala.
Exemple de code.
Le programme « Hello World » :
Le programme « Hello World » programmation orientée objet :

</doc>
<doc id="2882346" url="http://fr.wikipedia.org/wiki?curid=2882346" title="A-0 System">
A-0 System

A-0 System est le premier compilateur développé pour un ordinateur. Il a été écrit par Grace Hopper en 1951 et 1952 pour l'UNIVAC I (celle-ci fut plus tard à l'origine de COBOL).
Description.
A-0 était plus un « chargeur de programme » ou un éditeur de liens que ce que l'on appelle aujourd'hui un compilateur. Il permettait de décrire un programme comme une séquence de sous-programmes ayant des paramètres. Les sous-programmes étaient identifiés par un code numérique et leurs paramètres étaient écrits directement après le code de chaque sous-programme. Le « système A-0 » convertissait cette description en code machine exécutable sur l'ordinateur cible.
Évolution.
A-0 fut suivi de A-1, A-2, A-3 (ARITH-MATIC), AT-3 (MATH-MATIC) et B-0 (FLOW-MATIC).

</doc>
<doc id="2898489" url="http://fr.wikipedia.org/wiki?curid=2898489" title="AspectJ">
AspectJ

AspectJ est une extension orientée aspect, créée à Xerox PARC, pour le langage de programmation Java. Cette extension est disponible dans les projets open-source Eclipse, de manière autonome ou sous forme d'extension pour l'environnement de développement Eclipse. AspectJ est devenu le standard, du fait de son utilisation répandue, pour la Programmation orientée aspect en mettant l'accent sur la simplicité et la facilité de mise en œuvre pour les utilisateurs finaux. AspectJ se base sur la syntaxe du langage Java et s'intègre aux IDE pour afficher sa structure transversale depuis sa première publication en 2001.
Le tissage des aspects est réalisé sur les classes compilées. Ce tissage peut être établi au moment de la compilation du code source ou lors de l'exécution, lors du chargement des classes par la machine virtuelle.
Langage de description simple.
Tout programme Java est compatible AspectJ. Toutefois, AspectJ permet également aux programmeurs de définir des constructions spéciales nommées ""aspects"". Les "aspects" peuvent contenir plusieurs entités inutilisables par des classes standard.
On trouve :
Par exemple, ce "pointcut" fait correspondre l'exécution de n'importe quelle méthode d'instance d'un objet de type codice_2 dont le nom commence par codice_9 :
AspectJ supporte également des formes statiques limitées de vérification et réutilisation d'aspect basées sur les "pointcuts" (par héritage).

</doc>
<doc id="2931108" url="http://fr.wikipedia.org/wiki?curid=2931108" title="NQP">
NQP

NQP signifie Not Quite Perl (Pas Vraiment Perl). Ce composant de Parrot est un sous ensemble de Perl 6 destiné à l'écriture de compilateurs. Il utilise PGE pour l'analyse syntaxique.
Il est utilisé pour le bootstrap de Rakudo, un compilateur Perl 6.

</doc>
<doc id="2950251" url="http://fr.wikipedia.org/wiki?curid=2950251" title="BBj Language">
BBj Language

BBj, sigle de Business Basic on Java, est un langage de programmation édité par Basis international
C'est un langage issu de la famille Business Basic. Il est écrit en Java pour assurer un maximum de portabilité sur différentes plateformes (Windows, Unix/Linux, Solaris, Mac, etc.) et assure une compatibilité ascendante avec les versions précédentes de Business Basic (BBx, Pro5, OpenBasic).
Sa syntaxe permet de mélanger la syntaxe Business Basic traditionnelle, la programmation orientée objet et du code Java. Cette double syntaxe le rend accessible aux développeurs de Business Basic, tout en ouvrant la possibilité aux développeurs formés à Java de l'appréhender.
Son système de données est basé sur un système natif de fichiers ou sur une base de données (ex. MySQL) via des pilotes ODBC et JDBC. De plus, on peut accéder à ce système de données depuis des applications tierces par un syntaxe SQL.

</doc>
<doc id="2976380" url="http://fr.wikipedia.org/wiki?curid=2976380" title="Processing.js">
Processing.js

Processing.js est le portage par John Resig du langage de programmation Processing en JavaScript (au lieu de Java). Processing.js repose sur la balise canvas et les applications conçues avec Processing.js ne requièrent donc pas la machine virtuelle Java pour fonctionner. Le code source de Processing.js tient en en seul fichier compressé de moins de 10 Kio. 
Les programmes réalisés avec Processing.js peuvent être affichés de manière optimum par les navigateurs web compatibles HTML 5, tels que les versions des moteurs de rendu Gecko (version 1.9), WebKit et Presto (version 9.5). 
Il existe également une version de processing.js appelée Node-processing, pouvant donc être déployé sur un serveur d'application node.js.
Processing.js peut permettre de créer et de déployer facilement des applications Internet riches (RIA) multi plates-formes.

</doc>
<doc id="260294" url="http://fr.wikipedia.org/wiki?curid=260294" title="Visual Basic .NET">
Visual Basic .NET

Visual Basic .NET est un langage de programmation à la syntaxe similaire à celle de Visual Basic 6. 
Néanmoins, ces deux langages sont assez peu comparables dans la pratique tant l'évolution entre ceux-ci est énorme. Le principal changement étant sans conteste l'introduction de l'orientation objet dans le langage.
VB.NET permet de développer en .NET via Visual Studio, c'est-à-dire seulement sur les systèmes d'exploitation Windows (98, 2000, XP, Vista, 7). Il existe cependant un projet visant à porter la plateforme DotNet (et donc VB.NET) sous Linux, MacOS et OpenBSD. Ce projet s'appelle Mono et il permet déjà de faire tourner nativement des applications .NET 2.0.
Il est important de rappeler que tout programme VB.NET est compilé dans le même langage intermédiaire (IL) que C# ou tout autre langage de la plateforme DotNet.
Les IDE (environnements de développements).
L'IDE commun et incontournable de tous les langages DotNet est Visual Studio, mais celui-ci est payant.
Un IDE gratuit basé sur Visual Studio existe : Visual Basic Express.
D'autres IDE gratuits existent, comme SharpDevelop ou MonoDevelop, mais ceux-ci sont moins évolués que Visual Studio.
Versions.
Évolutions : de VB6 à VB7 (non-exhaustif).
Qu'est-ce qui différencie VB6 (Visual Basic 6) par rapport à VB7 (Visual Studio 2003) ? :
Évolutions : VB7 à VB8 (non-exhaustif).
Quelques nouveautés ont fait leurs apparitions entre VB7 et VB8, mais c'est surtout le passage du DotNet FrameWork 1.1 au 2.0 qui marque cette évolution. 
En voici tout de même un résumé :
Évolutions : VB8 à VB9 (non-exhaustif).
VB9 a évidemment implémenté toutes les nouvelles fonctionnalités de C#, ainsi que quelques autres :
Évolutions : VB9 à VB10.
VB10 (aussi appelé VBx) marque un tournant majeur dans l'évolution de VB. Outre le fait qu'il sera intégré dans le Framework 4, il devrait surtout combler totalement son "retard" par rapport à C# sur certains points (tout comme C# comblera son retard envers VB), vu que la "coévolution" des langages C# et VB.NET a été officiellement annoncée. Cela assure non seulement un futur stable à VB.NET, qui ne pourra pas être délaissé par Microsoft mais aussi une garantie que tout ce qui est faisable en C# le sera toujours aussi sous VB.NET (même si c'est d'une autre façon).
Les fonctionnalités prévues pour VBx :
Quelques différences entre C# et VB.NET (non-exhaustif).
Voici les différences les plus flagrants entre VB.NET et C# (VB.NET et C# évoluant, les éléments de cette liste peuvent être obsolètes):
Une liste des différences (en 2005) entre C# et VB.NET plus complète existe ici.
Quelques exemples de code en VB.NET.
Gestion des exceptions.
VB.NET possède les instructions "try" et "catch" permettant de gérer les exceptions (comportement non attendu des instructions du programme).
Exemples :

</doc>
<doc id="96036" url="http://fr.wikipedia.org/wiki?curid=96036" title="QBasic">
QBasic

QBasic est un environnement de développement intégré pour une variante du langage de programmation BASIC, basé sur Quick Basic.
Il s'agit en réalité d'une version bridée de QuickBasic 4.5, dans le sens où elle ne permet que d'exécuter des programmes interprétés, la compilation étant rendue impossible.
D'autres différences mineures subsistent cependant au niveau du langage, notamment la disparition de certaines commandes. À l'inverse, les instructions permettant l'utilisation du langage machine (telles que codice_1) ont été intégrées à l'environnement, car il n'était plus possible de les lier au moment de la compilation.
L'exécutable de QBasic contient également les fonctionnalités de la commande "EDIT" de MSDOS, accessibles en tapant codice_2 dans la ligne de commande.

</doc>
<doc id="3172055" url="http://fr.wikipedia.org/wiki?curid=3172055" title="JMathLib">
JMathLib

JMathLib est un environnement de calcul informatisé et un langage de programmation, sous forme d'un logiciel libre, relativement compatible au niveau des sources avec MATLAB et GNU Octave et FreeMat. Il supporte nombre des fonctions de MATLAB et quelques fonctionnalités d'IDL. Et il possède quelques capacités de rendu volumique et de visualisation 3D.

</doc>
<doc id="3185298" url="http://fr.wikipedia.org/wiki?curid=3185298" title="QuickPascal">
QuickPascal

QuickPascal était un compilateur de Pascal pour MS-DOS, compatible avec Turbo Pascal et commercialisé par Microsoft en 1989.

</doc>
<doc id="581888" url="http://fr.wikipedia.org/wiki?curid=581888" title="High Performance Fortran">
High Performance Fortran

High Performance Fortran est un langage de programmation pour les machines parallèles.
Ce langage, est basé sur Fortran 90 avec l’ajout de directives de placement des données (align, distribute), de boucles parallèles (directive independent, construction forall) et quelques autres extensions.

</doc>
<doc id="3268991" url="http://fr.wikipedia.org/wiki?curid=3268991" title="Langage CLP">
Langage CLP

Le Langage CLP (Control Language Procedure) est un langage de programmation du système d'exploitation OS/400.
Apparu sous ce nom sur les systèmes 38 (ancêtres de l'AS/400), il intègre les fonctions d'un langage OS traditionnel.
Il s'appuie sur les commandes de l'OS400 et il a pour particularité d'être compilé.
Description.
La grammaire du langage est basée sur les commandes CL de l'OS400
Les commandes.
La plupart des commandes sont une combinaison d'un verbe (représentant une action) suivi d'un nom ou une phrase qui identifie le destinataire de l'action (l'objet concerné par l'action). Les différents "mots" de la combinaison sont en général sur trois lettres pour faciliter la mémorisation des commandes. Exemple : WRKJOB ⇒ Work + Job ⇒ Gérer un travail (ou tâche), celui en cours par défaut.
On peut utiliser une aide à la saisie (ou invite), on l'obtient en pressant la touche de fonction F4 qui propose tous les paramètres disponibles et leur valeurs possibles pour chaque commande. Cette aide à la saisie est elle-même accompagnée d'un texte d'explication pour chaque paramètre, accessible par la touche F1.
La création de procédures.
L'éditeur natif est SEU (Source Editor Utility), désormais on peut éditer ses sources depuis MS-Windows surcouche à Eclipse, fournie par IBM sous le nom de WDSC (Websphere Development Studio Client).
Contrairement au RPG, ou au COBOL, il n'est pas colonné. 
Ce langage peut sauf interdiction exclusive être décompilé simplement ce qui facilite la lecture des chaines d'exploitation. 
Futur.
Les évolutions sont liées aux versions de l'OS/400, et les vrais changements arrivent à partir des versions 5.x 
Voir aussi.
System_i, iSeries, OS/400 
Références.
Se reporter aux références indiquées dans l'article System_i

</doc>
<doc id="3285835" url="http://fr.wikipedia.org/wiki?curid=3285835" title="MicroMondes (logiciel)">
MicroMondes (logiciel)

"MicroMondes Pro, MicroWorlds JR et MicroWorlds EX" sont des micromondes, descendants directs de Logo (langage). Il s'agit de versions commerciales plus finies et avec un meilleur support pour les fonctions multimédia (particulièrement la version anglaise, plus récentes).
Présentation générale.
L'élément le plus connu de MicroMondes (et de Logo) est la tortue, qui peut être manipulée à l'aide d'instructions de manière à tracer des graphiques, exécuter des animations, des jeux interactifs ou d'autres types de simulations.
Les développements technologiques ont ensuite permis à la tortue de migrer vers un écran graphique (distinct de l'écran de commande (texte)), puis vers un écran mixte (avec une zone texte et une zone graphique). Les versions modernes combinent sans problèmes le texte et les graphiques.
MicroMondes est produit par LCSI et peut être utilisé sur un PC ou un Macintosh. Il existe dans plusieurs langues dont l'anglais, le français, l'espagnol, l'italien, le portugais, etc. 
Syntaxe.
Le vocabulaire original de MicroWorlds (ou Logo) est constitué de primitives. Celles-ci comportent quelques dizaines de commandes:
codice_1, codice_2, codice_3, codice_4, codice_5, codice_6 (fixe position), codice_7 (fixe couleur), codice_8 (vide texte)...
et quelques dizaines de rapporteurs:
codice_9 (rapporte la couleur actuelle), codice_10 (rapporte la position), codice_11 (rapporte le contenu le la boîte de texte portant ce nom)...
Certaines primitives requièrent une ou plusieurs données :
codice_12 (baisse crayon, ne requiert aucune donnée)<br>
codice_13 (requiert un nombre qui indique la distance à parcourir)<br>
codice_14 (requiert un mot ou une liste dont le premier élément sera retiré)
Ce vocabulaire peut être augmenté par l'utilisateur à l'aide de « procédures » dont voici un exemple :
codice_15
Les procédures sont créées dans un espace réservé à cet effet : la page ou l'onglet "procédures". Dans les versions les plus récentes de MicroMondes (spécifiquement MicroWorlds EX, MicroMundos EX, MicroMondi EX) les procédures peuvent aussi être intégrées à l'intérieur du "sac à dos" de l'objet tortue. 
Une procédure comporte trois parties: la ligne titre (le mot codice_16 suivi du nom de la procédure, au choix de l'utilisateur), le corps (la liste des instructions) et la ligne de codice_17. Dans l'exemple précédent, l'exécution de la commande "cabriole" revient à exécuter les instructions contenues dans la procédure: tourner à droite à un angle déterminé au hasard entre 0 et 359, et avancer une distance choisie au hasard entre 0 et 999.
Outre les procédures, les instructions peuvent être tapées dans le Centre de Commandes pour être exécutées "en mode direct".
MicroMondes est un logiciel d'usage général qui constitue une excellente introduction dans le monde de la programmation. Une version "junior", qui permet aux enfants en pré-lecture ou lecteurs novices de programmer à l'aide d'icônes plutôt qu'avec des instructions textuelles, existe dans d'autres langues. Une autre version permet, à l'aide de quelques primitives supplémentaires, de contrôler des éléments robotiques.

</doc>
<doc id="3306898" url="http://fr.wikipedia.org/wiki?curid=3306898" title="Objective-J">
Objective-J

Objective-J est un langage de programmation développé en même temps que le "" Cappuccino. Sa syntaxe est sensiblement identique à celle de Objective-C. Par ailleurs il partage avec Javascript la même relation qu'il y a entre l'Objective-C et le langage C : il s'agit d'une sorte de sur ensemble ajoutant la notion d'héritage ainsi que le typage dynamique du style Smalltalk/Objective-C au JavaScript. 
Les programmes écrits en Objective-J ont besoins d'être compilés avant de pouvoir être lancés dans un navigateur web. Cette compilation peut être effectuée directement dans le navigateur au moment de l'exécution par un compilateur qui compile les programmes Objective-J en pur code Javascript. Le compilateur Objective-J est écrit en JavaScript, de ce fait le déploiement de programme écrit en Objective-J ne nécessite pas de "" attaché au navigateur.
Application.
La première utilisation connue de l'Objective-J a été faite avec le ' Cappuccino pour le développement de l'application web 280Slides. Bien que l'Objective-J peut être utilisé (et a été conçu) indépendamment du ' Cappuccino, Objective-J a été, à la base, inventé pour supporter le développement web avec Cappuccino.
Syntaxe.
Objective-J est un sur-ensemble du Javascript, cela implique que n'importe quel code JavaScript valide est aussi valide dans du code Objective-J. L'exemple suivant montre la déclaration en Objective-J d'une classe nommée , cette classe est une sous classe de l'objet de base CPObject qui joue le même rôle que le NSObject en Objective-C/Cocoa. Même si ce n'est pas le même nom pour l'objet de base, ce code pourrait être aussi un exemple pour une déclaration de classe en Objective-C.
Tout comme en Objective-C, la déclaration des méthodes de classes et des méthodes d'instances commencent respectivement par '+' (plus) et '-' (moins).
Gestion de la mémoire.
Contrairement à l'Objective-C, les objets en Objective-J n'ont pas besoin d'être libéré étant donné qu'ils sont automatiquement libérés par le ramasse-miettes de JavaScript.

</doc>
<doc id="664176" url="http://fr.wikipedia.org/wiki?curid=664176" title="Fenix">
Fenix

Fenix est un compilateur gratuit pour le projet GNU. Il s'agit d'un projet de compilateur pour un langage de script dérivé de celui créé par Hammer Technologies pour le Game Development Suite « DIV Games Studio. » Cependant, quelques fonctionnalités ont été ajoutées le rendant incompatible avec beaucoup de jeux programmés avec DIV.
Fonctions.
Fenix est un langage interprété concentré sur le développement de jeux vidéo en 2 dimensions. Sa principale caractéristique, héritée de DIV, est la programmation pseudo-parallèle, c'est-à-dire qu'il donne la possibilité aux créateurs de programmer les différents processus (ennemis, personnages, etc.) séparément, le moteur se chargeant de les synchroniser. Ceci rend le développement de jeux vidéo à plusieurs beaucoup plus simple. La majeure partie des dispositifs est maintenant basée sur SDL. Ceci fait de Fenix un projet vraiment portable sur divers systèmes. D'autres fonctions incluent le support complet de la 2D (étirements, transparences, "blendops"…), la couleur en 16 bpp, le son (ogg, mod, it, s3m, wav), le support de joystick, le mode 7 et des extensions via les DLL.
Fenix est surtout un langage très simple et puissant. Il est un très bon outil de programmation pour les débutants et les professionnels.
Ports.
Officiels : Win32, Linux, Mac OS X, BSD, BeOS
Non officiel : GP32, GP2X, Dreamcast, PlayStation 2
État.
La version actuelle officielle est la 0.92a, mais la version la plus récente (en version beta) est la 0.93 preview 9.
Le projet est actuellement en cours de réécriture complète, ainsi que le noyau nu auquel d'autres fonctions peuvent être liées. De cette façon, tous les graphismes ou bibliothèques de son peuvent être liés à ce noyau, tirant profit de son dispositif de programmation pseudo-parallèle.
Ce compilateur (nommé Bennu) plus optimisé mais aussi plus compliqué à utiliser est entièrement compatible avec l'interpréteur 0.92a de Fenix.
Fonctionnement.
Fenix est présenté comme un logiciel passant par une console. Il existe divers IDEs disponible, dont le plus populaire FlameBirds2. Beaucoup d'autres IDEs peuvent être facilement adaptés pour l'utiliser.

</doc>
<doc id="22579" url="http://fr.wikipedia.org/wiki?curid=22579" title="PL/SQL">
PL/SQL

PL/SQL (sigle de Procedural Language / Structured Query Language) est un langage, conçu aux paradigmes procédural et structuré. Il est propriétaire, créé par Oracle et utilisé dans le cadre de bases de données relationnelles. Sa syntaxe générale ressemble à celle des langages Pascal et Ada.
PL/SQL est disponible dans Oracle Database (depuis la version 7), TimesTen In-Memory Database (depuis la version 11.2.1) et IBM DB2 (depuis la version 9.7).
Il permet de combiner des requêtes SQL et des instructions procédurales (boucles, conditions...), dans le but de créer des traitements complexes destinés à être stockés sur le serveur de base de données (objets serveur), comme des procédures stockées ou des déclencheurs.
Les dernières évolutions proposées par Oracle reposent sur un moteur permettant de créer et gérer des objets contenant des méthodes et des propriétés.
À la base, PL/SQL est un langage interprété, mais depuis la version 9i RC1, le code peut être compilé en code machine. Dans la version 9i d'Oracle database, le code est converti en C puis doit être compilé en librairies partagées (DLL sous windows), dans la version 10g le code machine est stocké dans le catalogue et depuis la version 11g il est stocké dans le "tablespace" système après compilation directe.
Comparaison avec les autres bases de données.
MySQL et Mimer SQL proposent un langage analogue dans le principe mais plus limité, le SQL/PSM de la norme SQL:2003, et plusieurs SGBD en utilisent un dérivé (IBM DB2 avec SQL-PL, PostgreSQL avec PL/pgSQL et PL/pgPSM). Quant à Microsoft et Sybase, ils utilisent un concurrent développé par Sybase, le T-SQL nettement plus limité que PL/SQL.
Concepts.
Blocs.
Tout programme PL/SQL doit se présenter sous forme de blocs. Voici la forme générale d'un bloc.
Un bloc PL/SQL comprend d'abord une partie dédiée à la définition de toutes les variables employées dans le bloc. Elle commence par l'instruction "DECLARE" et est facultative. La section principale commence avec l'instruction "BEGIN". Elle contient les instructions du programme. Si une variable est utilisée dans cette section alors qu'elle n'a pas été déclarée dans la section de déclaration, le compilateur générera une erreur. Enfin, la dernière section est appelée en cas d'erreur dans la section précédente. Elle commence par l'instruction "EXCEPTION" et on y traite l'ensemble des exceptions levées dans la section principale.
Structure du code.
PL/SQL permet de grouper les instructions dans des procédures et des fonctions, ces termes ont la même signification qu'en Pascal : une fonction est un bloc de code prenant des paramètres et qui effectue des traitements pour obtenir un résultat retourné, une procédure recouvre la même notion sauf qu'une procédure ne retourne pas de résultat. Les arguments passés aux procédures et fonctions peuvent lui être donnés en lecture seule ("IN"), en écriture ("OUT") ou en lecture-écriture ("IN OUT") ; le développeur peut également choisir le passage par valeur (comportement normal) ou par référence ("NO COPY").
Des fonctions et procédures peuvent être regroupées dans des unités nommées paquetages, elles sont alors accessibles sous le même espace de noms. D'une manière similaire aux modules de Pascal, la création d'un paquetage requiert l'écriture d'une spécification exposant le prototype des fonctions et procédures du paquetage, ainsi que des variables et types publics. En second lieu, l'implémentation du paquetage est faite séparément ; elle contient le code des procédures et fonctions ainsi que la déclaration d'éléments privés.
La version 8i a introduit le concept d'objet et les implémentations depuis la version 9i supportent la programmation orientée-objet avec notamment l'héritage. Une classe PL/SQL est décrite comme un type. Elle a une structure analogue à celle d'un package PL/SQL : d'abord la déclaration des méthodes, ensuite leur implémentation dans le "body".
Variables.
Les premiers types de variables à disposition sont les types SQL supportés par le serveur Oracle ("INTEGER", "VARCHAR", ...), mais il est possible de définir des types personnalisés.

</doc>
<doc id="3163905" url="http://fr.wikipedia.org/wiki?curid=3163905" title="Xlogo">
Xlogo

XLogo est un interpréteur Logo écrit en Java. C'est un logiciel libre distribué selon les termes de la licence GNU GPL.
XLogo supporte actuellement dix langues : le français, l'anglais, l'espagnol, le portugais, l'allemand, l'arabe, l'espéranto, le galicien, le grec et l'italien.
Le langage Logo.
Le principe majeur du langage Logo consiste à déplacer sur l'écran un objet généralement sous la forme d'une tortue, à l'aide de commandes élémentaires telles que :
À chaque fois que la tortue se déplace, elle laisse un trait derrière elle et on peut ainsi très vite réaliser de très jolis dessins.
XLogo est un langage de programmation capable non seulement de dessiner des formes, mais aussi de manipuler les mots, les fichiers, etc.

</doc>
<doc id="3442598" url="http://fr.wikipedia.org/wiki?curid=3442598" title="Factor (langage)">
Factor (langage)

Factor est un langage de programmation dynamique concaténatif, dont la conception et l'implémentation sont coordonnées par . Les principales influences de Factor sont Joy, Forth, Lisp et Self.
Comme les autres langages concaténatifs, Factor utilise une syntaxe postfixée, ce qui signifie que vous écrivez les arguments d'une fonction avant son nom. À titre d'exemple, afficher « hello world » se fait ainsi :
Définition d'une fonction calculant la factorielle d'un entier 
calcul de la factorielle de 10

</doc>
<doc id="10994" url="http://fr.wikipedia.org/wiki?curid=10994" title="Forth (langage)">
Forth (langage)

Forth est un langage de programmation , inventé par Charles H. Moore dans les années 1960.
Historique.
En 1958, un jeune informaticien nommé Charles Moore, chargé de calculer des trajectoires de satellites, entreprend, pour faciliter son travail quotidien, la construction d'une boîte à outils sous la forme d'un interpréteur de commandes. D'année en année, cet interpréteur est amélioré et rendu indépendant de la machine hôte. En 1968, il prend le nom de Forth, et en 1970, il est suffisamment mûr pour faire l'objet d'une première publication comme « Langage pour calcul interactif ».
1971 voit la première application d'envergure : Moore utilise Forth pour développer le logiciel de pilotage du radio-télescope de Kitt Peak (Arizona) sur deux mini-ordinateurs 16-bits. Il y est bientôt rejoint par Elizabeth Rather, qui devient le deuxième programmeur Forth. Par ses performances et sa souplesse d'emploi, l'application intéresse rapidement d'autres observatoires, et en 1976, Forth est adopté comme standard par l'Union internationale d'astronomie.
Après une première modernisation du logiciel de Kitt Peak en 1973, Moore et Rather fondent Forth,Inc., pour promouvoir le langage et ses applications. En 1976, une première version exécutable sur microprocesseurs 8-bits est disponible sous le nom de MicroFORTH.
En 1978 est créée une association, le "Forth Interest Group" (FIG), pour promouvoir une version « domaine public » du langage sur un maximum de processeurs, et publier la revue "Forth Dimensions". Le FIG-FORTH, légèrement différent du MicroFORTH, contribuera grandement à la diffusion du langage.
Le besoin de standardisation d'un langage que chacun peut modifier à sa guise devient manifeste. Une première tentative (FORTH77) aboutit au premier standard largement diffusé, FORTH79. Ce standard évolue quatre ans plus tard en FORTH83, mais des incompatibilités entre les deux versions engendrent des problèmes de portabilité, et sont à l'origine d'un clivage dans la communauté des programmeurs FORTH.
Dénomination.
Son nom est une contraction de l'anglais "fourth", qui signifie « quatrième » : c'était à l'origine un langage pour les machines de quatrième génération machines dotées de lecteurs de disquettes ; mais, à l'époque, la machine IBM utilisée ne permettait que des noms de cinq lettres (ce qui suggère qu'il s'agissait d'un IBM 1130). Forth utilisait des concepts novateurs pour l'époque : multiprogrammation et cache-disque notamment.
Principes.
Forth repose sur l'utilisation explicite de piles, alors que les autres langages utilisent des piles invisibles au programmeur.
Pile de données.
Une des importantes caractéristiques du langage est l'utilisation d'une pile de données pour passer des arguments entre les mots, qui sont les constituants d'un programme Forth. 
Un simple exemple : l'expression codice_1 sera traduite par la suite codice_2, dans la notation polonaise inversée.
Cette suite de mots agit sur la pile de données, son effet est
À partir des mots prédéfinis du langage, comme +, *, DUP (qui duplique l'élément en sommet de pile), SWAP (qui échange les
deux éléments du sommets), etc. le programmeur construit le vocabulaire de son application en définissant ses propres mots, qu'il réutilise ensuite :
Une conséquence importante de l'utilisation d'une pile est la quasi-suppression des noms de variables locales, qui deviennent inutiles.
Pile de retour.
Comme dans la quasi-totalité des langages, Forth utilise une pile pour stocker les adresses de retour des sous-programmes en cours d'exécution. L'originalité ici est de mettre cette pile à la disposition du programmeur, principalement pour un stockage temporaire de données, au moyen de deux opérateurs permettant les transferts pile de données - pile de retour.
Sous-programmes.
Un mot Forth est l'équivalent des sous-programmes, fonctions ou procédures dans les autres langages. Cependant, Moore décrit les mots plus comme des abréviations que comme des fonctions à la C. Le mot d'ordre en Forth est la factorisation, c'est-à-dire le découpage de l'application en petits mots dont la définition tient sur une ligne ou deux.
Les « mots » de Forth sont « compilés », c'est-à-dire convertis en une forme exécutable et ajoutés au dictionnaire des mots. La forme exécutable diffère suivant le compilateur/interpréteur utilisé : génération directe de code machine ou "bytecode" par exemple (il existe de nombreuses variantes intermédiaires).
Autres caractéristiques.
Il n'y a pas d'instruction GOTO. La syntaxe particulière de l'instruction IF...ELSE...THEN permet de résoudre de façon élégante le problème des "n+1/2 itérations" qui, en programmation structurée, aboutit à l'introduction d'une variable booléenne supplémentaire si l'on veut absolument éviter le GOTO.
Il n'y a pas d'opérateur d'affectation "=". Les variables ne sont pas des données, mais des pointeurs vers des zones de mémoire allouées explicitement par le programmeur, qui contiennent les données. Le transfert des données se fait par les deux opérateurs @ (fetch) et ! (store), qui correspondent aux instructions LDA (Load Accumulator) et STA (Store Accumulator) d'un assembleur, la pile jouant ici le rôle de l'accumulateur.
L'invocation de toto pousse l'adresse de la variable toto sur la pile. @ remplace cette adresse par la valeur contenue dans toto, à savoir 3.
A son tour, l'invocation de titi pousse l'adresse de titi sur la pile, qui contient à ce moment les deux valeurs 3 et adr(titi). Enfin, ! écrit 3 en mémoire à l'adresse titi, et laisse la pile vide.
Mise en œuvre.
Le mélange interprétation/compilation, associé à des techniques de compilation efficaces et à la possibilité offerte par nombre de systèmes de définir aussi de nouvelles primitives en assembleur, fait de Forth l'un des langages interprétés les plus rapides et les plus compacts.
Très proche du matériel, le Forth est un langage que l'on peut qualifier de « bas niveau », mais qui dispose de ressources qui lui permettent de se rapprocher du « haut niveau ». Le langage est en effet basé sur un petit nombre de primitives suffisamment élémentaires pour être implémentées directement « dans le silicium » (c'est-à-dire être les instructions d'un processeur matériel ; les primitives de Forth sont donc bel et bien un « langage assembleur » pour ces processeurs. Il existe quelques exemples de processeurs Forth).
Dans le même temps, le langage permet de définir des mots qui ont une action sur la compilation ; on peut ainsi définir de nouvelles structures de contrôle (par exemple la structure switch/case peut s'écrire à partir de la structure if/then/else). Cette caractéristique fait de Forth un langage extensible.
C'est ainsi qu'à partir de quelques primitives écrites en langage machine, on peut construire un interpréteur en ligne de commande, un assembleur, un compilateur, un éditeur de source. La compacité est extrême : sur une machine 8 bits, 7 kilooctets suffisent pour avoir un interpréteur en ligne de commande, dont 700 octets seulement de code machine, le reste étant constitué de tables de pointeurs. En ajoutant environ 5 ko, on dispose de l'éditeur, d'un assembleur, et d'un système rudimentaire de stockage sur disquettes, le tout fonctionnant sans système d'exploitation avec quelques kilooctets de mémoire vive, et tenant sur une simple disquette (source intégrale incluse) ; autrement dit un micro-environnement de développement capable de s'autocompiler à partir de son propre source depuis une plateforme disposant de ressources modestes comme les applications embarquées.
Un des aspects de Forth est de tenter de trouver un juste milieu entre la langue naturelle du programmeur et la « langue » artificielle du processeur, contrairement aux autres langages qui prennent nettement le parti du programmeur au détriment du processeur. Ce compromis donne au langage son aspect exotique et déroutant de prime abord, et requiert sans conteste une certaine capacité d'adaptation de la part du programmeur.
Le langage Forth a fait l'objet d'une normalisation officielle, l'ANS-FORTH, fondée sur les standards officieux précédents Forth-79 et Forth-84. La plupart des Forth commerciaux suivent cette norme. De par l'extrême facilité d'implémentation d'un interpréteur pour ce langage, il existe un nombre incalculable de systèmes Forth de domaine public, qui sont soit alignés sur le standard ANS-Forth (comme gforth de GNU), soit sont des dialectes plus ou moins éloignés de Forth (notamment ColorForth de Charles Moore), et ce pour à peu près toutes les plateformes, du Intel 8051 à Windows, en passant évidemment par Linux.
Utilisations.
Forth a été utilisé principalement dans des systèmes embarqués et des contrôleurs, en raison de leur caractère compact et de la facilité d'utiliser des mots définis en assembleur dans des programmes de plus haut niveau. Parmi les applications les plus prestigieuses, on relèvera sa présence sur quelques missions de la NASA.
Les ROM Open Firmware des produits d'Apple et de Sun, ainsi qu'une partie du boot de FreeBSD, étaient jusqu'à récemment écrites en Forth, permettant la portabilité du code de bas niveau entre les processeurs.
L'augmentation de performance des micro-contrôleurs permettant désormais la programmation des applications de ce type en langage C, désormais érigé en assembleur universel, l'utilisation de Forth régresse sur son terrain de prédilection. Plus généralement, la tendance étant à ce que le programmeur devienne une ressource interchangeable (ce qui permet déjà l'externalisation de certains développements) au détriment de l'expérience et de la compétence, l'utilisation de Forth ne peut que décliner.
Bien que la mort de Forth ait été annoncée maintes et maintes fois, et que d'aucuns le qualifieraient de moribond, de nouveaux programmeurs de divers horizons curieux et attirés par ses performances et ses conceptions remarquables s'y intéressent régulièrement et s'en inspirent ; la survie de quelques sociétés prestataires de services qui basent leur offre sur Forth et réalisent des développements pour des projets de pointe (gestion de trafic aérien par exemple), laissent à penser que Forth n'est pas une langue morte.
Voir aussi.
Bibliographie.
Historiquement, une des premières bibles Forth (techniquement Fig-forth) fut le livre de Kevin McCabe publié en 1983, traduit en français et publié en France en 1985.
Léo Brodie a écrit deux ouvrages considérés unanimement comme des références par la communauté Forth, qui les a mis en ligne. Le premier est un cours sur le langage, le second un précis de programmation et de style, traitant de sujets tels que l'architecture d'un programme, les différentes étapes du processus de programmation, la programmation ascendante et descendante, la factorisation, le choix des noms, etc.
Un ouvrage décrivant le fonctionnement interne et l'implémentation en liste chaînée sur processeur Z80 d'un langage très voisin de Forth :

</doc>
<doc id="1773425" url="http://fr.wikipedia.org/wiki?curid=1773425" title="Quartz Composer">
Quartz Composer

Quartz Composer est un langage de programmation visuel, fourni depuis Mac OS X 10.4 avec le logiciel Xcode, spécialisé dans le traitement et le rendu de données graphiques.
Réaliser un programme consiste à connecter entre eux des blocs de traitement. Quartz Composer utilise OpenGL, Core Image, Core Video, JavaScript pour créer des traitements qui peuvent être joués en tant que séquences Quicktime, être transformés en économiseurs d'écrans ou intégrés dans des applications Cocoa ou Carbon.

</doc>
<doc id="3450535" url="http://fr.wikipedia.org/wiki?curid=3450535" title="Modula-2">
Modula-2

Modula est un langage de programmation créé en 1977 par Niklaus Wirth à l'École polytechnique fédérale de Zurich. Sa syntaxe est une amélioration de celle du langage Pascal dont il reprend bon nombre de principes.
Modula est un langage de programmation compilé, procédural, fortement typé, modulaire, facile à lire et à apprendre. Il est conçu pour enseigner la programmation et faciliter le développement des projets de grande ampleur. 
Par rapport à Pascal, il ajoute :
En résumé, Modula 2 est plus puissant et plus complet que Pascal. La modularité étant mieux conçue et traitée qu'en C, Modula 2 s'avère plus fiable dans les grosses applications. 
Wirth a déclaré que ce langage était "celui qu'il aurait aimé concevoir quand il avait conçu Pascal". 
Dialectes et langages apparentés.
Algol W et Pascal (Niklaus Wirth, 1970) sont les ancêtres de Modula.
Oberon est un descendant direct de Modula. (Niklaus Wirth, 1985)
Modula a influencé les langages Java et C# 
dialectes
Caractéristiques du langage Modula.
La syntaxe générale de Modula est celle de Pascal. La différence majeure étant l'usage moins fréquent du mot clé "BEGIN", et le remplacement du mot clé "PROGRAM" par "MODULE", "IMPLEMENTATION MODULE" ou "DEFINITION MODULE" selon les cas.
Contrairement au langage Pascal, qui n'est pas sensible à la casse, les mots réservés et noms des éléments de base (fonctions, types et constantes) en Modula-2 sont obligatoirement écrits en majuscule.
exemple: Hello World écrit en Modula :
Typage fort et données brutes.
Modula est un langage fortement typé, qui interdit toute conversion entre deux types où il y a possibilité de perte d'information tout en permettant la manipulation de "données brutes" et non typées.
Les types de base sont INTEGER (nombre entier), REAL (nombre à virgule flottante), CHAR (caractère), et BOOLEAN. (booléen)
Modula offre de nombreuses possibilités de créer des types complexes tels que tableaux "ARRAY", enregistrements "RECORD", pointeurs typés "POINTER", énumérations, intervalles, groupe de flags "SET OF".
Modula offre la possibilité de créer des "callback" par l'utilisation de types "PROCEDURE".
En invoquant le module System, Modula offre aussi la possibilité de manipuler des informations "brutes" et non typées, grâce aux types génériques "BYTE" et "WORD" (octet), "ADDRESS" (pointeur non typé + nombre) et "BITSET" (groupe de "flags" non typé). Si un paramètre d'une fonction est de type "ARRAY OF BYTE" (tableau d'octets de taille quelconque), le paramètre pourra contenir en vrac "n'importe quel type d'information". On peut ainsi profiter des avantages de la programmation physique dans les modules où elle est nécessaire, et d'une sécurité maximale partout ailleurs.
Modules, interfaces, encapsulation et unité de compilation.
En Modula le mot clé MODULE sert à encapsuler des éléments tels que des variables, des types ou des fonctions, c'est-à-dire à les rendre invisibles de l'extérieur du module, afin de cacher les détails internes de la construction du module. 
Un module peut contenir d'autres modules. Dans un programme de grande dimension, un seul fichier exécutable peut contenir plusieurs fonctionnalités, le code source de chaque fonctionnalité peut être réparti sur plusieurs fichiers sources. Les fichiers sont alors compilés par petits groupes appelés "unités de compilation".
La compilation peut se faire en plusieurs étapes, une "unité de compilation" à la fois. 
Pour un programme ordinaire l'unité de compilation est composée d'un seul fichier source qui commence par "MODULE". 
Pour une bibliothèque l'unité de compilation est composée de deux fichiers source :
Pour utiliser dans un module B un élément (fonction, type, variable) provenant d'un module A, on ajoute au début du module B le mot clé "FROM" suivi du nom du module (ici A), puis du mot "IMPORT" et de la liste des éléments importés.
Primitives et bibliothèques.
Le langage Modula comporte seulement quelques instructions : INC, DEC, INCL, EXCL, CHR et ORD.
Dans les programmes écrits en Modula, la majorité des opérations se font par l'utilisation des primitives incluses dans un ensemble de bibliothèques fournies avec le compilateur. les fonctions dans ces bibliothèques peuvent varier selon le système et le compilateur.
Le langage offre la possibilité de créer des bibliothèques, et toutes les bibliothèques de primitives fournies avec le compilateur sont écrites en Modula, exception faite des bibliothèques SYSTEM et COROUTINES.
Chaque bibliothèque consiste en un fichier de définition "DEFINITION MODULE" et un fichier d'implémentation "IMPLEMENTATION MODULE". 
Dans le fichier de définition sont déclarés les éléments qui seront "rendu publics" et dont utilisables par les programmes qui exploiteront ce module. et dans le fichier d'implémentation se trouvent les éléments privés, ainsi que les instructions.
Programmation concurrente.
La programmation concurrente en Modula est basée sur les coroutines et les variables de contexte. le contexte étant l'instruction qu'une coroutine était en train d'exécuter à un moment donné (voir commutation de contexte).
Le type de données contexte s'appelle "PROCESS" en Modula-1 et Modula-2 et "COROUTINE" en Modula-3.
L'instruction "TRANSFER" permet d'arrêter l'exécution de la coroutine en cours "A", et de relancer l'exécution d'une coroutine quelconque "B". le contexte d'exécution de la coroutine "B" est passé en paramètre. La coroutine "A" sera suspendue - l'exécution de l'instruction TRANSFER est ne se terminera pas - jusqu'à ce qu'une autre coroutine utilise l'instruction "TRANSFER".
L'instruction "IOTRANSFER" permet d'arrêter l'exécution de la coroutine en cours "A" et de relancer l'exécution d'une coroutine quelconque "B" jusqu'à ce qu'une interruption matérielle survient. La coroutine "A" reste suspendue jusqu'à la venue de l'interruption.
Une instruction permet de créer un nouveau contexte pour une coroutine.
Ces trois instruction suffisent à réaliser un noyau multitâche préemptif, des thread légers, ainsi que des mécanismes de synchronisation. Des mécanismes qui sont souvent inclus dans les bibliothèques fournies avec le compilateur Modula.
Programmation de haut niveau et portabilité.
Modula est un langage de programmation de haut niveau, c'est-à-dire qu'il permet d'écrire un programme sous une forme proche de la pensée humaine, et cache les détails techniques de la machine sur laquelle le programme va être exécuté.
Un langage de programmation de haut niveau permet d'écrire des programmes portables. C'est-à-dire qu'un programme écrit pour un système peut, moyennant quelques changements mineurs, être compilé de nouveau sur un autre système.
Pour faciliter les modifications, les éléments du langage qui peuvent différer d'un système à l'autre sont encapsulés dans les modules SYSTEM et COROUTINE. Il y a notamment les types de données de bas niveau BYTE, ADDRESS, BITSET, PROCESS et COROUTINE. ainsi un module qui risque de demander des changements peut être repéré facilement par le fait qu'il importe des éléments du module SYSTEM ou COROUTINE.
La majorité des instructions dans un programme écrit en Modula consistent à utiliser des fonctions incluses dans les bibliothèques fournies avec le compilateur. Tout comme dans le langage C, il existe une suite de bibliothèques standard et communes à tous les compilateurs, suite à laquelle se rajoutent diverses bibliothèques, différentes d'un compilateur à l'autre.
Lilith.
Lilith est le nom d'une station de travail conçue en 1978 par L'école Polytechnique Fédérale de Zürich, et dont l'environnement logiciel est entièrement écrit en Modula.
Cet environnement inclut un compilateur, un système d'exploitation, un environnement graphique et divers outils.
Le développement de la machine était à la fois un exercice grandeur nature pour les élèves des facultés d'électronique et d'informatique de l'université, et une occasion d'évaluer les qualités et les défauts de Modula sur les projets de grande ampleur.
Le processeur utilisait un M-code, et un bus rapide pour l'affichage graphique.

</doc>
<doc id="3468721" url="http://fr.wikipedia.org/wiki?curid=3468721" title="PL/M">
PL/M

Le PL/M (sigle de "Programming Language for Microcomputers") est un langage de programmation développé par Gary Kildall en 1972 pour Intel pour ses microprocesseurs.
Le langage incorpore des idées empruntées aux langages PL/I, ALGOL et XPL, et possède un préprocesseur de macros intégré. Contrairement aux langages évolués contemporains tels que Pascal, C ou C++, il ne possède pas de routines d'entrées-sorties standard. Par contre, étant spécialement conçu pour certains processeurs, il est nettement plus efficace que d'autres langages pour certaines opérations de bas niveau.
Le système opérationnel CP/M ainsi que le "firmware" pour le "Service Processor Component" de l'AS/400 ont été écrits en PL/M. On a écrit des compilateurs PL/M pour les contrôleurs/processeurs suivants : Intel 4004, 8008, 8080, 8085, 8051, 80196, 8086/8088, 80186/80188, 286, et 386.
Quoique PL/M ne soit plus supporté par Intel, il existe toujours, du fait la longévité de certains systèmes informatiques l’utilisant encore, des compilateurs et des outils de traduction PL/M vers C.

</doc>
<doc id="3452000" url="http://fr.wikipedia.org/wiki?curid=3452000" title="OpenCL">
OpenCL

OpenCL (Open Computing Language) est la combinaison d'une API et d'un langage de programmation dérivé du C, proposé comme un standard ouvert par le Khronos Group. OpenCL est conçu pour programmer des systèmes parallèles hétérogènes comprenant par exemple à la fois un CPU multi-cœur et un GPU. OpenCL propose donc un modèle de programmation se situant à l'intersection naissante entre le monde des CPU et des GPU, les premiers étant de plus en plus parallèles, les seconds étant de plus en plus programmables. 
Présentation.
OpenCL distingue le processeur hôte (processeur central faisant office de chef d'orchestre) des périphériques (CPU, GPU, ou autre) dont la mission est d'exécuter des noyaux de calcul intensifs. OpenCL distingue donc d'un coté l'application tournant sur le processeur hôte (et qui va appeler l'API OpenCL), et de l'autre coté les noyaux qui sont programmés en OpenCL-C (et dont la vocation est d'être exécutés sur les périphériques).
OpenCL permet d'exprimer du parallélisme de tâches mais aussi du parallélisme de données sous deux formes ; SPMD (Single Program Multiple Data) et SIMD (Single Instruction Multiple Data), le tout de manière hiérarchique. Un graphe de tâches peut être créé dynamiquement via l'API OpenCL. Chaque tâche peut être représentée soit sous forme d'une instance unique (appelée tâche), soit sous forme d'une collection d'instances (appelée NDRange) d'un même noyau. Les NDRanges peuvent être de 1, 2 ou 3 dimensions. Chaque instance de kernel appartenant à un NDRange est appelée work-item. Le NDrange peut lui-même être structuré en work-groups, ce qui permet aux work-items à l’intérieur des work-groups de partager des données et de se synchroniser via des barrières.
Si parmi certains de ses objectifs techniques, OpenCL semble se rapprocher de C pour CUDA, modèle de programmation propriétaire de la société Nvidia, OpenCL a des objectifs plus larges car n'étant pas uniquement dédié aux GPU. Dans le monde du calcul haute performance ou du jeu, OpenCL permettra de tirer parti de la puissance des processeurs graphiques, des CPU multi-cœurs ou d'autres systèmes de calcul intensifs tels le CELL d'IBM, qui équipe notamment la PlayStation 3 de Sony. Dans le monde des systèmes embarqués sur puce (SoC), tels qu'on les trouve dans les smartphones, OpenCL permettra l'accès, via une infrastructure de programmation unique, au processeur central, ainsi qu'aux différents sous-systèmes multimédia embarqués (GPU, DSP, computing array ou autres).
Il existe actuellement peu de moyens de déboguer des noyaux OpenCL. Tout d'abord, le débogueur NVIDIA Parallel Nsight, capable de déboguer CUDA thread par thread, ne supporte actuellement pas OpenCL, mais permet seulement de traquer les appels à l'API. Ensuite, AMD propose une extension permettant de mettre des traces directement dans le code OpenCL (cl_amd_printf). Enfin, un programme appelé gDebugger (par Gremedy puis par AMD) permet de suivre le déroulement de l'algorithme thread par thread.
Historique.
OpenCL a été initialement conçu par Apple (qui en possède les droits d'auteur), et affiné dans le cadre d'une collaboration avec AMD, Intel et Nvidia. Apple soumet d'abord sa proposition initiale au Khronos Group. Le , le "Khronos Compute Working Group" est formé, comprenant des représentants des fabricants de matériel informatique et de logiciels. Celui-ci travaille durant cinq mois à boucler les détails techniques de la spécification OpenCL 1.0. La spécification est révisée par les membres de Khronos et approuvée pour une version d'essai le 8 décembre. Une nouvelle version, OpenCL 1.1, est publiée en juin 2010 par le Khronos Group. OpenCL 1.1 clarifie certains aspects de la spécification précédente et apporte de nouvelles fonctionnalités telles que les sous-buffers, les vecteurs à 3 éléments, les événements utilisateur, de nouvelles fonctions builtin, le support en standard d'extensions optionnelles 1.0 (telles que les fonctions atomiques 32 bits) .
OpenCL est intégré dans Mac OS X 10.6 (Snow Leopard).
AMD décide de supporter OpenCL et DirectX 11 plutôt que Close to Metal dans son framework Stream SDK. RapidMind annonce l'adoption de OpenCL sous sa plate-forme de développement, afin de supporter les processeurs graphiques de plusieurs fabricants avec une interface unique. Nvidia confirme également le 9 décembre 2008 le support complet de la spécification 1.0 dans son GPU Computing Toolkit.
Le 15 novembre 2011, Le Khronos Group a publié les spécifications d'OpenCL 1.2. On y trouve notamment des fonctionnalités liées à la mobilité et à la portabilité, avec par exemple la possibilité de dissocier compilation et édition de liens des noyaux .
WebCL.
Le Khronos Group a également développé une intégration d'OpenCL, bibliothèque de calcul parallèle, dans l'ensemble des interfaces de programmation d'HTML5. Actuellement, les navigateurs utilisent des extensions pour gérer OpenCL.
Nokia et Mozilla ont développé des extensions pour Firefox. Samsung pour WebKit et Motorola pour Node.js.
Historique des implémentations.
Des implémentations d'OpenCL existent pour la majorité des plateformes aujourd'hui. IBM pour ses supercalculateurs sous GNU/Linux utilisant des processeurs Power, les processeurs X86 d'Intel et AMD et les GPU les accompagnant traditionnellement (ATI, nVidia, VIA), les processeurs ARM Cortex-A9 (parties SSE et fpu 128bits Neon), ainsi que les DSP, GPU et autres computing array les accompagnant dans les nombreuses implémentations des System on chip (SoC) (nVidia Tegra2, Qualcomm Snapdragon, Apple A4, Marvell Armada, etc.). Mesa (Implémentation OpenGL/OpenVG sous GNU/Linux) contient un state-tracker OpenCL pour Gallium3D en cours de développement, nommé Clover
Le 10 décembre 2008, AMD et Nvidia font la première démonstration publique d'OpenCL, une présentation de 75 minutes à "SIGGRAPH Asia 2008". AMD effectue une démonstration d'OpenCL accélérée sur CPU et explique la scalabilité d'OpenCL sur un ou plusieurs cœurs tandis qu'Nvidia fait une démonstration accélérée par GPU.
Le 26 mars 2009, à la "GDC 2009", AMD et Havok font une démonstration de la première implémentation accélérée par OpenCL, "Havok Cloth" sur un GPU de la série Radeon HD 4000 d'AMD.
Le 20 avril 2009, Nvidia annonce la sortie de son pilote OpenCL et du SDK aux développeurs participant à son "OpenCL Early Access Program".
Le 5 août 2009, AMD révèle les premiers outils de développement pour sa plateforme OpenCL comme partie de son programme "ATI Stream SDK v2.0 Beta".
Le 28 août 2009, Apple sort Mac OS X Snow Leopard, qui contient une implémentation complète d'OpenCL.
Dans Snow Leopard, OpenCL est initialement supporté sur les puces ATI Radeon HD 4850, ATI Radeon HD 4870 ainsi que les puces Nvidia Geforce 8600M GT, GeForce 8800 GS, GeForce 8800 GT, GeForce 8800 GTS, Geforce 9400M, GeForce 9600M GT, GeForce GT 120, GeForce GT 130, GeForce GTX 285, Quadro FX 4800, et Quadro FX 5600.
Le 28 septembre 2009, Nvidia sort ses propres pilotes OpenCL et son implémentation du SDK.
Le 13 octobre 2009, AMD sort la quatrième bêta du "ATI Stream SDK 2.0", qui fournit une implémentation OpenCL complète sur tous les GPU des familles R700/R800, utilisant également les unités SSE3 des CPUs. Le SDK est disponible à la fois pour GNU/Linux et Windows.
Le 30 octobre 2009, IBM sort la version 0.1 de son SDK OpenCL pour GNU/Linux sur l'architecture Power utilisé dans une majorité des plus puissants supercalculateurs au monde.
Le 26 novembre 2009, Nvidia sort des pilotes pour l'implémentation OpenCL 1.0 (rev 48).
Les implémentations OpenCL d'Apple, Nvidia, RapidMind et Mesa Gallium3D sont toutes basées sur la technologie de compilation LLVM et utilisent le compilateur Clang comme frontend.
Le 10 décembre 2009, VIA sort son premier produit supportant OpenCL 1.0 - Le processeur vidéo ChromotionHD 2.0 inclus dans les puces VN1000. 
Le 21 décembre 2009, AMD sort la version de production de l'"ATI Stream SDK 2.0", qui fournit un support d'OpenCL 1.0 pour les R800 GPUs et un support bêta pour R700.
Le 29 juin 2011, Intel sort la version finale de son kit de développement supportant OpenCL version 1.1.
Le 3 août 2011 AMD annonce son kit de développement "ATI Stream SDK 2.5" , qui améliore, entre autres, la bande passante CPU/GPU pour tirer un meilleur parti de ses récents APU.
Chez Intel, les processeurs graphiques inclus dans sa gamme de processeurs Ivy Bridge, sortis le 29 avril 2012, Intel HD 2500 ainsi que HD 4000 et supérieurs, sont les premières architectures à supporter matériellement OpenCL, en version 1.1.
La bibliothèque Beignet est une bibliothèque OpenCL libre pour les processeurs Intel IvryBridge GT2, dans le cadre du projet freedesktop.org, et développé principalement par Intel. Il utilise principalement LLVM, mais est également compatible avec GCC. 
Fin 2013, ARM annonce à son tour son « Mali OpenCL SDK », pour ses processeurs graphiques Mali T600 et supérieurs, dont les premiers modèles sont sortis en 2012. Les sources sont disponibles, mais la licence est propriétaire et contraignante quant à la redistribution.
Exemple.
Cet exemple calcule une Transformée de Fourier rapide
Le calcul : (basé sur Fitting FFT onto the G80 Architecture)

</doc>
<doc id="3509235" url="http://fr.wikipedia.org/wiki?curid=3509235" title="Cat (langage)">
Cat (langage)

Cat est un langage de programmation fonctionnel orienté pile, à typage statique, inspiré par Joy. Joy et Cat diffèrent cependant des autres langages fonctionnels de par leur approche de composition de fonctions plutôt que d'application de fonctions (comme en Scheme ou Haskell).
Cat est un langage polyvalent, plus particulièrement destiné à l'enseignement.
Exemples.
Définition de la fonction carré :
Définition de la fonction factorielle, avec méta-commentaires (description et test unitaire) et signature de type :

</doc>
<doc id="3564402" url="http://fr.wikipedia.org/wiki?curid=3564402" title="Ioke (langage de programmation)">
Ioke (langage de programmation)

Ioke est un langage de programmation conçu pour la JVM par Ola Bini, l'un des développeurs de JRuby. C'est un langage de programmation orientée prototype inspiré par Io, Smalltalk, Lisp et Ruby.
Ola Bini utilise GNU Emacs pour ses développements.

</doc>
<doc id="105170" url="http://fr.wikipedia.org/wiki?curid=105170" title="PL/I">
PL/I

Le PL/I ou PL/1 (Programming Language number 1) est un langage de programmation développé par IBM dans les débuts des années 1970. 
Son objectif était d'être universel et de pouvoir remplacer indifféremment les langages à destination scientifique, tels que FORTRAN et ALGOL, et le langage COBOL, plus adapté aux problèmes de comptabilité et de gestion. Il permettait même l'accès à des fonctions autrefois réservées à la programmation système, comme la gestion de zones dynamiques de mémoire allouées à la demande (et non simplement à l'entrée dans un bloc), de pointeurs, et le travail par programme directement dans les tampons d'entrée-sortie. Ses capacités de points d'entrée génériques dans les procédures offraient une possibilité qui se retrouvera avec C++.
Ce langage est défini par les normes ECMA-50 (1976), ANSI X3.53-1976, AFNOR NF Z 65-500 et ISO 6160:1979. Il fut utilisé comme langage de programmation système dans le projet Multics. 
Son objectif était de devenir le langage privilégié de programmation des ordinateurs universels IBM 360 et 370. Les noms de PL/1 à PL/100 furent déposés par IBM par précaution, mais cela empêcha ce langage d'être proposé sous ce nom par d'autres constructeurs, nuisant ainsi à son succès.
Sa syntaxe ajoutait aux idées de FORTRAN certaines idées de COBOL (structures, calcul en mode décimal), et d'ALGOL (structure de blocs imbriqués). Toutefois, les programmeurs de ces deux langages ne communiquaient guère entre eux à l'époque, et chacun jugeait inutile et encombrant ce qui avait été inclus pour l'autre — et vice versa. Son compilateur nécessitait également des machines importantes, et ne comportait au départ ni optimiseur, ni compilateur incrémental (le "PL/I Optimizing compiler" et le "PL/I Checkout compiler" ne viendront que plus tard).
Ce langage avait beaucoup des caractéristiques de ce qui sera plus tard le C, et même déjà certaines du C++. IBM déposa les noms PL/1 à PL/100 pour éviter de perdre le contrôle des spécifications du langage. Un effet non prévu de cette décision fut de dissuader la concurrence de nommer « PL/I » ses propres implémentations, qui prirent des noms voisins : « SL/1 », « CPL/1 », « PL/M », « PL/C »... Devant la multitude de ces appellations, la crainte d'une balkanisation du langage (et des frais de migration associés en cas de changement de constructeur) dissuada les équipes informatiques d'y migrer. Le lancement du langage, malgré ses qualités (gestion simple du "multitasking", récursivité, structures de blocs, facilités de "debugging" et de profilage, allocation dynamique dans des pools de mémoire eux-mêmes dynamiques (AREA), procédures génériques analogues aux "templates" de C++) ne rencontra donc pas le vif succès attendu. Ses puissantes possibilité de débogage, en particulier "(CHECK):" et "ON CHECK(...) ... furent néanmoins remarquées.
Défauts.
La recherche d'universalité du langage, en lui donnant une apparence complexe, a joué contre lui. Les programmeurs Fortran n'avaient guère l'usage des "structures" ni du format décimal inspirés du COBOL et ceux de Cobol ne voyaient pas l'intérêt de calculer en nombres complexes.
Les instructions FORMAT et le GOTO calculé du Fortran combinées aux curiosités du Cobol avec ses PICTURE et son tri de fichier intégré ont fait du PL/I un langage certes complet mais plus complexe à apprendre
Et maintenant ?
Il est comme langage RAD, . 
Cela permet de se faire des outils très rapides, et aussi simplement qu'en REXX. 
Mais pour utiliser ce type de langage, il est nécessaire que les développeurs aient une bonne discipline en programmation, alors que pour le Cobol, par exemple, le compilateur « tente » d'éviter ces problématiques qui nécessitent autant de discipline (déclaratives, "closures", ..).
Conclusion.
PL/I permettait de confiner à des zones prédéfinies et allouées à la demande ("AREA") la manipulation des pointeurs et des adresses, faisant ainsi bénéficier le programmeur de la protection mémoire matérielle du système. Il disposait de puissantes possibilités intégrées de débogage. Ces possibilités natives du langage sont assurées dans d'autres aujourd'hui par des bibliothèques (Electric Fence...), ou des frameworks (Valgrind...). Ses autres innovations se retrouvent aujourd'hui, parfois dans le corps des langages et compilateurs (appels génériques de procédure, conversions automatiques de type, profilage, structures chaînées), plus souvent dans des bibliothèques optionnelles.

</doc>
<doc id="3636010" url="http://fr.wikipedia.org/wiki?curid=3636010" title="LACATRE">
LACATRE

LACATRE est l'abréviation de Langage d'Aide à la Conception d'Applications Temps-REel. C'est un langage graphique utilisé pour la conception de programmes informatiques multitâches et temps-réels. Ce langage est très utile pour représenter les interactions d'une tâche avec les différents moyens de communication (IPC) de façon simple permettant une première ébauche en conception tout en se rapprochant énormément du code final. Il existe d'ailleurs des applications permettant de traduire le formalisme LACATRE en code C (notamment pour VxWorks).

</doc>
<doc id="3688585" url="http://fr.wikipedia.org/wiki?curid=3688585" title="Charity (langage)">
Charity (langage)

Charity est un langage de programmation expérimental purement fonctionnel, développé à l'Université de Calgary. Il ressort des idées de Hagino Tatsuya, et il est complètement fondé sur la théorie des catégories. 
Nonobstant les interactions entrées-sorties, tous les programmes programmés en Charity sont garantis de terminer. Cela signifie que ce langage n'est pas Turing-complet. Cependant, il est capable d'exprimer la fonction d'Ackermann et la rend plus expressive qu'une récursion primitive. 
Le langage autorise les types récursifs ordinaires, tels qu'ils se trouvent en ML, et qui doivent être finis, et également les types de données corécursifs, qui sont autorisés d'être potentiellement infinis. La structure de contrôle pour les opérations sur les types récursifs est une récursion primitive ou catamorphisme, et celle pour les types de données corécursifs est une co-récursion primitive ou anamorphisme. Les structures de contrôle ne peuvent pas sinon opérer sur d'autres types de données. Tous les catamorphismes terminent et tous les anamorphismes sont productifs. 

</doc>
<doc id="743736" url="http://fr.wikipedia.org/wiki?curid=743736" title="NULL">
NULL

En termes de bases de données, ce mot clef exprime le fait que la valeur d'une donnée n'est pas connue. Il ne s'agit donc pas d'une valeur mais de l'état dans lequel la donnée se trouve, et signifie l'absence de valeur.
Variantes.
Il existe des équivalents nommés différemment :
C et C++.
En C, codice_1 est défini dans le fichier d'en-tête codice_11 de la bibliothèque standard du C, a pour valeur zéro et pour type void*.
En C++, codice_1 est remplacé par la constante codice_7, mais il est toujours possible d'utiliser une macro constante codice_1 qui — à la différence de celle utilisée en C — ne doit pas être de type void* (les pointeurs vers des types différents étant incompatibles).
En C++11, le mot clef codice_9 est introduit pour remplacer la constante codice_7 et la macro-constante codice_1.
Voici un exemple de code montrant l'initialisation d'un pointeur à codice_1, avant d'être utilisé pour stocker l'adresse d'une variable :
La valeur réellement utilisée comme pointeur nul par le processeur peut, sur certains systèmes, être différente de l’adresse spéciale 0 ; cela relève de la mécanique interne aux compilateurs. Cependant au niveau du C, codice_1 représente toujours un zéro, et doit être utilisé uniquement dans le but de désigner un pointeur qui ne pointe sur rien ; en ce sens, parfois (et toujours en C++, où pointeurs et données sont clairement distincts), sa définition est agrémentée d'un type, codice_20 ou codice_21.
Différence avec NUL.
Bien que cela ne pose généralement pas de problème de compilation en C (car une conversion implicite a lieu), le pointeur NULL ne doit pas être confondu avec le caractère ASCII codice_22 (un seul L) qui est utilisé pour marquer la fin d'une chaîne de caractères et correspond sur la majorité des systèmes à un octet (8 bits) plutôt qu'à un mot (ex. 32 bits) :
Java.
Le langage Java ne permet pas l'emploi de pointeur mais de références.
Le mot clé null définit une référence nulle, c'est-à-dire ne désignant aucun objet en mémoire.
Il s'agit de la valeur par défaut des variables non initialisées de type référence d'objet.
Voici un exemple de code montrant l'initialisation d'une référence à null, avant d'être utilisée pour référencer un objet alloué :
PHP.
En php, une variable de valeur NULL est considérée comme non-définie :
Affiche :
$a est indéfinie.
$a est NULL
$b est indéfini
$b est NULL
NULL, Typage et Méta-modélisation.
Soient deux types A et B distincts (et sans rapport)
La modélisation correcte d'un système de types rendant ces deux affections valables implique que null possède un type sous-type union de A et B : "None".
"None" est un type singleton ayant comme seule valeur possible "null" défini comme l'union de tous les types du programme. Comme ce type n'est pas modélisable sans une forme spéciale du langage et que son utilité est limitée (il n'accepte qu'une seule valeur, "null" ), peu de langages à typage statique le proposent.
Si on s'intéresse aux langages à objets, et qu'on pose comme première approximation du système de type :
Alors la classe de null (étrangement tous ces langages utilisent plutôt la forme "nil") devient la classe singleton "None", sous-classe de toutes les classes ayant pour seule instance "null". Pour garantir un fonctionnement cohérent avec le comportement des envois de messages sur null, toutes ces méthodes doivent être redéfinies par l'envoi d'une exception "NullPointerException".
Bien qu'en théorie la valeur "null" puisse être quelconque, en pratique tous les langages utilisent la valeur 0. Cette valeur est non adressable et toute tentative d'accès provoque une erreur de segmentation. Si l'on veut proprement lever une exception, on doit protéger tous les envois de messages par un test à "null". Un bon compilateur ne génèrera pas ces tests dans les cas où le receveur est trivialement non "null" (cas des "self", "this", "super" et autres) et dans certains autres cas.
UNIX.
Dans les systèmes UNIX, /dev/null est un fichier spécial qui détruit immédiatement toutes les données qui lui sont envoyées. Pour cette raison, ce fichier est appelé le « trou noir » ou encore la « poubelle ».
Les systèmes d'exploitation Microsoft utilisent un fichier spécial appelé NUL.

</doc>
<doc id="3874756" url="http://fr.wikipedia.org/wiki?curid=3874756" title="Euphoria (langage)">
Euphoria (langage)

Euphoria est un langage de programmation interprété créé par Robert Craig de Rapid Deployment Software.

</doc>
<doc id="3883723" url="http://fr.wikipedia.org/wiki?curid=3883723" title="Microsoft Small Basic">
Microsoft Small Basic

Microsoft Small Basic est un langage de programmation utilisant la technologie .NET dérivé de BASIC qui a été créé par Microsoft en novembre 2008. La volonté des développeurs est que Small Basic soit un langage simple mais performant pour ceux qui n'ont pas encore fait de programmation et qui souhaitent se lancer dans la conception de programmes. 
Microsoft Small Basic (à ne pas confondre avec SmallBASIC, un autre langage basé sur BASIC) a été imaginé et publié en première version par l'équipe Microsoft DevLabs en novembre 2008. Son public cible est l'ensemble des débutants en programmation (que ce soit des enfants ou des adultes) ou des développeurs confirmés qui souhaitent créer de petits programmes « pour le fun » de manière plus rapide qu'avec des langages conventionnels. Lorsqu'il a été publié, Small Basic ne comportait que 15 mots-clés, ce qui est très peu pour un langage basé sur Basic, et ce dans une volonté de rendre le langage simple à apprendre et à utiliser.
Langage.
Le langage en tant que tel, même s'il ressemble au très connu Visual Basic.NET, a son propre compilateur (inclus dans la suite Microsoft Small Basic) et fonctionne de manière très différente. 
Changer le fond d'écran.
Small Basic dispose de fonctionnalités permettant de faire interagir par du mash-up différents services (dictionnaires en ligne, Flickr, ...) et certaines fonctions de Windows, tel le fond d'écran du bureau.
Essais 'in vivo'.
Small Basic a déjà été testé par l'équipe de DevLabs avec succès avec plusieurs groupes d'étudiants secondaires et les enfants de certains employés de Microsoft, et les échos ont semblé très positifs.

</doc>
<doc id="3916821" url="http://fr.wikipedia.org/wiki?curid=3916821" title="Joy (langage)">
Joy (langage)

Joy est un langage de programmation purement fonctionnel et orienté pile conçu par Manfred von Thun de l'Université de La Trobe à Melbourne. Il possède de nombreux points communs avec son ancêtre Forth. Dans cette catégorie de langages, il se démarque par sa pureté mathématique.

</doc>
<doc id="3907007" url="http://fr.wikipedia.org/wiki?curid=3907007" title="Visual T Sharp">
Visual T Sharp

Visual T# (prononcé []) est un environnement de développement gratuit de tests unitaires intégré à Visual Studio™, mais peut s'utiliser indépendamment. Il comprend :
Avantages.
T# est un langage de programmation pour Microsoft .NET, compatible avec C# v2 (sauf en ce qui concerne le code non "managed"), et offre les avantages suivants par rapport aux solutions NUnit ou Visual Studio Team Test :
Le langage.
Voici un exemple d'un test minimal, écrit en T# :
Bonnes pratiques pour les tests unitaires.
T# est complètement orienté bonnes pratiques.
Structure d'un test.
Un test unitaire est toujours composé de trois parties :
La partie la plus importante étant Exécution, c'est pour elle que vous écrivez le test.
T# identifie clairement la partie Exécution en faisant commencer l'instruction par le mot clé codice_2.
La préparation est donc naturellement tout ce qui se trouve avant runtest, et la vérification après runtest.
Vérifications.
La partie vérification s'assure que tous les effets (par exemple : retour de fonction, changements des paramètres, modification d'instance, de déclarations statiques, de fichiers, bases de données...) escompté lors de l'utilisation de la déclaration se sont bien effectués comme prévu.
T# n'offre qu'un seul mot-clé pour cela : codice_1.
Le message est automatiquement généré à partir du code source.
Ainsi, si le test précédent échoue (si la fonction codice_4 est mal codée en retournant toujours codice_5), le test échouera avec le message d'erreur suivant : "Expected: somme == 3 but was: 0 == 3".
Il est ainsi très rapide de déterminer que la somme vaut 0, mais que l'on s'attendait à 3. Cette façon de générer le message d'erreur le rend plus proche du code source (donc plus facile de faire le lien avec le code quand l'erreur apparait) et décompose les différentes valeurs impliquées (si plusieurs variables étaient impliquées, on saurait alors la valeur de chacune des variables et non pas de l'expression finale), rendant le déboguage beaucoup plus facile.
De plus, les conversions naturelles du langage de programmation sont utilisées (somme est un codice_6, 3 est un entier). Ainsi, pas de problème pour comparer les deux contrairement à Visual Studio Team Test pour lequel vous devez écrire : codice_7 pour faire la même vérification!
4 états pour un test.
Le test étant du code, il peut lui aussi échouer.
Contrairement aux concurrents, T# sait exactement l'instruction qui teste réellement (codice_2). Ainsi, il est en mesure de déterminer si l'échec du test s'effectue avant ou après cette instruction :
T# a donc 4 états pour un test :
Afin de profiter de cette différence et de rendre le test très clair, utilisez des assert avant l'instruction codice_2 :
Dans cet exemple, on veut rendre gratuit T#. Le test passe. Le code codice_12 de la propriété codice_13 est donc correct.
Vraiment?
Mais si ni le constructeur, ni le codice_12 de la propriété codice_13 ne sont codés... le test passe!
Un bon test pour le changement du prix est donc :
Maintenant, ce cas est exclu. Si le constructeur n'initialise pas la propriété codice_13, le premier codice_1 échouerait et, comme il est avant l'instruction codice_2, le test est 'Invalid' et non pas échoué!
De plus, d'un point de vue logique d'affaires, on voit bien que mettre le prix à 0 le fait passer d'une valeur non nulle à nulle et donc qu'un prix nul est acceptable.
Quoi tester ?
T# incite à dire ce qui est testé, non pas par des noms de classes et méthodes les plus appropriés possibles, mais en l'indiquant clairement.
Ainsi, le test précédent devrait s'écrire :
Les avantages sont les suivants :
Contextes.
Comme pour tout système de test, il y a beaucoup de redondances dans l'écriture des tests. En effet, il est nécessaire d'avoir plusieurs tests pour chaque déclaration d'une classe et, généralement, une classe possède plusieurs déclarations. Dans tous ces tests, il sera nécessaire de créer une instance de la classe à tester.
Tous les systèmes de test proposent une méthode à appeler avant tout test et une à appeler après tout test.
T#, lui, ne propose qu'une seule méthode.
Cela procure ainsi les avantages suivants :
Contexte de chaque test.
La forme la plus simple de contexte est le "context" de chaque test. C'est celle utilisée par défaut.
Les tests sont exécutés, mais pas directement. Le contexte, introduit par une méthode déclarée par le mot clé codice_22, est appelée pour chaque test.
Le mot clé codice_2 indique l'endroit où le codice_24 doit réellement s'exécuter.
Ainsi, dans notre exemple, nous voulons créer l'instance avec une seule ligne de code, mais il faut créer une instance pour chaque test :
Différents niveaux de contexte.
En T#, le contexte se situe à trois niveaux :
Dans cet exemple, les tests seront exécutés 2 fois, sans avoir à les écrire 2 fois :
Quel cas tester ?
Lors de l'écriture de tests unitaires, le problème le plus classique est : "Quel cas dois-je tester ?".
En effet, une même déclaration doit-être testée dans différents cas. Un des exemples précédents traitait du prix d'un produit représenté par une propriété. Combien faut-il de tests et quels sont ces tests dans un tel cas?
Dans les systèmes de tests classiques, c'est encore une fois le nom du test qui dit quel cas est testé (ou un commentaire, comme dans notre exemple précédent). Cela donne des noms souvent très longs et pas nécessairement clairs... ni mis à jour.
T# introduit un nouveau mot clé pour exprimer le cas testé : codice_28 suivi d'un cas à tester.
Ainsi, l'exemple des tests du prix d'un produit devrait être :
Cas manquants.
En fait, ce qui suit le mot clé codice_28 est un cas parmi plusieurs fonctionnant ensemble, décrits par un critère.
Dans notre exemple, le critère est codice_30 qui combine 2 cas normaux (codice_31 et codice_32) et 1 cas d'erreur (codice_33).
Il suffit donc d'identifier qu'un prix de produit a une valeur minimale (0) pour identifier qu'il faut tester selon le critère codice_30. Ce critère définissant 3 cas, il va falloir écrire 3 tests pour tester cette propriété, un pour chaque cas défini dans le critère.
Pour l'instant, nous n'avons que deux cas définis (les cas normaux). Dès la compilation, T# indique les cas manquants : codice_35.
Expressions de cas.
En réalité, après un codice_28, une expression de cas est utilisée. Cette expression peut être un cas simple d'un critère ou une combinaison de critères.
Les opérateurs suivants existent :
Enfin, lorsqu'un cas n'a pas de sens, il est possible de demander à ne pas le prendre en compte en déclarant le cas codice_40. Dans ce cas, le test ne doit pas avoir de code, donc pas d'accolades, seulement un point-virgule.
Critères.
Il existe déjà beaucoup de critères dans la bibliothèque de T#, mais cela ne peut couvrir tout vos besoins.
Il est alors très facile de créer les vôtres.
Un critère est comme un type énuméré, mais défini par le mot clé codice_41 et non pas enum. Les cas d'erreur sont repérés en ajoutant l'attribut codice_42 au cas en question.
La convention veut que :
Ainsi, la déclaration de codice_43 est la suivante :
Tester les exceptions.
Comme nous l'avons vu avec les critères dans le paragraphe précédent, il est nécessaire de non seulement tester les cas normaux, mais aussi les cas d'erreur.
Généralement, un cas d'erreur est rapporté par une exception.
Il faut donc pouvoir tester les exceptions.
Tester qu'une exception est lancée.
T# vérifie les exceptions comme toute autre vérification :
Les avantages sont les suivants :
Ainsi, dans l'exemple précédent, il est nécessaire de tester le cas où le prix affecté au produit est négatif.
Comme cela n'a pas de sens, la propriété devrait générer une exception codice_45.
Testez-le ainsi :
Tester complètement une exception.
En fait, cela va simplement vérifier que l'exception est bien générée dans l'instruction runtest. Ce qui est déjà bien.
Cependant, il serait bon de pouvoir valider le message d'erreur par exemple.
L'instruction codice_46 peut aussi être suivi d'un nom de variable, comme dans une instruction codice_47, et d'un bloc de code pour faire autant de vérifications voulues lorsque l'exception est déclenchée. Accédez alors normalement à cette variable pour vérifier tout ce que vous voulez.
Vérifier les changements.
Le problème d'utiliser des contextes est que celui-ci peut se trouver physiquement loin du test que l'on travaille, et lorsqu'il est changé, peut avoir des conséquences sur l'ensemble des tests.
Ainsi, dans l'exemple précédent, si le produit créé a maintenant un prix de 100 au lieu de 123, l'instruction codice_48 échoue car le prix sera de 100!
L'idéal serait de faire des tests relatifs : conserver la valeur initiale de codice_49 dans une variable locale, puis l'utiliser dans la vérification.
Le problème est que cela fait plus de code à écrire.
T# offre la possibilité d'écrire des vérifications relatives en une seule ligne de code.
Vérifier la constance d'une expression.
La forme la plus simple de vérification relative est celle de la constance d'une expression.
T# offre une nouvelle forme de l'instruction codice_1 : codice_51
L'expression sera évalué avant l'instruction codice_2, et sa valeur conservée, pour être de comparée par égalité au moment du codice_1 en question.
Ainsi, dans notre exemple, plutôt que de vérifier que le prix du produit est bien 123, il serait préférable de vérifier que le prix n'a pas changé :
Vérifier la constance d'un objet.
La forme la plus sophistiquée de vérification relative est celle de la constance d'un objet. En effet, qui dit que notre code d'affaires n'a pas modifié l'objet avant que de lancer l'exception?
Dans l'instruction codice_51, l'expression peut référencer un objet et se terminer par :
Note : l'opérateur codice_57 est semblable à l'opérateur codice_58 si ce n'est qu'il accède à n'importe quelle déclaration, privée ou non.
Ainsi, dans notre exemple, plutôt que de vérifier que le prix du produit n'a pas changé, il serait préférable de vérifier que l'objet codice_59 n'a pas changé :
Vérifier un changement.
Sur le même principe, vérifiez qu'un changement a été apporté par une assertion relative.
Une assertion relative de changement s'effectue avec l'instruction codice_60.
L'affectation se présente sous 3 formes :
La partie de droite est évaluée avant l'instruction runtest, et conservée, pour être comparée par égalité à la partie de gauche sur le codice_1 correspondant.
Ainsi, codice_71 n'incrémente pas élément, mais vérifie que la valeur d'élément ajoutée de 1 avant l'instruction codice_2 est égale à la valeur d'élément après l'instruction codice_2. Ou tout simplement, que l'instruction runtest à bien fait augmenter de 1 la valeur d'élément.
Ainsi, c'est l'expression équivalente à une affectation comme précisé, mais seulement des accès en lecture sont effectués. Il est donc possible de l'utiliser avec des propriétés en lecture seule.
Si nous reprenons notre exemple avec notre classe codice_74, on pourrait ajouter une classe codice_75 (une collection de codice_74)qui aurait donc une méthode codice_77 et une propriété codice_78.
Le test de cette méthode serait :
Tester les événements.
En dehors des exceptions, les événements non plus ne sont pas faciles à tester correctement.
Il n'existe aucune facilité fournie par les système de tests existants.
T# offre une nouvelle fois l'instruction codice_1 mais avec le mot clé codice_80.
Par exemple, une classe implémentant codice_81 doit déclencher l'événement codice_82 si une propriété est changée. Mais, elle ne devrait pas déclencher l'événement si la valeur affectée est la même que celle actuelle!
Note : Ce cas étant classique, nous T# fournit déjà le critère codice_83 avec 3 cas :
Vérifier le non-déclenchement d'un événement.
La forme la plus simple est la vérification du non déclenchement d'un événement.
En T#, la vérification du non-déclenchement d'un événement s'effectue comme toujours en une ligne de code : codice_84
Le compilateur T# génère une variable d'instance et une méthode compatible avec la signature de l'événement.
Dans le test, la variable est initialisée à faux, le méthode est enregistrée (codice_85) auprès de l'événement avant l'instruction codice_2 et désenregistrée (codice_87) après l'instruction codice_2.
La méthode générée va réinitialiser la variable à vrai.
L'instruction codice_89 va vérifier que la variable est toujours à faux.
En supposant que notre classe codice_74 supporte l'interface codice_81, nous devrions avoir le test suivant :
Vérifier le déclenchement d'un événement.
La forme la plus simple de vérification du déclenchement d'un événement vérifie seulement que l'événement est déclenché.
Comme toujours, T# le vérifie en une seule ligne de code : codice_92
Le compilateur T# génère exactement les mêmes choses que pour codice_93, mais vérifie que la variable est à vrai.
Ainsi, dans notre exemple, nous devrions avoir :
Vérifier complètement un événement.
L'inconvénient de procéder comme dans le chapitre précédent, c'est que cela prouve simplement que l'événement s'est déclenché, pas que :
Une forme beaucoup plus sophistiquée de test des événement existe : codice_95
Où :
Ainsi, le même tests que dans le chapitre précédent, mais complet serait :
Tester avec les 'Code Snippets'.
Visual Studio offre la possibilité d'utiliser des 'Code Snippets' dans les langages de Microsoft. Nous avons aussi ajouté des 'Code Snippets' pour Visual T# (25 dans la version 1.0).
Ainsi, rien de plus facile pour générer vos tests :
Dans notre exemple, nous voulons tester le prix d'un produit.
Nous avons déjà établi que les critères à utiliser sont :
Comme par hasard, il existe le 'Code Snippet' codice_99 qui va générer d'un seul coup le code.
Il ne reste plus qu'à indiquer les informations suivantes :
Et voici le code généré :
Liens externes.
Visual T# est téléchargeable gratuitement sur : Forum Visual T#

</doc>
<doc id="91480" url="http://fr.wikipedia.org/wiki?curid=91480" title="APL (langage)">
APL (langage)

L'APL (initialement "A Programming Language", officieusement "Array-Processing Language") est un langage de programmation conçu entre 1957 et 1967 par Kenneth Iverson pour décrire commodément des opérations portant globalement sur des tableaux (booléens, numériques ou, dans une moindre mesure, de caractères).
Révolutionnaire à son lancement (usage du terminal à boule ou à écran alors que la carte perforée restait encore la référence, gestion dynamique de mémoire, interactivité totale, concision par suppression de la nécessité des ordres de boucles), il connut un succès croissant jusqu'au milieu des années 1980, époque où le tableur le concurrença pour les petits travaux, et des outils comme SAS, puis R (langage de programmation et environnement statistique) pour le travail sur les grands volumes de données.
Historique.
APL s’est montré particulièrement adapté en son temps aux calculs statistiques, aux ventilations, aux consolidations, aux descriptions fonctionnelles d’architectures comme celle de l’IBM 360, aux graphiques interactifs (GRAPHPAK) et à quelques travaux en combinatoire et en théorie des graphes. Il a également été utilisé pour le prototypage d’applications et l’écriture de langages de manipulation simples dans le cadre d’un infocentre en masquant les symboles appropriés sous des dénominations commodes et parlantes, par exemple en permettant d’écrire simplement :
"MOYENNE X" pour "(+/X)÷⍴X".
"NORMALISER X" pour "X÷+/X"
etc.
Il permet de manipuler aisément des tableaux de 1 à N indices (N variant de 7 à 255 selon l’implémentation considérée) de façon "globale". Les opérations puissantes de "feuilletage" ("lamination") ainsi que les opérateurs de "réduction", "expansion", "compression", "produit intérieur" et "produit extérieur" évitent souvent toute nécessité d’indices de boucle explicite - ainsi d’ailleurs que l’usage de boucles lui-même.
Il utilise de nombreux symboles représentant des opérations utilisables en programmation comme en calcul immédiat à la console, par exemple le « domino » (⌹) qui inverse directement une matrice, ou résout un système d’équations linéaires surdimensionné au sens des moindres carrés.
On estimait dans les années 1970-80 qu’une équipe de 5 développeurs APL avait la puissance de développement d’une équipe de 25 programmeurs FORTRAN. L’application APL se montrait plus gourmande en ressources matérielles, mais le prix de celles-ci était en constante diminution. Aujourd'hui, 2013, son adaptation à la programmation agile lui donne un regain d'intérêt pour toutes les applications à mettre en place ou faire évoluer rapidement, aussi bien que pour les applications à courte durée de vie. Il a été utilisé entre autres par NASA, British Airways, Banque de France (études économiques éclair), Direction générale des Impôts (impact fiscal de lois nouvelles), etc.
Depuis 2013 également, il est proposé pour la réalisation de servlets.
Son interface initiale (bicolore en mode machine à écrire) a inspiré celle de logiciels comme Maple.
Présentation.
APL innovait à son époque par plusieurs aspects conviviaux : 
Exemples.
Ainsi pour écrire « Hello, World! » en APL, les choses se passent ainsi :
Il faut y ajouter la possibilité spectaculaire d’indexer un tableau par un autre tableau. Ainsi :
Voire :
Pas de traduction automatique ici ni dans un cas ni dans l'autre : l'indice a simplement été remplacé par ce qui était indicé (ainsi "T" est le septième caractère), ce qui est le propre de l'opération d'indexation. Ce qui est indicé prend également la forme de l'indice (ainsi, une matrice 2x3 dans le second cas).
Grâce à sa priorité de gauche à droite, le langage se lit simplement, comme une langue naturelle : « 1 plus somme des inverses des factorielles des entiers de 1 à 30 » s'écrira :
Une extension d'APL, nommée APL2, gère quant à elle des tableaux de tableaux, et permet à l'utilisateur de définir lui-même ses propres « opérateurs ». Elle travaille également en nombres complexes automatiquement si les besoins du calcul le demandent.
Opérations sur tableaux.
APL a créé une matrice A de 2 lignes et 2 colonnes, la remplit avec les nombres 1 2 3 4, puis l'imprime
le résultat est une matrice booléenne indiquant les éléments de A égaux à 2
APL concatène la matrice A avec elle-même, formant une matrice de 2 lignes et 4 colonnes
APL concatène le scalaire 5 à la matrice A
APL concatène à A un vecteur 'somme des lignes de A' 
même chose suivant l'autre axe : colonnes
concaténation en créant une nouvelle dimension : la matrice devient cube
concaténation en créant une nouvelle dimension sur un autre axe
APL met dans A et imprime un produit externe ou cartésien, genre table de multiplication
APL édite la suite résultant du tri ascendant des éléments de A
Opérateurs.
De même qu'une "fonction" agit sur une ou plusieurs "variables", un "opérateur" agit sur une ou plusieurs "fonctions" (ou opérations). Pour prendre une comparaison mathématique, « sigma » et « pi » correspondent à l'opérateur APL de "réduction" (« / ») appliqué aux opérations « + » et « × ». Sigma (somme de termes) s'écrit "+/", « pi » (multiplication entre termes) "×/", « Union » ("ou" logique entre termes) ∨"/", etc. On parle, dans d'autres langages, de clôture ("closure").
Dans la première version d’APL, les "opérateurs" sont définis de façon fixe (réduction (/), scan (\), produit externe (°.), composition (.), …). En APL2, l’utilisateur peut fabriquer les siens à volonté et leur donner des noms. Un opérateur peut agir indifféremment sur des opérations de base du langage ou sur des fonctions définies par l’utilisateur dans sa "workspace".
APL2 introduit également l'opérateur tréma ('¨', nommé "each"), généralisant au niveau de chaque sous-tableau une opération dans les "tableaux de tableaux".
Tableaux de tableaux, et fonction ⍎.
Une opération nommée "enclose" (⊂) permet d’"encapsuler" un tableau qui est alors vu comme un scalaire. Il est dès lors facile de représenter des structures complexes sous forme de "tableaux ayant pour éléments d’autres tableaux". L’existence d’une fonction "execute" (⍎) permet même d’inclure dans ces tableaux de tableaux des désignateurs de fonction que l’on peut exécuter à la demande, comme en langage C. Elle permet aussi à un programme d’engendrer lui-même un code qu’il exécutera ensuite, comme en Lisp.
Le nombre d'"indices" d’un tableau est par convention nommé "rang" (rank) en APL. Le nombre de "niveaux" d’un tableau de tableaux est nommé "profondeur" (depth).
Espace de travail.
L’utilisateur travaille dans un "espace de travail" où il stocke ses fonctions et ses variables. Il peut à tout moment sauvegarder l’ensemble (y compris en état d’exécution suspendue) et reprendre plus tard son travail exactement dans les conditions où il l’avait laissé. Des commandes comme ")COPY" et ")PCOPY", et la notion de "groupe" permettent des transferts aisés de fonctions et de variables d’un "workspace" à un autre.
Horodatage automatique.
Chaque objet APL2 (variable, fonction ou opérateur) est horodaté dans la "espace de travail", ce qui facilite sa gestion sur le long terme. Le type et la date des objets sont retournées par la fonction système "⎕AT" (="AT"tributes). Couplé aux opérateurs de tri ⍋ ("grade-up") et ⍒ ("grade-down"), cet horodatage des objets facilite beaucoup le processus de développement.
Implémentations.
Exemple de session NARS2000
Trois implémentations en Open Source d'APL sont téléchargeables gratuitement à ce jour, 2013 :
Réalisations.
Des interpréteurs APL ont existé pour l’IBM 7090, les IBM 360 à zSeries (sous TSO, VM/CMS et même CICS!), l’IBM 1130, le "Xerox XDS Sigma 7" alias CII 10070, et le CII Iris 80, le Bull DPS-7, le Burroughs B1700, le Bull SEMS T1600 (ex-"Télémécanique Électrique T1600"), la série des Mitra, etc. 
Ce langage était même directement en ROM dans des ordinateurs personnels du milieu des années 1970 comme le "MCM-70" ou l’IBM 5110 modèles A et C.
Des versions station de travail et ordinateur personnel en ont aussi été commercialisées ou réalisées gratuitement pour AIX, Solaris, Linux, Windows, Mac OS, OS/2 et même le DOS (une version gratuite nommée TRYAPL2 existe pour le DOS, en version anglaise comme française).
La société Microsoft considérait l'APL comme le successeur naturel de son BASIC et avait entrepris deux implémentations du langage sur 8080 et 6800, comme le montre un extrait de lettre de Bill Gates aux utilisateurs de l'Altair BASIC 
Le succès de DOS, de Windows et surtout des tableurs Multiplan et Excel fit abandonner ce projet, qui s'adressait à un marché potentiel bien plus restreint.
Environnements informatiques.
Le mécanisme d’échange dit des "processeurs auxiliaires" permet à des workspaces APL de communiquer avec le monde extérieur : fichiers, SQL/DB2, TCP/IP, X-window, OpenGL, ainsi qu'"autres workspaces APL et consoles du réseau actives au même moment" si celles-ci en donnent l’autorisation. On peut ainsi commencer à mettre au point un calcul sur un PC, puis une fois qu’il est au point l’exécuter à distance sur un mainframe équipés de dizaines de processeurs parallèles depuis la même session.
Les processeurs auxiliaires se codent le plus souvent en langage C.
Situation présente du langage.
L’apparition du tableur, plus intuitif et plus facile à manier, a fait disparaître une partie de l’intérêt du langage. Cela n’enlève rien pour autant à sa puissance d’expression et à sa concision, et plusieurs interpréteurs APL sont téléchargeables gratuitement sur Internet, pour le PC comme pour le Macintosh. La généralisation des écrans et des imprimantes à laser ont éliminé l’ancien problème que représentait l’usage de caractères spécifiques. Les caractères APL/APL2 sont d’ailleurs présents dans l’Unicode.
APL traitant globalement les tableaux, ses implémentations tirent aisément parti des possibilités de calcul parallèle ou de pipeline des processeurs modernes. Elles utilisent extensivement les possibilités vectorielles du S/390 (zSeries), de l’architecture PowerPC et des instructions multimédia (SSE) de l’architecture Intel/AMD.
Il a deux successeurs, le langage A+, et le langage J, ce dernier ayant été promu par K. E. Iverson lui-même, et ne nécessitant pas l’usage de caractères spéciaux. APL possède toutefois une lisibilité supérieure, à condition de disposer de la police de caractères appropriée. La mise à disposition du langage lui-même n’aurait pas été possible dès 1969 sans les "terminaux IBM à boule" également nommés Selectric (par exemple le "2741").
Pour information, des calculs actuels typiques sur un Celeron s’effectuent à peu près en un dixième du temps de calcul qu’ils prenaient en 1970 sur un "IBM 360/91". Le cœur de l’interpréteur tient entièrement dans le cache d'instructions d’un microprocesseur contemporain (2004), donnant à APL des performances comparables à celle qu’on obtenait il y a quelques années avec un langage compilé.
GRAPHPAK est une des workspaces fournies avec APL et combinable avec toute autre application de l’utilisateur pour lui donner des possibilités d’entrée-sortie graphiques 2D comme 3D. La structure des appels du langage (pas de nécessité de parenthèses pour les appels de fonctions et de sous-programmes) permet de donner des ordres ayant une vague allure de langage naturel. Les éléments "IBM" et "AP", fournis avec cette workpsace, sont simplement des matrices contenant des coordonnées de points respectivement en 2D et en 3D, la première colonne spécifiant une indication de tracé (couleur et style).
Caractères APL/APL2 en Unicode.
Vérifiez que votre navigateur accepte bien l’Unicode; dans le cas contraire, vous verrez s’afficher des rectangles blancs ou des points d’interrogation à la place des caractères APL.
Glyphes.
Tous les caractères APL ne sont pas encore associés à une signification aujourd'hui (2004).
Polices APL existantes.
En mai 2010, les principales polices APL téléchargeables depuis l'Internet sont les suivantes :
Quelques opinions.
« APL is a mistake, carried through to perfection. It is the language of the future for the programming techniques of the past: it creates a new generation of coding bums ».
"« APL est une erreur, poussée jusqu'à la perfection. C’est le langage de l’avenir pour les techniques de programmation du passé : il crée une nouvelle génération de fainéants du codage»".
« APL is a write-only language. I can write programs in APL, but I can’t read any of them ».
"« APL est un langage en écriture seule. Je peux écrire des programmes en APL, mais je ne peux en lire aucun. »"
« APL is like a diamond. It has a beautiful crystal structure; all of its parts are related in a uniform and elegant way. But if you try to extend this structure in any way - even by adding another diamond - you get an ugly kludge ».
"« APL est comme un diamant. Il a une superbe structure cristalline ; toutes ses parties sont en correspondance d’une façon uniforme et élégante. Mais si vous essayez d’étendre cette structure de quelque façon que ce soit — même en y ajoutant un autre diamant — vous obtenez un bricolage hideux »". (Allusion au passage d’APL à APL2).
« Je ne recommanderais pas de mettre rapidement APL entre les mains des étudiants ».
Lacune d’APL.
APL n’a jamais officiellement connu les tables associatives, indexant un tableau avec autre chose que des valeurs entières. On ne peut donc pas écrire :
"CAPITALE[⊂'FRANCE']←⊂'PARIS'
ou, pour rester dans le vectoriel,
"CAPITALE['FRANCE' 'ESPAGNE' 'ITALIE']←'PARIS' 'MADRID' 'ROME
ce qui est regrettable, car :
Il est peu ergonomique de contourner cette lacune au prix de variables supplémentaires, comme par exemple:
"FRANCE←32" (dès lors, "CAPITALE←⊂"PARIS"". Si le pays provient d'une saisie, l'indice peut être retrouvé par "execute" : "⍎"FRANCE"" qui rend 32, mais l'application perd en robustesse et on encombre inutilement la table des symboles (APL/X contourne la difficulté par des "namespaces").
Une autre manière est de définir un vecteur des noms de pays :
"PAYS ←'BELGIQUE' 'FRANCE' ", l'instruction devenant alors :
"CAPITALE[PAYS⍳⊂'FRANCE']←⊂'PARIS' "
Mais en ce cas, indépendamment de la lisibilité plus faible, le temps d'accès n'a plus le moindre rapport avec un accès direct de type "hash" en Perl ou PHP, surtout si s'il y a des centaines de noms.
Non seulement la lisibilité des programmes n'y gagne rien, mais leur facilité de maintenance s'effondre compte tenu des variables "surajoutées" au programme.
APL, langage cryptique.
Épargnant l’usage des indices et des boucles en multipliant les opérateurs, APL permet l'écriture rapide et concise d'expressions qui seraient bien plus longues avec un langage classique. Vue la compacité et la puissance du langage, certains puristes considéraient que pour être « élégant », un programme APL ne devait pas dépasser une ligne de code. Ces programmes, nommés "one-liners" dans la revue de l'ACM "APL Quote-Quad" étaient les ancêtres des "deulignes" de ce qui sera plus tard Hebdogiciel.
Cependant, la multiplicité des glyphes, leur usage unaire ou binaire, les superpositions de caractère sensées les exprimer ont fait qualifier ce langage de "cryptique". D'autant que l'absence de mécanismes conditionnels amenait chacun à employer diverses astuces, nuisant à la lisibilité et à la maintenance des applications, sauf à introduire des opérateurs nommés à usage auto-documentaire.
Succession.
Ces deux langages, du fait de leur appartenance au projet GNU, sont par ailleurs gratuits.

</doc>
<doc id="3662401" url="http://fr.wikipedia.org/wiki?curid=3662401" title="Falcon (langage)">
Falcon (langage)

Falcon est un langage de programmation de scripts créée par Giancarlo Niccolai. Il supporte différents paradigmes.

</doc>
<doc id="148634" url="http://fr.wikipedia.org/wiki?curid=148634" title="YAML">
YAML

YAML, acronyme récursif de YAML Ain't Markup Language, est un format de représentation de données par sérialisation Unicode. Il reprend des concepts d'autres langages comme XML, ou encore du format de message électronique tel que documenté par RFC 2822. YAML a été proposé par Clark Evans en 2001, et implémenté par ses soins ainsi que par Brian Ingerson et Oren Ben-Kiki.
Caractéristiques.
L'idée de fond de YAML est que toute donnée peut être représentée par une combinaison de listes, tableaux (de hachage) et données scalaires. YAML décrit ces formes de données (les "représentations YAML"), ainsi qu'une syntaxe pour présenter ces données sous la forme d'un flux de caractères (le "flux YAML").
Une application informatique passe du flux YAML à la représentation YAML par l'opération de "chargement" (anglais "load"). Elle passe de la représentation au flux par l'opération de "déchargement" (anglais "dump").
La syntaxe du flux YAML est relativement simple et efficace, moins verbeuse que du XML, moins compacte que du CSV, et a été établie de sorte qu'elle soit le plus lisible possible par des humains, tout en pouvant être mise en correspondance facilement avec les types de données précités, communs dans les langages de haut niveau. À ces langages il emprunte certaines notations.
La syntaxe YAML se distingue de JSON par le fait qu'il se veut plus facilement lisible par une personne. Il se distingue du XML par le fait qu'il s'intéresse d'abord à la sérialisation de données, et moins à la documentation.
"phpMyAdmin" permet l'export des bases MySQL en YAML, entre autres formats.
Exemples.
Listes.
<syntaxhighlight lang="yaml">
</syntaxhighlight>
Tableaux associatifs.
<syntaxhighlight lang="yaml">
</syntaxhighlight>
Blocs de mise en forme.
Nouvelles lignes conservées.
<syntaxhighlight lang="yaml">
</syntaxhighlight>
Nouvelles lignes rassemblées.
<syntaxhighlight lang="yaml">
</syntaxhighlight>
Listes de tableaux associatifs.
<syntaxhighlight lang="yaml">
</syntaxhighlight>
Tableaux de listes.
<syntaxhighlight lang="yaml">
</syntaxhighlight>
Implémentations.
Des bibliothèques pour YAML existent pour les langages suivants :

</doc>
<doc id="4004355" url="http://fr.wikipedia.org/wiki?curid=4004355" title="IronRuby">
IronRuby

IronRuby est une implémentation de l'interpréteur du langage de programmation Ruby visant le .NET Framework de Microsoft. C'est une surcouche au DLR, une bibliothèque se superposant au CLR 2.0 qui fournit, entre autres, un typage dynamique et la délégation dynamique des méthodes pour les langages dynamiques.
Histoire.
Le 30 avril 2007, à la conférence MIX 2007, Microsoft dévoila IronRuby, qui utilise le même nom que le projet de Wilco Bauwer, avec l'accord de ce dernier. Sa sortie publique était annoncée pour l'OSCON 2007.
Le 23 juillet 2007, comme prévu, John Lam et la DLR Design Team présentèrent la version pré-Alpha du compilateur IronRuby à l'OSCON. Il annonça également une intégration rapide de IronRuby au sein de la communauté open source.
Le 31 août 2007, John Lam et la DLR Design Team publièrent le code (au stade de version pre-alpha) sur RubyForge. Le code source a été mis à jour régulièrement par l'équipe de Microsoft. L'équipe n'accepte pas les contributions de la part de la communauté concernant le noyau de la bibliothèque DLR, du moins pour le moment.
Le 24 juillet 2008, la IronRuby team publia la première version alpha exécutable, dévoilée pour l'OSCON 2008. Le 19 novembre 2008, une seconde version alpha vit le jour. 
L'équipe de développement travailla activement sur le support de Rails par IronRuby. Quelques tests fonctionnels de Rails donnent des résultats, mais il y a encore beaucoup de travail à faire avant de pouvoir utiliser Rails dans un environnement de production.
Le 21 mai 2009, ils publièrent la version 0.5 lors de la RailsConf 2009. Cette version de IronRuby peut exécuter des applications Rails, mais pas encore dans un environnement de production.
L'annonce de la version 1.0 est attendue pour l'OSCON 2009. La version 0.9 a été publiée le août 2009.
Prise en charge par Mono.
Normalement, IronRuby s'exécute aussi bien sur Mono que sur le CLR de Microsoft, mais comme l'équipe de développement ne l'a testé qu'avec le CLR s'exécutant sur Windows, il pourrait ne pas être supporté par Mono suivant l'architecture.
Interopérabilité vis-à-vis de .NET.
L'interopérabilité entre les classes d'IronRuby et les classes habituelles du .NET Framework est plutôt limitée pour le moment car de nombreuses classes de Ruby ne sont pas des classes de .NET. Cependant, un meilleur support des langages dynamiques dans .NET 4.0 pourrait accroître l'interopérabilité à l’avenir.
Licence.
IronRuby est disponible sous la Microsoft Public License, certifiée par l'Open Source Initiative.

</doc>
<doc id="545298" url="http://fr.wikipedia.org/wiki?curid=545298" title="Command LIST">
Command LIST

Command LIST, le plus souvent appelé simplement CLIST, est un langage de programmation procédurale que l'on retrouve essentiellement sur le système d'exploitation MVS des grands systèmes IBM, en particulier sous TSO et TSO/ISPF.
Bien qu'exécutable en ligne de commande ou en mode traitement par lots ("batch"), sa principale utilité est de permettre le développement d'applications interactives. 
Sous sa forme basique, une CLIST est juste une simple liste de commandes devant être exécutées dans l'ordre précis (comme un traitement par lots).
Une CLIST peut aussi lire/écrire des fichiers MVS, réaliser une lecture/écriture sur un terminal TSO et possède les instructions normales de bloc (IF/ELSE DO/END). Elle peut lire des variables passées en paramètre et a également une fonction pour garder des variables globales et les passer d'une CLIST à l'autre.
CLIST est un langage interprété. C'est-à-dire que l'ordinateur doit traduire un programme en CLIST chaque fois que celui-ci est exécuté. Les CLIST tendent donc à être beaucoup plus lents que des programmes écrits en langages compilés tels que COBOL, Fortran ou PL/I (un programme écrit en langage compilé est traduit une seule fois pour créer un exécutable qui sera lancé par la suite).
Langage très lourd à première vue, il comporte de grandes similitudes avec REXX. Il est donc recommandé de commenter abondamment les CLIST, notamment en cas d'utilisation de code REXX dans le script.
Quelques mots sur la syntaxe :
Cet exemple :
peut être valable aussi bien en CLIST qu'en REXX

</doc>
<doc id="4011245" url="http://fr.wikipedia.org/wiki?curid=4011245" title="Reia">
Reia

Reia est un langage de programmation concurrent orienté objet pour la machine virtuelle Erlang.
Reia supporte différents paradigmes dont : la programmation impérative la programmation orientée objet, la programmation fonctionnelle, la programmation déclarative et la programmation concurrente.
Ce langage utilise le modèle d'acteur pour la concurrence, de manière à fonctionner avec son système d'objets.
Son typage est dynamique, et gère la mémoire de manière automatique (via un ramasse-miettes).
Ce langage est proche, par différents aspects, de l'Erlang, du Ruby et du Python.

</doc>
<doc id="4028420" url="http://fr.wikipedia.org/wiki?curid=4028420" title="MUMPS">
MUMPS

MUMPS (Massachusetts General Hospital Utility Multi-Programming System), est un langage de programmation développé par Neil Pappalardo dans le laboratoire vétérinaire du Octo Barnett à l'hôpital général du Massachusetts de Boston entre 1966 et 1967 afin de produire des applications de gestion de bases des données multi-utilisateur. Il fut beaucoup utilisé dans le domaine de la santé mais également dans les systèmes d'informations du monde de la finance entre 1970 et 1980.
Caractéristiques du langage.
MUMPS est un langage conçu pour le développement l'application utilisatrice de base de données, , MUMPS est un langage interprété, .
Dans MUMPS, il n'y a qui est ensuite interprété en chaine de caractères, en entier ou en flottant selon le contexte. Il ne s'agit pas d'un langage faiblement typé mais bien d'un langage non-typé ou plutôt mono-typé. Ainsi, MUMPS n'associe pas les types de données. De cette façon, un nombre peut-être traité comme une chaîne de caractères et une chaîne de caractères peut être traitée comme un nombre avec les opérateurs numériques.
Le typage est dynamique. Les variables ne sont pas déclarées, elles sont créées lors de leur première référence dans le code.
Les commandes et fonctions principales ne sont pas sensibles à la casse. Par contre, les nom des variables et les labels le sont.
Détails important, dans MUMPS, il n'y a pas de mot réservé: Le code est interprété selon le contexte.

</doc>
<doc id="3982522" url="http://fr.wikipedia.org/wiki?curid=3982522" title="NCL (langage)">
NCL (langage)

NCL (sigle de Nat System’s Command Language) est un langage de programmation de 4 génération, créé par Nat System pour l'Environnement de développement intégré NSDK et plus tard utilisé dans Natstar.
Syntaxe.
Structures de contrôle.
Boucles.
Bien qu’elles aient toutes un rôle similaire, chaque boucle est pourtant adaptée à une situation :
Boucle sans condition au début ou à la fin (quand la condition est au milieu des traitements):
Structures conditionnelles.
Structure si : condition simple
Structure si … sinon : condition avec alternative unique
Structure si … ou si … ou si … : condition avec alternatives multiples
Structure atteindre … cas x … cas y …" : embranchement vers un bloc d’instructions énuméré
Evaluate fonctionne avec les types entiers, flottants et chaîne (attention, "A" ≠ "a"). Les expressions dans les Where peuvent être arbitrairement complexes, mais le code est plus efficace quand on utilise uniquement une expression entière dans l'Evaluate et de simples constantes littérales entières (12, $7F) en évitant les grands intervalles (n1 To n2 quand n2 - n1 >= 16) dans les Where.
La commande Break sort immédiatement de la boucle en cours (For, While, Repeat ou Loop), même si elle apparaît dans un Evaluate.
De même, Continue ramène au début de la boucle (en passant à l'itération suivante dans le cas d'une boucle For).
Les instructions Exit ou Return font quitter fonction, instruction ou évènement, en retournant la valeur par défaut (0, 0.0 ou "") selon le type retourné dans le cas des fonctions et évènements.
Avec Return uneValeur, uneValeur sera renvoyée à la méthode appelante (si l'on est dans une fonction ou un évènement appelé par Send avec variable de retour).
Exemples.
Fonction qui retourne l’aire d’un cercle :
La dernière ligne de l'exemple ci-dessus va afficher une fenêtre ayant pour titre "AireDuCercle" et pour contenu la phrase : "L'aire d'un cercle de rayon 2.4cm est 18.0864 cm²."

</doc>
<doc id="4008341" url="http://fr.wikipedia.org/wiki?curid=4008341" title="Simple (programmation)">
Simple (programmation)

Simple est un langage de programmation de Google pour Android.
Il est inspiré du BASIC. 

</doc>
<doc id="2340" url="http://fr.wikipedia.org/wiki?curid=2340" title="Python (langage)">
Python (langage)

Python est un langage de programmation objet, multi-paradigme et multi-plateformes. Il favorise la programmation impérative structurée et orientée objet. Il est doté d'un typage dynamique fort, d'une gestion automatique de la mémoire par ramasse-miettes et d'un système de gestion d'exceptions ; il est ainsi similaire à Perl, Ruby, Scheme, Smalltalk et Tcl.
Le langage Python est placé sous une licence libre proche de la licence BSD et fonctionne sur la plupart des plates-formes informatiques, des supercalculateurs aux ordinateurs centraux, de Windows à Unix en passant par GNU/Linux, Mac OS, ou encore Android, iOS, et aussi avec Java ou encore .NET. Il est conçu pour optimiser la productivité des programmeurs en offrant des outils de haut niveau et une syntaxe simple à utiliser.
Il est également apprécié par les pédagogues qui y trouvent un langage où la syntaxe, clairement séparée des mécanismes de bas niveau, permet une initiation plus aisée aux concepts de base de la programmation.
Utilisations.
Python est un langage qui peut s'utiliser dans de nombreux contextes et s'adapter à tout type d'utilisation grâce à des bibliothèques spécialisées. Il est cependant particulièrement utilisé comme langage de script pour automatiser des tâches simples mais fastidieuses comme par exemple un script qui récupérerait la météo sur Internet ou qui s'intégrerait dans un logiciel de conception assistée par ordinateur afin d'automatiser certains enchaînements d'actions répétitives. On l'utilise également comme langage de développement de prototype lorsqu'on a besoin d'une application fonctionnelle avant de l'optimiser avec un langage de plus bas niveau.
Il est particulièrement répandu dans le monde scientifique, et possède de nombreuses extensions destinées aux applications numériques.
Historique.
Au CWI.
À la fin des années 1980, le programmeur Guido van Rossum participe au développement du langage de programmation ABC au Centrum voor Wiskunde en Informatica (CWI) d'Amsterdam, aux Pays-Bas. Il travaillait alors dans l’équipe du système d’exploitation Amoeba dont les appels systèmes étaient difficilement interfaçables avec le bourne shell utilisé comme interface utilisateur. Il estime alors qu’un langage de script inspiré d’ABC pourrait être intéressant comme interpréteur de commandes pour Amoeba.
En 1989, profitant d’une semaine de vacances durant les fêtes de Noël, il utilise son ordinateur personnel pour écrire la première version du langage. Fan de la série télévisée des Monty Python, il décide de baptiser ce projet Python. Il s’est principalement inspiré d’ABC, par exemple pour l’indentation comme syntaxe ou les types de haut niveau mais aussi de Modula-3 pour la gestion des exceptions, du langage C et des outils UNIX.
Durant l’année suivante, le langage commence à être adopté par l’équipe du projet Amoeba, Guido poursuivant son développement principalement pendant son temps libre. En février 1991, la première version publique, numérotée 0.9.0, est postée sur le forum Usenet alt.sources. La dernière version sortie au CWI fut Python 1.2
Au CNRI.
En 1995, Van Rossum continua son travail sur Python au à Reston, aux États-Unis, où il sortit plusieurs versions du logiciel. 
À partir d', l'équipe Python travaille au CNRI sur "Grail" un navigateur web utilisant Tk. Il est l'équivalent pour Python du navigateur HotJava, permettant d'exécuter des applets dans un environnement sécurisé. La première version publique, disponible en novembre, est la 0.2. Il a entraîné le développement de modules pour la bibliothèque standard comme "rexec", "htmllib" ou "urllib". La version 0.6 sera la dernière de "Grail"; elle est publiée en avril 1999. 
En 1999, le projet "Computer Programming for Everybody" (CP4E) est lancé avec collaboration entre le CNRI et la DARPA. Il s'agit d'utiliser Python comme langage d'enseignement de la programmation. Cette initiative conduira à la création de l'environnement de développement IDLE. Cependant, du fait du manque de financement du projet par la DARPA, et du départ de nombreux développeurs Python du CNRI (dont Guido van Rossum), le projet s’éteint en 2000.. Python 1.6 fut la dernière version sortie au CNRI.
À BeOpen.
En 2000, l'équipe principale de développement de Python déménagea à BeOpen.com pour former l'équipe PythonLabs de BeOpen. Python 2.0 fut la seule version sortie à BeOpen.com. Après cette version, Guido Van Rossum et les autres développeurs de PythonLabs rejoignirent Digital Creations (à présent connue sous le nom de Zope Corporation).
Andrew M. Kuchling a publié en décembre 1999 un texte nommé "python warts" qui synthétise les griefs les plus fréquents exprimés à l'encontre du langage. Ce document aura une influence certaine sur les développements futurs du langage.
La Python Software Foundation.
Python 2.1 fut une version dérivée de Python 1.6.1, ainsi que de Python 2.0. Sa licence fut renommée Python Software Foundation License. Tout code, documentation et spécification ajouté, depuis la sortie de Python 2.1 alpha, est détenu par la Python Software Foundation (PSF), une association sans but lucratif fondée en 2001, modelée d'après l'Apache Software Foundation.
Afin de réparer certains défauts du langage (ex: orientation objet avec deux types de classes), et pour nettoyer la bibliothèque standard de ses éléments obsolètes et redondants, Python a choisi de casser la compatibilité ascendante dans la nouvelle version majeure : Python 3.0, publié en décembre 2008. Cette version a été suivie rapidement par une version 3.1 qui corrige les erreurs de jeunesse de la version 3.0 en la rendant directement obsolète.
Caractéristiques.
Syntaxe.
Python a été conçu pour être un langage lisible. Il vise à être visuellement épuré. Par exemple, il possède moins de constructions syntaxiques que de nombreux langages structurés tels que C, Perl, ou Pascal. Les commentaires sont indiqués par le caractère croisillon.
Les blocs sont identifiés par l'indentation, au lieu d'accolades comme en C ou C++ ; ou de codice_1 comme en Pascal. Une augmentation de l'indentation marque le début d'un bloc, et une réduction de l'indentation marque la fin du bloc courant. Les parenthèses sont facultatives dans les structures de contrôle :
NB : des accolades pourraient être retirées de la version en C mais, des erreurs pouvant être aisément commises en cas d'imbrication de plusieurs blocs, cela ne correspondrait pas aux normes de codages habituellement recommandées. À noter que l’indentation automatique mise en oeuvre par les éditeurs de code modernes ôte toute raison d'être à cette habitude. En conséquence, il est de plus en plus souvent conseillé de ne pas utiliser d’accolades, afin de favoriser la lisibilité du code, et, ce, dans un esprit analogue à celui de Python.
Mots-clés du langage.
Les mots-clés sont fournis dans la liste codice_2 du module codice_3. Les mots-clés de Python 2.7.5 sont les suivants : codice_4, codice_5, codice_6, codice_7, codice_8, codice_9, codice_10, codice_11, codice_12, codice_13, codice_14, codice_15, codice_16, codice_17, codice_18, codice_19, codice_20, codice_21, codice_22, codice_23, codice_24, codice_25, codice_26, codice_27, codice_28, codice_29, codice_30, codice_31, codice_32, codice_33, codice_34.
À partir de Python 3.0, codice_28 et codice_15 ne sont plus des mots-clés du langage, mais des fonctions du module codice_37. Sont ajoutés aux mots-clés : codice_38, codice_39, codice_40 et codice_41. Les trois premiers étaient déjà présents dans les versions précédentes, mais ils ne sont plus modifiables (auparavant, l'affectation codice_42 était possible). codice_41 a été introduit par le PEP 3104, et permet, dans une fonction définie à l'intérieur d'une autre fonction, de modifier une variable d'un niveau supérieur de portée. Avant cela, seules les variables locales à la fonction, et globales (niveau module) étaient modifiables.
Types de base.
Les types de base en Python sont relativement complets et puissants, il y a entre autres :
Les objets itérables sont parcourus à l'aide d'une boucle codice_17 de la manière suivante :
Pour une chaîne de caractères, l'itération procède caractère par caractère.
Il est possible de dériver les classes des types de base pour créer ses propres types.
On peut également fabriquer ses propres types d'objets itérables sans hériter des itérables de base en utilisant le protocole d'itération du langage.
Programmation fonctionnelle.
Python permet de programmer dans un style fonctionnel. Les compréhensions de listes sont disponibles. Par exemple, pour construire la liste des carrés des entiers naturels plus petits que 10, on peut utiliser l'expression :
la liste des nombres pairs :
Une forme limitée de fonctions lambda, ou fonctions anonymes, est disponible :
Les fonctions lambda peuvent être définies en ligne et utilisées comme arguments dans des expressions fonctionnelles : retournera une liste constituée des éléments de une_liste inférieurs à 5. Le même résultat peut être obtenu avec 
Les lambdas de Python n'admettent que des expressions et ne peuvent être utilisées comme fonctions anonymes généralisées ; mais en Python, toutes les fonctions sont des objets, elles peuvent donc être passés en arguments d'autres fonctions, et appelés lorsque nécessaire. En effet, les fonctions définies avec def sont équivalentes à celles définies avec lambda, il est d'ailleurs possible de définir une fonction à l'intérieur d'une autre fonction et ainsi obtenir une définition de fonction dans une variable locale, exemple :
Programmation objet.
La programmation objet est très bien supportée par Python : tous les types de base, les fonctions, les instances de classes (les objets « classiques » des langages C++ et Java) et les classes elles-mêmes (qui sont des instances de méta-classes) sont des objets.
Une classe se définit avec le mot codice_8. Les classes Python supportent l'héritage multiple ; il n'y a pas de surcharge statique comme en C++,ou des restrictions sur l'heritage comme le cas en java (une classe implémente plusieurs interface et hérite d'une seule classe) mais le mécanisme des arguments optionnels et par mot-clef est plus général et plus flexible. En Python, l'attribut d'un objet peut référencer une variable d'instance ou de classe (le plus souvent une méthode). Il est possible de lire ou de modifier un attribut dynamiquement avec les fonctions :
Exemple de deux classes simples :
Méthodes spéciales et définition des opérateurs.
Python fournit un mécanisme élégant et orienté objet pour définir un ensemble pré-défini d'opérateurs : tout objet Python peut se voir doté de méthodes dites spéciales.
Ces méthodes, commençant et finissant par deux tirets de soulignement "(underscores)", sont appelées lors de l'utilisation d'un opérateur sur l'objet : codice_66 (méthode codice_67), codice_68 (méthode codice_69), codice_70 (méthode codice_71), codice_72 (méthode codice_73), … Des méthodes comme codice_74 et codice_75, permettent de définir la représentation d'un objet dans l'interpréteur interactif et son rendu avec le mot clé "print". 
Les possibilités sont nombreuses et sont décrites dans la documentation du langage.
Par exemple on peut définir l'addition de deux vecteurs à 2 dimensions avec la classe suivante :
Générateurs.
Le mot-clef "yield" utilisé dans une fonction permet de faire de cette fonction un générateur. L'appel de cette fonction renvoie un objet de type "generator", qui peut être utilisé dans une boucle "for", par exemple.
À chaque appel, le générateur effectue son traitement jusqu'à rencontrer le mot-clé "yield", renvoie la valeur de l'expression "yield", et à l'appel suivant, reprend son déroulement juste après le "yield". Par exemple pour calculer la suite de Fibonacci, on peut faire :
Un générateur peut sembler identique à une fonction qui retourne une liste, mais contrairement à une liste qui contient "tous" ses éléments un générateur calcule ses éléments "un" par un.
Réflexivité.
Grâce à un usage intensif des dictionnaires (conteneur associatif développé avec des tables de hachage), Python permet d'explorer les divers objets du langage (introspection) et dans certains cas de les modifier (intercession).
Typage.
Le typage n'est pas vérifié à la compilation. De ce fait, des opérations sur un objet peuvent échouer, signifiant que l'objet en question n'est pas du bon type. Malgré l'absence de typage statique, Python est fortement typé, interdisant des opérations ayant peu de sens (comme, par exemple, additionner un nombre à une chaîne de caractères) au lieu de tenter silencieusement de la convertir en une forme qui a du sens. Python propose des fonctions permettant de transformer les variables dans un autre type :
De même, chaque variable devra être déclarée avant d'être utilisée.
Python propose aussi un mécanisme de typage fort grâce à l'API "trait" ou au design pattern "decorators".
Compilation.
Il est possible d'effectuer une analyse statique des modules Python avec des outils comme Pylint ou PyChecker. Sans nécessiter une exécution, ces outils repèrent des fautes ou des constructions déconseillées. Par exemple, une classe qui hérite d'une classe abstraite et qui ne redéfinit pas les méthodes abstraites, ou bien des variables utilisées avant d'être déclarées, ou encore des attributs d'instance déclarés en dehors de la méthode codice_76.
Il est aussi possible de générer un code intermédiaire (bytecode) Python.
Des outils comme PyInstaller ou d'autres plus spécifiques comme cx_Freeze sous Unix, Windows et Mac OS X, py2app sous Mac OS X et py2exe sous Windows permettent de « compiler » un programme Python sous forme d'un exécutable comprenant le programme et un interpréteur Python.
Le programme ne tourne pas plus rapidement (il n'est pas compilé sous forme de code machine) mais cela simplifie largement sa distribution, notamment sur des machines où l'interpréteur Python n'est pas installé.
Modèle objet.
En Python, "tout est objet", dans le sens qu'une variable peut contenir une référence vers tous les éléments manipulés par le langage : nombres, méthodes, modules. Néanmoins, avant la version 2.2, les classes et les instances de classes étaient un type d'objet particulier, ce qui signifiait qu'il était par exemple impossible de dériver sa propre sous-classe de l'objet "list".
Méthodes.
Le modèle objet de Python est inspiré de celui de Modula-3. Parmi ces emprunts se trouve l'obligation de déclarer l'instance de l'objet courant, conventionnellement nommée "self", comme premier argument des méthodes, et à chaque fois que l'on souhaite accéder à une donnée de cette instance dans le corps de cette méthode. Cette pratique n'est pas naturelle pour des programmeurs venant par exemple de C++ ou Java, la profusion des "self" étant souvent critiquée comme étant une pollution visuelle qui gène la lecture du code. Les promoteurs du "self" explicite estiment au contraire qu'il évite le recours à des conventions de nommage pour les données membres et qu'il simplifie des tâches comme l'appel à une méthode de la superclasse ou la résolution d'homonymie entre données membres. 
Python reconnaît trois types de méthodes :
Visibilité.
Le langage a un support très limité de l'encapsulation. Il n'y a pas, comme en java par exemple, de contrôle de l'accessibilité par des mots clefs comme codice_79 ou codice_80.
La philosophie de Python est de différencier conceptuellement l'encapsulation du masquage d'information. Le masquage d'information vise à prévenir les utilisations frauduleuses, c'est une préoccupation de sécurité informatique. Le module "bastion" de la bibliothèque standard, qui n'est plus maintenu dans les dernières versions du langage, permettait ainsi de contrôler l'accès aux attributs d'un objet dans le cadre d'un environnement d'exécution restreint.
L'encapsulation est une problématique de développement logiciel. Le slogan des développeurs Python est "we're all consenting adults here" (nous sommes entre adultes consentants). Ils estiment en effet qu'il suffit d'indiquer, par des conventions d'écriture, les parties publiques des interfaces et que c'est aux utilisateurs des objets de se conformer à ces conventions ou de prendre leurs responsabilités. L'usage est de préfixer par un underscore les membres privés. Le langage permet par ailleurs d'utiliser un double underscore pour éviter les collisions de noms, en préfixant automatiquement le nom de la donnée par celui de la classe où elle est définie. 
L'utilisation de la fonction codice_81 permet de définir des propriétés qui ont pour but d'intercepter, à l'aide de méthodes, les accès à une donnée membre. Cela rend inutile la définition systématique d'accesseurs et le masquage des données comme il est courant de le faire en C++ par exemple.
Héritage.
Python supporte l'héritage multiple. Depuis la version 2.3, il utilise l', issu du langage Dylan, pour résoudre l'ordre de résolution de méthode ("MRO"). Les versions précédentes utilisaient un algorithme de parcours en profondeur qui posait des problèmes dans le cas d'un héritage en diamant.
Bibliothèque standard.
Python possède une grande bibliothèque standard, fournissant des outils convenant à de nombreuses tâches diverses. Le nombre de modules de la bibliothèque standard peut être augmenté avec des modules spécifiques écrits en C ou en Python. 
La bibliothèque standard est particulièrement bien conçue pour écrire des applications utilisant Internet, avec un grand nombre de formats et de protocoles standards gérés (tels que MIME et HTTP). Des modules pour créer des interfaces graphiques et manipuler des expressions rationnelles sont également fournis. Python inclut également un framework de tests unitaires (codice_82, anciennement PyUnit avant version 2.1) pour créer des suites de tests exhaustives.
Conventions de style.
Bien que chaque programmeur puisse adopter ses propres conventions pour l'écriture de code Python, Guido van Rossum a mis un guide à disposition, référencé comme « PEP 8 ». Publié en 2001, il est toujours maintenu en 2013, pour l'adapter aux évolutions du langage. Google propose également un guide.
Interfaces graphiques.
Python possède plusieurs modules disponibles pour la création de logiciels avec une interface graphique. Le plus répandu est Tkinter. Ce module convient à beaucoup d'applications et peut être considéré comme suffisant dans la plupart des cas. Néanmoins, d'autres modules ont été créés pour pouvoir lier Python à d'autres bibliothèques logicielles (« "toolkit" »), pour davantage de fonctionnalités, pour une meilleure intégration avec le système d'exploitation utilisé, ou simplement pour pouvoir utiliser Python avec sa bibliothèque préférée. En effet, certains programmeurs trouvent l'utilisation de Tkinter plus pénible que d'autres bibliothèques. Ces autres modules ne font pas partie de la bibliothèque standard et doivent donc être obtenus séparément.
Les principaux modules donnant accès aux bibliothèques d'interface graphique sont Tkinter et Pmw (Python megawidgets) pour Tk, wxPython pour wxWidgets, PyGTK pour GTK+, PyQt et PySide pour Qt, et enfin FxPy pour le FOX Toolkit. Il existe aussi une adaptation de la bibliothèque SDL : Pygame, un binding de la SFML : PySFML, ainsi qu'une bibliothèque écrite spécialement pour Python : .
Il est aussi possible de créer des applications Silverlight en Python sur la plateforme IronPython.
La communauté Python.
Van Rossum est le principal auteur de Python, et son rôle de décideur central permanent de Python est reconnu avec humour par le titre de « Dictateur bienveillant à vie » ("Benevolent Dictator for Life", BDFL).
Il est assisté d'une équipe de "core developers" qui ont un accès en écriture au dépôt de CPython et qui se coordonnent sur la liste de diffusion python-dev. Ils travaillent principalement sur le langage et la bibliothèque de base. Ils reçoivent ponctuellement les contributions d'autres développeurs Python via la plateforme de gestion de bug Roundup, qui a remplacé SourceForge.
Les utilisateurs ou développeurs de bibliothèques tierces utilisent diverses autres ressources. Le principal média généraliste autour de Python est le forum Usenet anglais comp.lang.python.
Les allusions aux Monty Python sont assez fréquentes. Les didacticiels consacrés à Python utilisent souvent les mots "spam" et "eggs" comme variable métasyntaxique. Il s'agit d'une référence au sketch "Spam" des Monty Python, où deux clients tentent de commander un repas à l'aide d'une carte qui contient du jambon en conserve de marque SPAM dans pratiquement tous les plats. Ce sketch a été aussi pris pour référence pour désigner un email non sollicité.
Adoption de Python.
Plusieurs entreprises mentionnent sur leur site officiel qu'elles utilisent Python :
Python est aussi le langage de commande d'un grand nombre de logiciels libres :
Python est utilisé comme langage de programmation dans l'enseignement élémentaire et supérieur 
Implémentations du langage.
Outre la version de référence, nommée CPython (car écrite en langage C), il existe d'autres systèmes mettant en œuvre le langage Python :
Ces autres versions ne bénéficient pas forcément de la totalité de la bibliothèque de fonctions écrites en C pour la version de référence.
Les distributions.
Différentes distributions sont disponibles, qui incluent parfois beaucoup de packages dédiés à un domaine donné :
Développement.
Les PEP.
Les propositions d'amélioration de Python (ou « PEP » : "Python Enhancement Proposal") sont des documents textuels qui ont pour objet d'être la voie d'amélioration de Python et de précéder à toutes ses modifications ultérieures. Un pep est une proposition d'orientation pour le développement "(process PEP)", une proposition technique "(Standard Track PEP)" ou une simple recommandation ("Informational PEP", la plus célèbre étant certainement celle de Tim Peters : http://www.python.org/dev/peps/pep-0020/). 
À leur sortie, les PEP sont relus et commentés par le BDFL.
Python 3000.
Une nouvelle version de Python, appelée Python 3.0 (le projet était appelé « Python 3000 » ou « Py3K ») abolit la compatibilité descendante avec la série des versions 2.x, dans le but d'éliminer les faiblesses du langage. La ligne de conduite du projet était de « réduire la redondance dans le fonctionnement de Python par la suppression des méthodes obsolètes ». Python 3.0a1, la première version alpha, a été publiée le 31 août 2007, et il existe un PEP qui détaille les changements prévus, ainsi qu'une page pour orienter les programmeurs dans leur choix de Python 2 ou 3.
Philosophie.
Python 3.0 a été développé avec la même philosophie que dans ses versions antérieures, donc toute référence à la philosophie de Python s'appliquera aussi bien à la version 3.0. Comme toujours, Python a accumulé beaucoup de nouvelles méthodes qui font en fait acte de redondance avec d'autres préexistantes. Python 3.0, en recherchant la suppression du code redondant et des modules semblables, suit la grande directive philosophique de Python « Il ne devrait subsister qu'une seule méthode, qui soit à la fois optimale et naturelle pour chaque chose ».
En dépit de cela, Python 3.0 restera un langage multi-paradigme. Les programmeurs auront encore le choix entre l'orientation objet, la programmation structurée, la programmation fonctionnelle et d'autres paradigmes ; en dépit du choix existant, Python 3.0 a cependant pour but d'être utilisé de manière plus naturelle que dans les versions 2.x.
Planning et compatibilité.
Python 3.0a1, la première version alpha de Python 3.0, a été publiée le 31 août 2007. Les versions 2.x et 3.x de Python seront publiées en parallèle pendant plusieurs cycles de développement, pendant lesquels la série des 2.x subsistera principalement pour la compatibilité, en incluant quelques caractéristiques importées depuis Python 3.x. Le PEP 3000 contient plus d'informations à propos du processus de publication d'une version.
Comme Perl 6, Python 3.0 rompt la compatibilité descendante (rétro-compatibilité). L'utilisation de code écrit pour les séries 2.x n'est pas garantie avec Python 3.0. Ce dernier apporte des changements fondamentaux, comme le passage généralisé à l'Unicode pour les chaînes de caractères et une distinction forte entre les chaînes de caractère et les objets « bytes ». Le typage dynamique associé à certaines méthodes sur les objets de type dictionnaire font qu'une transition parfaite de Python 2.x vers Python 3.0 est très difficile. Comme toujours, un outil nommé « 2to3 » réalise la plus grande part du travail de traduction des versions 2.x vers les versions 3.x, en indiquant les zones de codes sujettes à caution par des commentaires spéciaux et des mises en garde.
De plus, dans sa pré-version, 2to3 semble réussir franchement à réaliser une traduction correcte. Dans le cadre d'une migration de Python 2.x vers Python 3.x, le PEP 3000 recommande de conserver le code original comme base des modifications et de le "traduire" pour la plateforme 3.x en utilisant 2to3. 
Python 2.6 devra fournir des caractéristiques de compatibilité ascendante, aussi bien qu'un mode « mise en garde » qui devrait faire prendre conscience des problèmes potentiels de transition pour le passage à Python 3.0.
Python pour smartphones.
Il existe des versions de python adaptées pour Android et iPhone en version 2.6 ou 2.5. Disponible en Jailbreak d'iOS sur iOS grâce à "setup tools", et sur Android grâce à SL4A qui donne même une possibilité de faire des petites interface graphiques grâce au module "android" et qui permet d'envoyer des SMS, d'allumer la caméra, ou encore de faire vibrer le téléphone. Les quelques lignes suivantes montrent comment faire ça : 
Un portage de Python sur les les terminaux Blackberry est sortie en juin 2012, pour le système BlackBerry OS 10. Une version allégée est sortie en septembre 2012, appelée « BlackBerry-Tart », en raison d'un jeu de mots en anglais : « "a "tart" is lighter-weight than a "pie"" ». Elle est basée sur Python 3.2.2.

</doc>
<doc id="4230561" url="http://fr.wikipedia.org/wiki?curid=4230561" title="Go (langage)">
Go (langage)

Go est un langage de programmation compilé et concurrent inspiré de C et Pascal. Ce langage a été développé par Google à partir d'un concept initial de Robert Griesemer, Rob Pike et Ken Thompson. Go possède deux implémentations, la première utilise gc, le compilateur Go et la seconde utilise gccgo un « frontend » GCC écrit en C++. Gc est écrit en C en utilisant yacc et GNU Bison pour l'analyse syntaxique
Go a pour but de faciliter et d'accélérer la programmation à grande échelle : La compilation est de 80 % à 90 % plus rapide que la compilation classique du C. Il vise également la rapidité d'exécution, indispensable à la programmation système.
Voici un exemple d'un programme Hello world typique écrit en Go.
Caractéristiques.
Le langage Go a été créé pour la programmation système et a depuis été étendu aux applications, ce qui constitue la même cible que le C et surtout le C++. Il s'agit d'un langage impératif et concurrent.
Concurrence.
Go intègre la concurrence en son cœur, permettant très facilement d’exécuter du code en concurrence. Il suffit d'utiliser le mot clé codice_1 pour qu'un appel de fonction puisse être exécuté en concurrence du thread courant. Ce code exécuté en concurrence s'appelle une goroutine par analogie avec les coroutines. Le programme prendra alors avantage de la topologie de l'ordinateur pour exécuter au mieux les goroutines, pas forcément dans un nouveau thread, mais il est aussi possible qu'un groupe de goroutines soit multiplexé sur un groupe de threads.
Les goroutines peuvent communiquer entre elles par passage de messages, en envoyant ou en recevant des messages sur des canaux.
Cet échange de message est le mécanisme principal de synchronisation des goroutines entre elles, conformément au modèle CSP, considéré par les auteurs comme plus facile à maîtriser par le développeur que le modèle multi-threadé (avec synchronisation via sémaphores, verrous ...).
Système de types.
Go a un système de type statique, fortement typé et sûr, basé sur l'inférence de types avec la possibilité d'utiliser un typage explicite.
La compatibilité des types composés est basée sur les propriétés plutôt que sur le nom. C'est-à-dire que deux types composés seront équivalents si leurs propriétés sont équivalentes : même nom pour la propriété et équivalence de type.
Cela a pour conséquence que le langage n'est pas objet au sens classique (soit avec classes, soit avec prototype), cependant les concepteurs du langage ont fait un choix plus original pour un langage statique. Il est possible de définir des interfaces portant des méthodes décrivant le comportement d'un objet (Il est aussi facilement possible de mélanger plusieurs interfaces en une seule). Les fonctions Go peuvent déclarer accepter un argument de cette interface. Un objet déclarant toutes les méthodes de cette interface, avec la même signature, peut être passé en argument de cette méthode. La vérification du type est effectuée statiquement par le compilateur.
Le fait que Go ne soit pas objet au sens classique fait que Go n'a pas d'héritage de type et pas de sous-classage. Ceci permet de contourner les problèmes posés par ces systèmes tels l'héritage multiple dans les langages qui le permettent (en C++ par exemple), ou l'héritage simple (en Java par exemple). Grâce à l'équivalence de types basée sur les propriétés, Go n'a pas besoin d'héritage de type. Le sous-classage est émulé par l'« embarquement de type ».
La visibilité des structures, attributs, variables, constantes, méthodes, types de haut niveau et des fonctions hors de leur paquetage de déclaration est définie par la casse du premier caractère de leurs identificateurs.
Divers.
Dans Go, la gestion de la mémoire est laissée à un ramasse-miettes.
Il n'y a pas encore de programmation générique même si les concepteurs du langage y réfléchissent. Il n'y a pas de surcharge de méthodes ou d'arithmétique des pointeurs. Enfin, il n'y a pas d'assertions ou d'exceptions. Pour remplacer ces deux derniers, Go fournit les mots clés codice_2, codice_3 et codice_4 qui donnent des mécanismes similaires aux systèmes de gestion des exceptions de langages tels que C++ et Java (mots clés codice_5, codice_6, codice_7 et codice_8).
Go peut s'interfacer avec des bibliothèques en C/C++, des développeurs tiers ayant déjà développé des bindings pour SDL, MySQL, ...
Go définit un format de code standard (au niveau des indentations, de la présentations des structures de contrôle) et fournit un outil pour l'appliquer (go fmt).
Go propose également un système de documentation à partir du code et un framework de test.
L'unité de compilation de go est le package qui est représenté dans l'implémentation standard par un répertoire et les fichiers directement contenu dans ce répertoire.
L'import d'un package se fait par son chemin d'importation et peut préciser soit une bibliothèque standard, soit également des packages tiers installé dans des dépôts de sources distants (actuellement supporté : dépôt sous svn, git, mercurial et bazaar)

</doc>
<doc id="4233496" url="http://fr.wikipedia.org/wiki?curid=4233496" title="Go! (langage)">
Go! (langage)

Go! est un langage de programmation concurrent, originellement conçu par Keith Clark et Francis McCabe en 2003. Il est orienté vers le besoin de programmer des agents d'applications surs, de qualité de production. Il est multi-thread, fortement typé et d'un niveau élevé (au sens de la programmation fonctionnelle). Il a des définitions de relation, de fonctions et de procédures d'action. Les threads exécutent les procédures d'action, les appels de fonctions et les "querying relations" au besoin. Les threads des différents agents communiquent et se coordonnent en utilisant des messages asynchrones. Les threads à l'intérieur d'un même agent peuvent également utiliser des relations dynamiques partagées agissant comme des registres mémoires.
Sa nature comme langage de programmation multi-paradigme, intégrant des styles de la programmation logique, fonctionnelle et orientée objet, est particulièrement mise en œuvre dans les modèles basés sur une ontologie, tel qu'employés par le web sémantique en permettant un système type où les classes OWL peuvent être représentées dans le système type. La conception de Go!, d'après Bordini et al.'s survey.
Depuis le lancement du langage de programmation de Google, Go! et Go sont devenus le sujet d'une polémique sur le nom du langage qui n'est pas résolue au 12 novembre 2009.
Modèle de Communication.
Les threads à l'intérieur d'un même processus Go!, et donc dans le même agent, peuvent aussi communiquer en manipulant des objets à relation dynamiques, comparable aux registres de tuple de Linda, utilisés pour coordonner leurs activités.
Exemple.
L'exemple suivant montre le style de type et de déclarations 'ontology-oriented' de Go!.

</doc>
<doc id="4244847" url="http://fr.wikipedia.org/wiki?curid=4244847" title="X10 (langage de programmation)">
X10 (langage de programmation)

X10 est un langage de programmation en cours de développement chez IBM "Thomas J. Watson Research Center" financé par le projet "High Productivity Computing Systems" de DARPA. Les auteurs principaux sont Kemal Ebcioğlu, Vijay Saraswat, and Vivek Sarkar.
X10 est conçu pour la programmation parallèle avec le modèle "espace d'adressage global partagé" (PGAS). Un programme s'exécuter sur un ensemble de "places" : chaque place possède des données et quelques "activities" qui font des calculs sur ces données. Il supporte un système de typage avec des contraintes pour la programmation orientée objet, les types primitifs "structs" définis par l'utilisateur, les "globally distributed arrays" et le parallélisme structuré et non structuré.

</doc>
<doc id="3480643" url="http://fr.wikipedia.org/wiki?curid=3480643" title="Common Intermediate Language">
Common Intermediate Language

Dans l'environnement de programmation Microsoft, le Common Intermediate Language (CIL) est le langage de programmation de plus bas niveau qui peut être lu par un humain. Le code de plus haut niveau dans l'environnement .NET Framework est compilé en code CIL qui est assemblé dans un code dit bytecode. CIL est un code assembleur orienté objet et pile. Il est exécuté par une machine virtuelle.
Le CIL était initialement connu sous le nom de Microsoft Intermediate Language ou MSIL durant les béta du langage .NET. Après la standarisation du C sharp et de la CLI, le bytecode fut officiellement référencé sous le nom de CIL. Les utilisateurs précoces de la technologie continuent néanmoins à se référer au terme MSIL.
Compilateur JIT/NGEN.
Durant la compilation .NET, le code source est transformé en un code CIL portable, indépendant de la plateforme et du processeur, et appelé bytecode.
Ce bytecode est compilé par la CLR/DLR en temps réel pour obtenir un code immédiatement exécutable par le processeur. Durant cette compilation, le compilateur (JIT) effectue un grand nombre de tâches pour éviter des accès illégaux à la mémoire :
Cette compilation peut aussi être réalisée avec un générateur natif d'image (NGEN). Cet outil a pour but de supprimer le temps d'attente dû à la compilation qui a lieu au niveau des CLR et DLR . Attention, l'image binaire native est placée dans le cache des 'assemblies' mais nécessite pour s'exécuter le fichier d'origine (certaines informations ne sont pas recopiées dans l'image).
.NET metadata.
.NET enregistre les informations concernant les classes compilées dans un fichier de nom metadata. Ces données agissent comme la bibliothèque Component Object Model, et permettent aux applications compatibles de découvrir les interfaces, les classes, les types, et les méthodes présentes dans le code assembleur. Le processus de lecture de ces données est appelé réflexion. Ces données peuvent être lues en utilisant l'outil ILDASM fourni avec le SDK .NET Framework.
Toute la CIL est autodescriptive, grâce aux Métadonnées .NET. La CLR vérifie les métadonnées pour s'assurer que la bonne méthode est appelée. Les métadonnées sont généralement générées par les compilateurs des langages, mais les développeurs peuvent aussi créer leurs propres métadonnées via l'utilisation d'attributs personnalisés. Les métadonnées contiennent aussi des informations à propos des assemblages et sont aussi utilisées pour implémenter la capacité de réflexion du .NET Framework.
.NET assemblies.
Le code CIL est stocké dans les assemblages .NET (ou assemblies).
L'assemblage est le bloc de structuration fondamental des applications .NET. Un assemblage regroupe l'ensemble des éléments nécessaires au bon fonctionnement d'une application (ou partie d'une application) : exécutables, métadonnées, autorisations, ressources (images...), etc...
Le concept d'assemblage a été introduit pour résoudre les problèmes d'installation, d'évolution de version, d'internationalisation, de contexte d'exécution, de conflits de DLL... À ce titre, c'est une unité de déploiement indivisible.
Les assemblages sont constitués d´un ou plusieurs fichiers, dont l'un doit contenir un document XML appelé manifeste. Le manifeste contient :
Les assemblages .NET sont enregistrés au format exécutable portable (PE) courant sur la plate-forme Windows pour tous les fichiers DLL ou EXE. Le nom complet d'un assemblage (à ne pas confondre avec le nom du fichier sur le disque) contient son nom simple, son numéro de version, sa culture et sa clé publique. La clé publique est unique et est générée à partir du hachage de l'assemblage après sa compilation. En conséquence, deux assemblages avec la même clé publique sont garantis être identiques. Une clé privée peut aussi être spécifiée ; elle est uniquement connue du créateur de l'assemblage et peut être utilisée pour le nommage fort de celui-ci. Cela garantit que l'assemblage est du même auteur lors de la compilation d'une nouvelle version.
Le code CIL d'un assemblage .NET existe sous deux formes : exécutables (process assemblies) et DLL (library assemblies). Lors de la compilation, le choix du format final du fichier contenant le code source ne dépend pas de l'extension du fichier mais d'une information stockée dans un fichier PE. Ce fait explique que, dans un même répertoire, deux fichiers de même nom mais avec des extensions différentes ne peuvent par défaut exister. Ce problème a été résolu par l'utilisation d'une clé publique/privée pour signer une DLL ou un exécutable et par l'introduction par .NET du GAC.

</doc>
<doc id="4416059" url="http://fr.wikipedia.org/wiki?curid=4416059" title="VisSim">
VisSim

VisSim est un langage de programmation visuelle distingué par sa capacité à modéliser et à simuler des systèmes dynamiques complexes. VisSim associe une interface intuitive d’assemblage de blocs de diagrammes (par glisser/déposer) à un puissant moteur de simulation. Il est développé par la société américaine Visual Solutions, de Westford.
Applications.
VisSim est largement utilisé pour la conception et la simulation de projets dans le domaine des systèmes de contrôle et de traitement numérique de signal. Il intègre des blocs pour l’arithmétique, le booléen et les fonctions transcendantes, ainsi que des filtres numériques, des fonctions de transfert, l’intégration numérique et un interactif de traçage. Les applicatifs les plus couramment modélisés sont du domaine de l’aéronautique, de la biologie ou de la recherche médicale, de la capacité de puissance numérique, des moteurs électriques, ainsi que du procédé électrique, hydraulique, mécanique ou économétrique.
Programme Académique.
Le Programme Académique VisSim permet aux établissements d’enseignement accrédités l’usage d’une licence libre de VisSim v3.0. Les dernières versions de VisSim, ainsi que leurs fonctionnalités additionnelles, sont également proposées aux étudiants et aux établissements universitaires à des prix considérablement réduits.
Partage des diagrammes.
Le Visualiseur VisSim offre un moyen gratuit de partager des modèles avec ses collègues ou des clients, sans licence VisSim complémentaire. Le visualiseur peut exécuter toutes sortes de modèles à partir de VisSim, tout en permettant d’effectuer certains changements dans les blocs ou dans les paramètres de simulation, afin d’illustrer des scénarios de différentes conceptions. Il est possible d’activer ou de changer les boutons inclus dans le modèle.
Code source.
La fonctionnalité additionnelle VisSim/C-Code convertit automatiquement les modèles VisSim en un code C ANSI hautement optimisé, qui peut être compilé et exécuté sur toute plate-forme acceptant ce langage. Il en résulte un code plus efficace et plus lisible que par la plupart des autres générateurs de codes. Le développeur de VisSim a siégé au comité « X3J11 ANSI C » et a écrit divers compilateurs C, de même qu’un livre sur le langage C.
Ingénierie dirigée par modèle.
La construction de modèles est un moyen visuel de se représenter une situation, en utilisant des blocs de résolution de problèmes au lieu de former des équations simultanées avec notations mathématiques. Si un modèle est construit à partir d’une situation concrète, la solution devient plus claire, voire évidente, alors que l’on rencontre fréquemment des problèmes au niveau des équations mathématiques à l’usage de solutions moins performantes.
Les diagrammes imbriqués sont faciles à créer : vous construisez normalement les modèles avec différentes couches VisSim, si nécessaire combinés avec des blocs personnalisés écrits en C ou Fortran, puis un contrôleur virtuel est ajouté avec l’assistance nécessaire pour obtenir toute la réponse souhaitée du système global. Il est encore possible d’ajouter des curseurs et des boutons, rendant plus facile la réalisation de divers scénarios destinés à la formation des opérateurs ou le contrôle de mise au point. La technique de simulation des performances du système hors connexion, suivi de la production automatique du code à partir du diagramme simulé est connue sous le nom de « Développement architecturé autour d’un modèle ». Il s’agit d’un développement basé sur un modèle pour systèmes embarqués : largement adopté pour les systèmes de production, il raccourcit les cycles de développement matériel de la même manière que l’architecture dirigée par modèle raccourcit les cycles de développement logiciel.

</doc>
<doc id="4471819" url="http://fr.wikipedia.org/wiki?curid=4471819" title="NesC">
NesC

NesC est un langage de programmation dérivé du langage C, fait pour minimiser l’utilisation de mémoire et de puissance de calcul par les capteurs, qui très souvent disposent de ressources très limitées (batterie de faible puissance et non changeable, mémoire réduite...).

</doc>
<doc id="4492793" url="http://fr.wikipedia.org/wiki?curid=4492793" title="Dylan (langage)">
Dylan (langage)

Dylan est un langage de programmation dynamique, réflexif, orienté objet et fonctionnel. Il propose un modèle de programmation axé vers une génération efficace de code machine. Il a été créé au début des années 1990 par un groupe conduit par Apple pour son PDA, l'Apple Newton.
Syntaxe et exemples.
À l'origine, Dylan utilisait une syntaxe préfixée, similaire à Scheme ou LISP, basée sur les S-expressions :
codice_1
Avant que la conception du langage ne soit terminée, elle fut remplacée par une syntaxe proche de l'Algol, conçue par Michael Kahl, dans l'espoir qu'elle serait familière au plus grand nombre de développeurs :
codice_2
Comme dans d'autres langages fonctionnels, le résultat d'une fonction est sa dernière expression évaluée (l'instruction "return" est donc inutile). L'exemple suivant montre l'implémentation récursive de la fonction factorielle
codice_3
Applications.
Outre son utilisation pour le PDA Newton d'Apple, Dylan est employé pour :

</doc>
<doc id="4614158" url="http://fr.wikipedia.org/wiki?curid=4614158" title="Frink (langage)">
Frink (langage)

Frink est un outil de calcul et un langage de programmation conçu par Alan Eliasen. Il est construit sur la machine virtuelle Java et inclut des fonctionnalités similaires à Java, Perl, Ruby, Smalltalk, et des nombreuses implémentations du BASIC. Il se concentre principalement sur les domaines des sciences, sciences de l'ingénieur, physique, traitement de textes et éducation.
Le langage est nommé d'après le savant fou fictif Professeur John Frink de la série télévisée populaire "Les Simpson", qui a prédit, des années auparavant, ""Je prédis que d'ici 100 ans, les ordinateurs seront deux fois plus puissant, dix mille fois plus grand, et si chers que seulement les cinq rois les plus riches d'Europe les possèderont.""
L'une des caractéristique notable de Frink est qu'il conserve les unités de mesure à travers tous les calculs. Cela permet à toutes les valeurs de contenir une quantité et une unité de mesure. Frink comprend comment différentes unités sont reliées, comme une longueur élevée à la puissance trois est un volume, ou la puissance multipliée par le temps est de l'énergie. Différentes unités de mesure peuvent être mélangées dans les calculs, et Frink automatiquement, s'assure que les calculs aboutisse à un résultat dans les dimensions attendues.
codice_1
La distribution standard vient avec un fichier de données contenant plusieurs milliers des unités de mesure les plus communes, avec des données telles que les masses des particules élémentaires, des données astronomiques et des mesures historiques. Le fichier de données standard utilise le système d'unité (SI) internationales comme base et l'étend avec des unités monétaires et informatiques (bits). Le fichier standard peut être complètement remplacé par l'utilisateur et de nouvelles unités peuvent être ajouté lors de l'utilisation.
La syntaxe de Frink essaie de suivre la notation mathématique standard lorsque sans ambiguïté. Par exemple, la déclaration ci-dessus peut être réécrite en utilisant la multiplication implicite entre les trois unités:
codice_2

</doc>
<doc id="4619825" url="http://fr.wikipedia.org/wiki?curid=4619825" title="Portal (langage)">
Portal (langage)

Portal est un langage de programmation créé par R.Schild et H.Lienard du Laboratoire de recherche de LGZ Landis & Gyr à Zoug en 1978, spécialisé pour la programmation temps réel et la programmation concurrente.
Dérivé de Pascal, il adopte en matière d'entrée/sortie la politique suivie par le PDP11, certains processeurs Motorola et le langage APL : les entrées-sorties se ramènent à des affectations, dès qu'on a associé à chaque port nécessaire une variable de même adresse. 
Définir une procédure la crée comme type, dont les instanciations seront des tâches. 
Enfin, Portal permet de définir facilement des moniteurs.

</doc>
<doc id="1015539" url="http://fr.wikipedia.org/wiki?curid=1015539" title="ABAL">
ABAL

ABAL est un langage de programmation conçu et distribué par la société Prologue (aux Ulis en France).
ABAL (Avanced Business Application Language) est un langage procédural orienté objet.
ABAL est un langage interprété, le code source est traduit en T-code par un traducteur (Atr) et un éditeur de liens (ald) sous forme d'un fichier informatique .at qui n'est pas exécutable directement.
Les programmes ABAL sont exécutables grâce à un exécuteur spécifique à chaque système d'exploitation (Windows, Twinserver, Useit, Unix/SCO).
Il existe différents type d'exécuteurs : 16Bits et 32Bits pour répondre aux spécificités des différents systèmes d'exploitation et des besoins applicatifs.
L'exécuteur s'appuie sur des BDA (bibliothèques dynamiques) pour ajouter des fonctionnalités :
L'exécuteur s'appuie aussi sur des bibliothèques systèmes spécifiques à chaque système d'exploitation (DLL sous Windows, .so sous Useit, .xp sous Twinserver).
Le langage ABAL est une amélioration de BAL (Business Application Language). ABAL a évolué depuis de nombreuses années : ABAL, ABAL2 et maintenant ABAL3. ABAL se compose d'un éditeur de texte, d'un éditeur de lien, d'un traducteur et d'un débuggeur.
Il existe un intégré de développement qui regroupe l'éditeur, l'éditeur de lien, le traducteur et le débuggeur.
Un nouvel intégré nommé SING s'appuie sur la BDA VISUAL. Il permet de définir des formulaires (écran de saisie ou d'édition) et crée automatiquement le code ABAL3 et VISUAL correspondant au formulaire de saisie ou d'impression (… à développer…) et qui permet, coupler à la BDA BDANET de réaliser un serveur HTTP qui répond aux requêtes en produisant des pages HTML.
La société Prologue :

</doc>
<doc id="4686629" url="http://fr.wikipedia.org/wiki?curid=4686629" title="TRAC (langage de programmation)">
TRAC (langage de programmation)

TRAC (en anglais « "Text Reckoning And Compiling" ») est un langage de programmation conçu au début des années 60 par Calvin Mooers. 
L. Peter Deutsch implémente TRAC sur machines PDP-1 en 1964 après avoir été recruté par Mooers au sein de la société Bolt, Beranek and Newman pour l'aider dans ses développements.

</doc>
<doc id="4689676" url="http://fr.wikipedia.org/wiki?curid=4689676" title="BLISS (langage de programmation)">
BLISS (langage de programmation)

BLISS est un langage de bas niveau développé dans les années 1970 à l'université Carnegie-Mellon par William Wul, D. B. Russell et Nico Habermann. Très populaire jusqu'à l'avènement du C, certains hackers des Laboratoires Bell le comparaient encore avec ce dernier pour certains de leurs projets.
Exemple de code.
Cet exemple est un extrait du manuel "Bliss Language Manual":
codice_1

</doc>
<doc id="1774184" url="http://fr.wikipedia.org/wiki?curid=1774184" title="GNU Data Language">
GNU Data Language

GNU Data Language est un clone libre d'Interactive Data Language (IDL) sous licence GNU GPL. IDL est un langage vectoriel de traitement de données et de visualisation très répandu dans l'industrie et la recherche, en particulier en astronomie, géophysique, télédétection et médecine.
GNU Data Language est en cours de développement depuis 2004 ; à ce jour, il respecte la syntaxe d'IDL version 7.1, ainsi qu'une partie des fonctionnalités de la version 8.0. Il met en œuvre la plupart des procédures et fonctions intrinsèques et un certain nombre des programmes de la bibliothèque fournie à côté du code compilé.
Sous réserve de bien préparer le code en syntaxe IDL, GDL permet de faire tourner de larges codes utilisant certaines librairies tierces
comme l'AstroLib.

</doc>
<doc id="4707911" url="http://fr.wikipedia.org/wiki?curid=4707911" title="GNU Awk">
GNU Awk

GNU Awk (ou "gawk") est l'implémentation du langage de programmation awk par le projet GNU. C'est un logiciel libre distribué sous licence GNU GPL.
GNU Awk est l'implémentation awk par défaut des distributions GNU/Linux actuelles.
GNU Awk est aujourd'hui maintenu par Aharon Robbins, un hacker travaillant pour Intel.
Histoire de awk et gawk.
Le nom "awk" provient des initiales des concepteurs du langage: Alfred V. Aho, Peter J. Weinberger et Brian W. Kernighan. La version originelle d’awk a été écrite en 1977 dans les laboratoires Bell d'AT&T. En 1985, plusieurs nouveautés sont introduites dans une nouvelle version, parmi lesquelles, les . Cette nouvelle version est largement distribuée par les systèmes SVR3. La version pour SVR4 ajoute d'autres nouveautés et, selon la documentation GNU, est l'occasion de nettoyer le comportement du langage, très peu ou pas du tout documenté. Les spécifications du standard POSIX adopté vont clarifier le langage. Les concepteurs de gawk, comme leurs prédécesseurs des laboratoires Bell pour la conception d’awk, fournissent leur retour d'expérience pour la spécification POSIX.
Paul Rubin écrit gawk, l'implémentation du langage par le projet GNU, en 1986. Jay Fenlason l'a complété selon les conseils de Richard Stallman. Un certain John Woods a également contribué à certaines parties du code. En 1988 et 1989, David Trueman refaçonna soigneusement gawk avec l'aide d'Arnold Robbins pour le rendre compatible avec la nouvelle version d’awk. Selon Arnold Robbins, qui travaille sur le projet depuis 1988 et est l’actuel mainteneur depuis 1994, David Trueman mérite une mention spéciale pour son travail inestimable sur l'évolution de gawk, de sorte qu'il fonctionne bien et sans bugs. Bien qu'il ne participe plus à gawk, travailler avec Trueman a été pour Robbins un plaisir considérable.
Depuis 1995, Arnold Robbins est le principal mainteneur du projet.

</doc>
<doc id="725938" url="http://fr.wikipedia.org/wiki?curid=725938" title="IDL (langage)">
IDL (langage)

IDL, acronyme d'"Interactive Data Language", est un langage de programmation propriétaire apparu à la fin des années 1970,
et qui est rapidement monté en puissance dans les domaines de la télédétection et de l'astronomie. IDL est un langage vectoriel de traitement de données et de visualisation très répandu dans l'industrie et dans la recherche.
Un langage propriétaire innovant.
IDL est un langage qui, au début des années 1990, présentait de nombreuses
avancées par rapport à d'autres langages (Fortran, C et Pascal) utilisés dans
certains laboratoires où la programmation était non pas un sujet de recherche
en soi mais un outil pour traiter des observations. Il offre,
à une époque où Fortran 90 n'était pas vraiment encore disponible, et C++
pas vraiment défini, une gestion objet des quantités (nombre, vecteur, tableau)
sans écrire de boucle, un affichage de traces (1D, 2D, 3D) à l'écran sans faire appel à des bibliothèques
graphiques alors limitées (pgplot) ou complexes (X11 Motif).
Quoiqu'interprété, un usage raisonnable (déjà en proscrivant les boucles explicites)
dans un contexte adéquat (opération globale sur des vecteurs ou des matrices)
ne donnait pas de différence notable en temps de calcul par rapport à du Fortran.
Les arguments majeurs en faveur d'IDL sont :
Les inconvénients :
Comparaison avec des langages semblables.
Des comparaisons sont aussi parfois faites avec matlab et octave.
Une alternative libre.
Depuis 2004, GNU Data Language, un clone libre d'IDL sous licence GNU/GPL, est en cours de développement.

</doc>
<doc id="4762587" url="http://fr.wikipedia.org/wiki?curid=4762587" title="Ooc (langage)">
Ooc (langage)

ooc est un langage de programmation compilé. Il permet d'allier la programmation orienté objet avec la programmation fonctionnelle avec une syntaxe simple qui favorise la lisibilité et la concision des programmes. L'implémentation principale traduit le code ooc en sources C puis utilise un compilateur C pour produire un exécutable.
Le langage ooc et la plupart de son écosystème sont placés sous la licence BSD. Il est conçu pour combiner une syntaxe simple avec la performance d'un langage compilé, tout en restant flexible. Il est développé par des individus dans leur temps libre. Sa bibliothèque standard est multiplateforme (Linux, Mac OS X, et Windows sont notamment supportés), grâce aux blocs de versions intégrés au langage.
Caractéristiques.
Syntaxe.
ooc, tout comme le Python, a été conçu pour être lisible, et pour être facilement écrit par un humain dans un simple éditeur de texte. Les blocs sont délimités par des accolades, comme en C.
Le principe DRY est au cœur de la syntaxe ooc. Par exemple, l'opérateur ":=" permet de déclarer une variable à partir de l'expression à droite, en inférant son type:
Types de bases.
ooc possède les mêmes types de bases que le langage C, toutefois, tous les types commencent par une majuscule, par convention.
La bibliothèque standard offre également de nombreuses structures de données telles que les tableaux-listes, les listes chaînées, les tables de hachages, les piles, etc. Les tableaux sont inclus dans le langage et, contrairement aux pointeurs C, sont sûrs (on ne peut y accéder en-dehors de leurs bornes).
On peut créer des types en définissant une classe, une interface, ou en faisant une cover d'un type défini en C.
Programmation objet.
Héritage simple.
Le modèle orienté objet d'ooc supporte l'héritage simple.
Interfaces.
Les interfaces permettent un semblant d'héritage multiple, à l'instar du Java.
Programmation fonctionnelle.
ooc supporte les fonctions anonymes et les fermetures. On peut manipuler les fonctions comme n'importe quelle valeur, grâce à une syntaxe claire et lisible :
Cet exemple utilise également des types génériques, montre une manière simple de créer des tableaux-listes (ArrayList), de parcourir des objets itérables, de retourner implicitement des objets, ainsi que la syntaxe courte pour les fonctions anonymes.
Modularité.
Chaque fichier .ooc correspond à un module qui peut être importé depuis n'importe où. Les modules peuvent être organisés en paquetages (les dossiers où ils sont placés). Il est possible d'importer un module dans un espaces de noms donné, par exemple
Contrairement au C il n'y a pas de fichiers d'en-tête séparés des fichiers sources. import, plutôt que de copier/coller le contenu du fichier, définit une dépendance entre deux modules.
Le compilateur ayant ainsi une vue claire des dépendances entre modules, il supporte la recompilation partielle sans besoin de fichiers de projets du type Makefile.
Les fichiers .use permettent également de spécifier des dépendances sur des bibliothèques externes, des options à passer au compilateur C, des informations de versions, etc. La directive use permet d'en faire usage dans du code ooc. Ainsi, utiliser par exemple la SDL, OpenGL est l'affaire d'une ligne de code source.
Exemples de code.
Le hello world classique :
Afficher le contenu d'un fichier :
Afficher les 5 premières puissances de 2
Implémentations.
L'implémentation principale d'ooc est rock, entièrement écrit en ooc et qui se compile lui-même. Il a été développé en quelques mois et a rendu obsolète j/ooc, l'implémentation initiale en Java qui a permis au langage de bootstrapper en 
Il existe également un effort pour implémenter un compilateur ooc écrit en Ruby, nommé rooc.
Liens externes.
Site officiel

</doc>
<doc id="263868" url="http://fr.wikipedia.org/wiki?curid=263868" title="Langage K">
Langage K

Le langage K est un langage d'abstraction des concepts de l'informatique, un langage de formalisation des structures de données et un langage d'approche mathématique et théorique de la programmation.
Présentation.
Langage d'enseignement, il permet d'aller au-delà des distinctions de tout type (langage de programmation, déclaration de type, mots-clés par sa syntaxe extrêmement pauvre).
Ce langage étant à vocation pédagogique, il n'existe pas de notation stricte de langage.
Néanmoins, une norme a été définie à l'adresse libe4.free.fr.
Ce langage ne permet d'effectuer que des modifications sur des nombres, des listes ou des tableaux, son intérêt est de voir la trace des algorithmes écrits.
Un programme K se divise par fonctions définies récursivement. Elles sont constituées de cas, autrement dit des conditions suivies d'un rendu de résultat.
Exemple.
Déterminer la valeur maximum d'un tableau :
Interpréteurs.
Plusieurs interpréteurs existent :

</doc>
<doc id="4733204" url="http://fr.wikipedia.org/wiki?curid=4733204" title="Hollywood (langage de programmation)">
Hollywood (langage de programmation)

Hollywood est un langage de programmation commercial développé par Andreas Falkenhahn (Airsoft Softwair) qui se concentre sur la création d'applications orientées multimédia. Hollywood est disponible pour AmigaOS (68k), AmigaOS 4 (PPC), MorphOS, WarpOS, AROS et Windows. Il n'y a pas de version pour Mac OS X pour l'instant mais le logiciel peut compiler des exécutables pour cette plateforme.
Hollywood possède un compilateur croisé (en anglais "Cross Compiler") intégré qui peut enregistrer automatiquement des exécutables pour toutes les plateformes supportées par le logiciel. Les exécutables générés fonctionnent de façon indépendante du système et sans aucune dépendance externe. Ils peuvent donc être utilisées directement depuis une clé USB.
Le logiciel Hollywood Designer est un module supplémentaire pour Hollywood avec lequel il est possible d'utiliser Hollywood comme un logiciel de présentation.
Historique.
Hollywood a débuté sur ordinateur Amiga. Il est inspiré par des langages de programmation sur Amiga tels que AMOS, Blitz Basic, et Amiga E. L'auteur d'Hollywood Andreas Falkenhahn a commencé le développement de Hollywood au printemps 2002. La version 1.0 du logiciel est sortie en novembre 2002, mais seulement pour les systèmes Amiga basés sur 68000. Un mois plus tard, une version native pour le système MorphOS a suivi. Le support de WarpOS a été ajouté à partir de Hollywood qui est sorti au printemps 2004 en même temps que la première version de Hollywood Designer qui permet la création de présentations avec Hollywood. AmigaOS 4 est supporté depuis mars 2005. À partir de la version 2.0 (sortie en janvier 2006), Hollywood utilise le langage de programmation Lua en tant que sa machine virtuelle, mais avec plusieurs modifications dans sa syntaxe et ses fonctionnalités. À partir de la version 3.0 (janvier 2008), Hollywood fonctionne sur deux systèmes d'exploitation non typés Amiga : Windows et Mac OS X. Depuis la version 4.5 (janvier 2010) Hollywood est disponible avec un environnement de développement intégré sur Windows.
La version 4.7 sortie en avril 2010 est encore plus indépendante de la plateforme sur laquelle l'application tourne.
Introduction.
Le but principal de Hollywood est la simplicité d'utilisation et aucune dépendance de la plateforme. Il a été développé principalement pour la création d'applications multimédia et de jeux. Le langage comprend environ 500 commandes dans les champs d'application : graphisme 2D, son, accès au système de fichiers, affichage de texte, animations, affichage de sprites, layers, effets de transition, manipulation d'images, enregistrement d'images et de fichiers vidéo, ... La programmation en Hollywood se fait via des scripts Hollywood (extension *.hws). Ces scripts sont compilés dynamiquement et peuvent être convertis en exécutables autonomes. Tous les programmes Hollywood fonctionnent dans une Sandbox qui permet de ne jamais planter le système.
Indépendance à la plateforme.
Hollywood a été conçu comme un langage de programmation totalement indépendant de la plateforme. De ce fait, les scripts ne peuvent pas appeler directement une fonction de l'API du système d'exploitation hôte et ils sont limités à la liste des commandes du langage. Même le rendu de texte est implémenté à travers un système de rendu de police complètement indépendant du système hôte. Cela permet à du texte en TrueType d'être visuellement identique sur toutes les plateformes. De plus, toutes les versions de Hollywood gèrent les formats de fichier spécifiques Amiga comme les images IFF ILBM, les sons IFF 8SVX, ou les fichiers IFF ANIM pour être entièrement compatibles avec les scripts écrits sur système Amiga.
Compilateur.
Une fonction intéressante du compilateur croisé (en anglais "Cross Compiler") livré avec Hollywood est la possibilité d'inclure tous les fichiers externes (dont les polices) dans l'exécutable généré. Il est alors possible de créer des programmes qui auront la forme d'un unique fichier exécutable, qui sera ainsi facilement transportable et distribué. De plus le compilateur de Hollywood peut compiler des scripts sous forme d'applets Hollywood (avec un extension de fichier *.hwa). Ces applets sont plus petits que des programmes Hollywood correspondants mais peuvent être utilisés uniquement sur des systèmes où Hollywood est installé.
Il est aussi possible d'exporter des scripts Hollywood en fichier AVI.
Environnements de développement.
Il n'y a pas d'environnement de développement intégré pour la version AmigaOS de Hollywood. Sur ces systèmes, il est possible d'utiliser un IDE tel que Cubic IDE ou Codebench qui permettent le développement en Hollywood grâce à des plugins. Sur Windows, Hollywood est disponible avec son propre IDE.
Un programme Hello World.
Un programme Hello World en Hollywood s'écrit comme ceci :
Ce code source ouvre une nouvelle fenêtre sur le bureau, affiche le texte "Hello World!" et attend qu'on presse le bouton gauche de la souris avant de quitter. L'ouverture de la fenêtre est faite automatiquement par Hollywood.
Hollywood Designer.
L'application Hollywood Designer est un logiciel supplémentaire qui permet la création de présentations informatives ou des applications interactives avec Hollywood. Ce logiciel utilise une interface WYSIWYG basée sur le principe des pages. Il est possible de créer autant de pages que désiré en utilisant du texte, des images ou des sons. Hollywood Designer pourra afficher les pages dans l'ordre séquentiel ou un ordre différent. Plusieurs effets de transition sont disponibles. Il est aussi possible de créer des applications qui nécessitent une interaction avec l'utilisateur comme pour des bornes interactives.
Tous les projets créés avec Hollywood Designer peuvent être visualisés avec Hollywood et peuvent donc être compilés en exécutables indépendants ou en fichier AVI. Les utilisateurs avancés peuvent aussi importer leur propre code dans un projet. Au travers de tels ajouts de code, il est possible d'accéder à toutes les commandes de Hollywood.
Techniquement parlant, Hollywood Designer ne fait que donner à Hollywood des scripts construits à partir des actions de l'utilisateur dans l'interface graphique GUI. Ce processus de générer des scripts et de les exécuter par Hollywood est entièrement transparent pour l'utilisateur. Ce qui fait qu'aucune connaissance de la programmation n'est nécessaire pour utiliser Hollywood Designer.

</doc>
<doc id="354698" url="http://fr.wikipedia.org/wiki?curid=354698" title="CEI 61131-3">
CEI 61131-3

La CEI 61131-3, intitulée Automates programmables - Partie 3 : Langages de programmation, est une norme industrielle de la Commission électrotechnique internationale (CEI) définissant cinq langages de programmation à utiliser pour les automates programmables :
Elle a été publiée la première fois en 1993, et une seconde édition a vu le jour en 2003.

</doc>
<doc id="4818370" url="http://fr.wikipedia.org/wiki?curid=4818370" title="Suneido">
Suneido

Suneido est un langage de programmation interprété et interactif pour Windows de Microsoft . 
Il a un typage dynamique et gère la mémoire automatiquement à l'aide d'un ramasse-miettes ; il est ainsi semblable à Python, TCL, Perl, Scheme et Ruby. Suneido est un logiciel libre (Open Source Software) et gratuit. Suneido est une plateforme d’application qui comprend un langage de programmation orientée objet, une base de données relationnelle intégrée client-serveur, et un environnement de développement intégré (EDI).
Exemple Hello World.
Le programme Hello world s'écrit en Suneido:
codice_1

</doc>
<doc id="4849284" url="http://fr.wikipedia.org/wiki?curid=4849284" title="Noop">
Noop

Noop est un nouveau projet de Google dans le but de développer un nouveau langage de programmation. Noop doit fonctionner sur la machine virtuelle Java.
Exemple.
"Hello world" en Noop :

</doc>
<doc id="4902214" url="http://fr.wikipedia.org/wiki?curid=4902214" title="Pastel (langage de programmation)">
Pastel (langage de programmation)

Pastel est un dialecte du langage de programmation Pascal et un compilateur développé au laboratoire national de Lawrence Livermore.
Pastel et le projet GNU.
Le compilateur GCC fut initialement écrit avec le langage de programmation Pastel avant d'être entièrement réécrit en C.

</doc>
<doc id="4925172" url="http://fr.wikipedia.org/wiki?curid=4925172" title="SRFI (informatique)">
SRFI (informatique)

SRFI (en anglais « Scheme Requests for Implementation ») est un processus de standardisation des librairies et extensions du langage de programmation Scheme, dans le but de faciliter l'implémentation du langage.
"SRFI" s'est imposé en raison du manque de normes précises pour développer des bibliothèques Scheme avant l'avènement du standard Scheme R6RS.
Le "standard R6RS" couvre désormais ce champ d'application.

</doc>
<doc id="4933441" url="http://fr.wikipedia.org/wiki?curid=4933441" title="SAM76">
SAM76

SAM76 est un langage de programmation développé à la fin des années 70.
Juridique.
Les auteurs seront poursuivis par Calvin Mooers pour violation de brevets logiciels, mais l'affaire sera classée sans suite.

</doc>
<doc id="4939372" url="http://fr.wikipedia.org/wiki?curid=4939372" title="GNU Pascal">
GNU Pascal

GNU Pascal est l'implémentation du langage de programmation Pascal par le projet GNU. C'est un logiciel libre distribué sous licence GNU GPL.
Il comprend un compilateur connu sous l'appellation GPC (en anglais « "GNU Pascal Compiler" »), compatible avec plusieurs dialectes du langage Pascal, et utilisant GCC comme "back-end" jusqu'à la version 3.4.

</doc>
<doc id="4571372" url="http://fr.wikipedia.org/wiki?curid=4571372" title="NumPy">
NumPy

NumPy est une extension du langage de programmation Python, destinée à
manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions mathématiques opérant sur ces tableaux.
Une bibliothèque très puissante, permettant de manipuler les tableaux, de multiples fonctions permettant notamment de créer directement un tableau depuis un fichier ou au contraire de sauvegarder un tableau dans un fichier.
Permet la manipulations des vecteurs, matrices et polynômes.
Utilisé de concert avec Matplotlib (gestion des graphiques) devient un outil scientifique parfait pour python.

</doc>
<doc id="4746721" url="http://fr.wikipedia.org/wiki?curid=4746721" title="NodeBox">
NodeBox

Nodebox est un langage de programmation open source pour la création graphique statique ou animée, basé sur l'emploi de Python. Créé par Frederik De Bleser et Tom De Smedt dans le cadre de l'Experimental Media Group de l'école d'art Saint-Luc d'Anvers.
Nodebox est écrit en Python et fonctionne sur Mac OS X depuis la première version bêta. Une version plus récente fonctionne sous Windows et peut également être portée sur Linux. Nodebox peut générer des formes vectorielles : courbes de Bézier, polygones (rectangles, étoiles…), ellipses et ovales. Il sait lire plusieurs formats d'image et enregistrer au format PDF ou films QuickTime et dispose dès à présent de plusieurs bibliothèques qui étendent ses fonctionnalités. Le projet trouve son origine dans l'idée d'offrir un environnement d'apprentissage aux débutants en programmation, en particulier les graphistes et designers. En cela il s'inscrit dans la continuité de projets comme "Design by Numbers" (dbn) et Processing.

</doc>
<doc id="4949180" url="http://fr.wikipedia.org/wiki?curid=4949180" title="KTurtle">
KTurtle

KTurtle est un environnement de programmation éducatif utilisant le dessin vectoriel. Il est sous Licence publique générale GNU (GPL) et fait partie de l'environnement de travail KDE. KTurtle comporte un langage de programmation basé sur le Logo. Il s'agit d'un des rares langages de programmation traduisible ; les instructions d'un programme peuvent être traduites dans la langue du développeur.
KTurtle est disponible en paquet pour la plupart des distributions de Linux/BSD, dont Red Hat Linux, Suse, Kubuntu, Mandrake, i Debian. KTurtle est disponible pour Windows comme paquet de Kdeedu de la distribution KDE 4 pour Windows.

</doc>
<doc id="5027765" url="http://fr.wikipedia.org/wiki?curid=5027765" title="PILOT">
PILOT

PILOT (acronyme de "Programmed Instruction, Learning, Or Teaching") est un langage de programmation précurseur de l'apprentissage en ligne ("E-learning").

</doc>
<doc id="5105774" url="http://fr.wikipedia.org/wiki?curid=5105774" title="Gibiane">
Gibiane

Gibiane est un langage de programmation basé sur Fortran développé par le Commissariat à l’énergie atomique (CEA). Ce langage est la base des codes de calcul neutronique déterministes APOLLO2 et CRONOS2.

</doc>
<doc id="2127408" url="http://fr.wikipedia.org/wiki?curid=2127408" title="JAL (compiler)">
JAL (compiler)

JAL (Just Another Language) est un langage de programmation semblable au Pascal et possède un compilateur qui génère le code exécutable pour les microcontrôleurs PIC. C'est un langage au format libre pour programmer les microcontrôleurs PIC et le compilateur fonctionne sous Linux, Mac OS X, et MS-Windows. JAL est le seul langage de ce type libre de droits et a des utilisateurs actifs dans différents pays. C'est un langage configurable qui peut être enrichi par des bibliothèques et peut être combiné avec de l'assembleur.
Historique.
Créé par Wouter van Ooijen, il a été publié comme logiciel libre de droits (Licence publique générale GNU) en 2003. En 2006, Stef Mientki entreprit le développement d'une nouvelle version : JAL V2. Kyle York est le programmeur de cette nouvelle version. Un groupe international d'utilisateurs constitua l'équipe du bêta test (par ordre alphabétique : Bert van Dam, Sunish Issac, Dave Lagzdin, Javier Martinez, Stef Mientki, Wouter van Ooijen, Michael Reynolds, André Steenveld, Joep Suijs, Vasile Surducan, and Michael Watterson).

</doc>
<doc id="274075" url="http://fr.wikipedia.org/wiki?curid=274075" title="Jasmin (langage)">
Jasmin (langage)

Jasmin est un langage d'assemblage d'instructions de la machine virtuelle Java, ou de façon plus concise, un assembleur de Bytecode Java.
Jasmin a été créé par Jon Meyer et Troy Downing pour accompagner leur ouvrage "JAVA Virtual Machine". 
Cet ouvrage est aussi connu sous le nom informel du "livre au bocal à poisson rouge" (en anglais "goldfish bowl book") - en référence au classique sur la compilation, le "livre au dragon rouge" (en anglais "Red Dragon Book") de Alfred V. Aho "et al."
Le nom de "Jasmin" fait quant à lui référence au thé au jasmin, clin d'œil au jeu de mot sur le sens argotique de Java : café.

</doc>
<doc id="4921634" url="http://fr.wikipedia.org/wiki?curid=4921634" title="ΛProlog">
ΛProlog

λProlog ou lambda prolog est un langage de programmation logique dérivé de prolog. λProlog est une double extension de prolog, dans un premier temps, en rajoutant les λtermes et dans un second temps avec l'ajout de nouveaux connecteurs tels que l'implication et le quantificateur universel.
Il est à noter que lambda prolog introduit egalement la notion de type simple.

</doc>
<doc id="632021" url="http://fr.wikipedia.org/wiki?curid=632021" title="Mel (langage)">
Mel (langage)

Mel, MEL ou "Maya Embeded Language" (langage incorporé de Maya) est le langage de programmation du logiciel 3D Maya. Il s'agit d'un langage interprété. Maya est caractérisé par sa possibilité d'être entièrement exploitable via des lignes de codes sachant qu'une grande partie du logiciel (dont son interface) est programmée en Mel, le reste en C++. On peut utiliser le Mel dans plusieurs environnements, par exemple, il est possible d'écrire des expressions qui agiront à chaque nouvelle image dans le temps ou d'associer un Mel à une collision. De façon générale, il permet d'avoir accès à la création d'interfaces (création de fenêtres, de boutons...) et à toutes les fonctions du logiciel, et c'est pour cette raison qu'il est un outil indispensable pour les utilisateurs de Maya.
Syntaxe et concepts.
La syntaxe du Mel se caractérise entre autres par l'utilisation du signe codice_1 au début de chaque variables comme en PHP. Elle découle de la syntaxe du UNIX shell scripting : une commande en Mel est suivie de codice_2, c’est-à-dire de données auxquelles on attribue une valeur. Parmi ces codice_2 on a souvent codice_4, pour appeler une valeur d'une donnée, ou codice_5, pour éditer une valeur d'une donnée. Par exemple :
Cette commande crée un cube polygonal, ou plutôt un prisme droit, Cube de hauteur 1.0, de largeur 2.0 et de profondeur 3.0.
Celle-ci modifie la hauteur du cube appelé pCube1, il n'y a pas de $ devant pCube1 car il ne s'agit pas d'une variable mais du nom de l'objet.
Le Mel ne respecte que le concept de programmation procédurale, sachant que le terme de procédure (le mot clé est codice_8) est employé à tort dans ce langage puisqu'il est possible de renvoyer une valeur, ce qui en principe ne l'est pas avec une procédure mais avec une fonction. Existe également la possibilité d'utiliser les fonctions Mel dans un environnement Python pour étendre les possibilité de ce langage au paradigme de programmation orientée objet et de programmation modulaire. Mel propose toutes les structures de contrôle les plus utilisées comme les conditions (codice_9 et codice_10), les boucles (codice_11, codice_12) et les branchements (codice_13).

</doc>
<doc id="274082" url="http://fr.wikipedia.org/wiki?curid=274082" title="Oolong (langage)">
Oolong (langage)

Oolong est un langage d'assemblage d'instructions de la machine virtuelle Java, ou de façon plus concise, un assembleur de Bytecode Java, créé par Joshua Engel.
Le nom d'"Oolong" fait référence au thé Oolong, clin d'œil au jeu de mots sur le sens argotique de Java : café.

</doc>
<doc id="356786" url="http://fr.wikipedia.org/wiki?curid=356786" title="4e Dimension (langage)">
4e Dimension (langage)

Historique.
Le logiciel 4D a été créé par Laurent Ribardière en 1984 et est l'un des premiers (sinon le premier) systèmes de base de données à voir le jour sur la plateforme Apple Macintosh. Cette particularité lui a d'ailleurs longtemps "collé à la peau", mais en 1995 4D devient multi-plateforme et fonctionne également sous Microsoft Windows.
Logiciel 4D.
4D est un Système de Gestion de Base de Données Relationnelle (SGBDR) disposant d'un langage de programmation de la quatrième génération (L4G).
Environnement de développement intégré (EDI ou IDE en anglais), 4D intègre un compilateur, un déboggeur, un système complet et automatisé de sauvegarde et de réplication, un serveur Web, un serveur et client de services web, un moteur d'exécution mono-poste et client-serveur multiplate-forme.
En 2009, 4D s'est vu enrichi de la suite 4D Web 2.0 Pack, intégrant le plugin 4D Live Window et le composant 4D Ajax Framework.
4D comporte de nombreux plug-ins :
Le logiciel 4D possédait traditionnellement 3 modes :
Depuis la version "4D v11 SQL", les modes Structure et Utilisation ont fusionné en un seul mode Développement. Le mode Menus Créés est devenu le mode Application.
4D en quelques notions.
Depuis "4D v11 SQL" :

</doc>
<doc id="983665" url="http://fr.wikipedia.org/wiki?curid=983665" title="Profil Ravenscar">
Profil Ravenscar

Le profil Ravenscar est un sous-ensemble du langage Ada dédié aux systèmes temps réel nécessitant une grande sûreté de fonctionnement. 
Il ne restreint que les fonctionnalités liées au parallélisme.
L'idée est de permettre de prouver formellement les propriétés temps-réel des programmes écrits selon ce profil. Le profil Ravenscar, en interdisant un certain nombre de caractéristiques du langage Ada, permet de rendre applicables les outils de preuve de programme.
Les restrictions apportées permettent également de réaliser des exécutifs plus simples, et donc eux-mêmes certifiables. 
Ce profil a aussi été appliqué à la spécification temps réel RTSJ du langage Java.
Restrictions apportées par le profil.
Le profil Ravenscar est maintenant intégré à la norme Ada (2005). Il suffit d'appliquer la directive de compilation suivante:
Ce profil est équivalent à l'ensemble de pragmas de configuration suivants:

</doc>
<doc id="5234325" url="http://fr.wikipedia.org/wiki?curid=5234325" title="OptimJ">
OptimJ

OptimJ est un langage de modélisation mathématique orientée-objet destiné à faciliter l'intégration de modèles d'optimisation avec le monde Java.
OptimJ est conçu sous la forme d'une extension au langage Java avec support sous Eclipse. OptimJ possède toutes les fonctionnalités des langages de modélisation actuels et peut supporter tout moteur d'optimisation. OptimJ est disponible gratuitement avec les moteurs open source lp_solve et GLPK
Les modèles OptimJ travaillent directement sur les données de l'application, sans création d'objets intermédiaires. Ils peuvent être déployés directement sous forme compilée sur toutes les plateformes pour lesquelles un Java Runtime Environment est disponible.

</doc>
<doc id="4605251" url="http://fr.wikipedia.org/wiki?curid=4605251" title="Pharo">
Pharo

Pharo est un langage de programmation dynamique, épuré et sous licence MIT, créé en 2009.
Introduction.
Pharo est un langage de programmation largement inspiré de Smalltalk. Il est basé sur une machine virtuelle, écrite en large partie en Pharo lui-même, ce qui lui permet d'être multiplateforme (Mac OS X, Windows, Linux, iOS, Android). 
La politique de Pharo oblige ses contributeurs à accepter de publier leur code sous licence MIT.
Pharo possède les principales caractéristiques de Smalltalk : 
Tout est objet, au sens de la programmation orientée objet,
Le système est réflexif : un programme peut modifier sa structure et son comportement lors de l’exécution,
Le typage est un typage dynamique : contrairement à certains langages à typage statique, qui forcent le développeur à indiquer de quel type est chaque variable (entier, chaîne de caractères…), les variables peuvent prendre n'importe quelle valeur,
L'héritage est simple,
La gestion de la mémoire est automatique : Pharo utilise un ramasse-miettes ("garbage collector"), comme d'autres langages comme Lisp ou Java. 
La syntaxe de Smalltalk est minimaliste : elle tient sur une carte postale.
Un des intérêts principaux de Pharo est qu'il n'est pas nécessaire de recompiler tout le code pour dans le cas de la modification d'une méthode. Il est par exemple tout à fait possible de modifier ou de créer une méthode au sein du debugger et de reprendre le flot d'exécution juste avant la modification. Certains appellent cela la méthode 'edit and continue' an lieu de la traditionnelle méthode 'edit compile and run'.
Communauté.
La communauté de Pharo est assez vaste : 600 personnes sur la Pharo mailing list, téléchargements de la version one-click depuis sa création.
Tous les 6 mois, de nombreux membres de la communauté se retrouvent durant une journée pour améliorer Pharo au cours d'un sprint.
Chaque année une conférence Pharo a lieu. Les utilisateurs de Pharo se réunissent au cours de cette conférence pour partager à la fois leurs projets de recherche et professionnels. En 2010, elle s'est déroulée à Annecy (France). En 2011 et 2012, elle a eu lieu à Lille en France. Enfin, en 2013, la conférence Pharo s'est déroulée à Berne en Suisse.
Régulièrement, des vidéos de programmation avec Pharo sont postés sur PharoCast ou sur la chaine youtube de Pharo.
Plus d'une vingtaine d'entreprises utilisent aujourd'hui Pharo pour leurs développements logiciels.
Les principales applications développées sont d'une part liés au développement d'application web (en utilisant par exemple le framework Seaside_(framework)) et d'autres
part à l'analyse et à la visualisation de système logiciel (en utilisant le framework MOOSE).
La communauté Pharo s'organise autour d'un consortium rassemblant des industriels, des partenaires académiques utilisant la plateforme.
Pharo dispose également d'une association à but non lucratif.
Historique.
Pharo est un fork de Squeak, un Smalltalk open-source développé par des membres de l'équipe originelle de Smalltalk-80 (Dan Ingals et Alan Kay). 
Se démarquant de l'aspect plus ludique de Squeak, les concepteurs de Pharo (chercheurs à l'INRIA) souhaitent développer un Smalltalk moderne tourné vers les besoins des entreprises et de la recherche en génie logiciel. Pharo est devenu l'implémentation de référence de Seaside, framework web pour développer des applications web en Smalltalk. Aujourd'hui, Pharo est soutenu par un consortium regroupant les utilisateurs industriels et une association pour les particuliers.
Fork en 2008.
La version 1.0 de Pharo est sortie le 15 avril 2010. 
La version 1.1 de Pharo est sortie le 26 juillet 2010.
La version 1.2 de Pharo est sortie le 29 mars 2011.
La version 1.3 de Pharo est sortie en août 2011.
La version 1.4 de Pharo est sortie en avril 2012.
La dernière version de Pharo, Pharo 2.0 est sortie le 18 mars 2013.
Le planning actuel prévoit une nouvelle version par an : Pharo 3.0 est donc prévu pour mars 2014. De plus, des versions de stabilisation (Pharo 2.1, 2.2) sont prévues tous les 4 mois.
Enseignement et Recherche.
Enseignement.
Avec sa communauté active, sa licence MIT, son noyau stable et son fonctionnement multiplateforme, Pharo est un environnement idéal pour apprendre le langage Smalltalk. 
Un livre en français, "Pharo par l'exemple", est disponible en ligne. Il est gratuit et permet d'apprendre les bases de Pharo. Un second volume est en préparation. Il est dors et déjà possible d'accéder à certains chapitres de la version anglaise sur ce site : http://rmod.lille.inria.fr/pbe2/.
Pharo est de plus en plus utilisé dans le cadre de l'enseignement. Smalltalk est enseigné sous la forme de Pharo notamment à : 
Recherche.
De nombreuses équipes de recherche travaillent avec Pharo, notamment les équipes :
La Pharo association a été récemment créée et regroupe tous les indépendants souhaitant soutenir le projet.
Performance et machine virtuelle.
Pharo est basé sur une machine virtuelle écrite en large partie en Smalltalk elle-même. Depuis 2008, une nouvelle machine virtuelle avec un niveau de performance comparable aux dialectes Smalltalk les plus rapides est disponible. Cette machine virtuelle performante fonctionne sur Mac OS X, Windows et Linux. Une version simplifiée et un peu moins rapide fonctionne sur iOS et Android.

</doc>
<doc id="5469256" url="http://fr.wikipedia.org/wiki?curid=5469256" title="UCBLogo">
UCBLogo

UCBLogo (appelé aussi "Berkeley Logo") est une implémentation libre du langage de programmation Logo concue par Brian Harvey et ses étudiants au sein de l'université de Californie à Berkeley.
Comme beaucoup d'autres implémentations, UCBLogo fournit un interpréteur Logo avec l'appel de récursion finale.
Écrit en C, "Berkeley Logo" est un logiciel libre distribué selon les termes de la licence publique générale GNU et disponible sur plusieurs systèmes libres comme GNU/Linux ou FreeBSD.

</doc>
<doc id="5231460" url="http://fr.wikipedia.org/wiki?curid=5231460" title="Next Byte Codes">
Next Byte Codes

__NOTOC__
Le ou NBC est un langage assembleur pouvant être utilisé pour programmer le Lego Mindstorms NXT, la brique programmable de Lego, développé par John Hansen, un membre du "".
Le compilateur NBC est disponible sous pour Windows, Mac OS et Linux. Son environnement de développement intégré est BricxCC.
Un débogueur a été développé par SorosyDotCom et est disponible en téléchargement gratuit.
Exemples de programmes.
Voici deux exemples de programmes réalisables avec le NBC, suivis de l'explication de leur effet.

</doc>
<doc id="5557107" url="http://fr.wikipedia.org/wiki?curid=5557107" title="Rubinius">
Rubinius

Rubinius est une implémentation de l'interpréteur du langage de programmation Ruby, conçue par Evan Phoenix et implémentée principalement dans le langage Ruby lui-même. Basé largement sur les concepts du "Blue Book" de Smalltalk-80, Rubinius vise à fournir un "environnement de développement riche et de haute performance pour exécuter du code Ruby".
Il s'agit d'un projet libre sous licence BSD.
Objectifs.
Le projet Rubinius perpétue la tradition de Lisp et Smalltalk en tentant d'implémenter autant que possible un interpréteur Ruby en Ruby ; du C++ est actuellement employé lorsque l'utilisation de Ruby n'est pas possible.
Il vise également à être "thread-safe" afin de pouvoir embarquer plus d'un interpréteur dans une même application.
Sponsor.
La société Engine Yard (spécialisée en gestion et déploiement d'application Ruby on Rails) emploie deux ingénieurs à temps plein pour travailler exclusivement sur le développement de Rubinius.

</doc>
<doc id="5561174" url="http://fr.wikipedia.org/wiki?curid=5561174" title="Opa">
Opa

Opa est un langage de programmation d'applications et services web utilisable sous licence Affero GPL ou sous licence privée.
Philosophie.
Opa est une technologie de développement d’applications Web distribuées. C’est un nouveau langage de programmation fortement couplé à une bibliothèque Web standard qui remplit toutes les fonctions : de serveur d’applications Web, à serveur de base de données.
En un mot, Opa ne dépend pas des piles serveurs actuelles, comme par exemple Apache plus PHP plus MySQL plus Symfony. Un code source Opa est compilé en un binaire autonome du service, qui se contente d’une distribution GNU/Linux nue (même MiniLinux) pour l’exécution.
Opa est spécialement conçu pour le Web et spécifie l’ensemble des aspects de l’application :
Exemple de code.
L'exemple ci-dessous est le code complet d'un webchat minimal en Opa.

</doc>
<doc id="5574783" url="http://fr.wikipedia.org/wiki?curid=5574783" title="Averest">
Averest

Averest est un langage de programmation synchrone conçu par un groupe de l'université technique de Kaiserslautern qui permet de spécifier, vérifier et implémenter des systèmes dit réactifs.
Averest contient aussi des outils qui permettent la vérification automatique de systèmes dynamiques ainsi qu'un compilateur.

</doc>
<doc id="5620659" url="http://fr.wikipedia.org/wiki?curid=5620659" title="S (langage de programmation)">
S (langage de programmation)

S est un langage de programmation de très haut niveau et un environnement d'analyse des données et des graphiques conçus dans les années 1975-1976 par John Chambers. En 1998, l'ACM offre son prix d'excellence logicielle à John Chambers pour le « "le système S, lequel a changé à jamais la façon dont les gens analysent, visualisent et manipulent les données "».
Les deux interpréteurs modernes de S sont GNU R et S-PLUS.
Historique.
Une première version du langage est distribuée par les laboratoires Bell en 1980, et le code source disponible en 1981. Les deux ouvrages publiés en 1984 et 1985 par John Chambers et Richard Becker témoignent de la popularité du langage. Le code source est alors distribué par AT&T selon les termes d'une licence propriétaire.
Les dépôts de l'Université Carnegie-Mellon disposent d'une quantité importante de contributions de code pour S.

</doc>
<doc id="4960653" url="http://fr.wikipedia.org/wiki?curid=4960653" title="Pôle Langage de programmation de l'ACM">
Pôle Langage de programmation de l'ACM

Le Pôle Langage de programmation de l'ACM (de l'anglais SIGPLAN) est le pôle d'intérêt commun de l'ACM dans le domaine de la programmation informatique.

</doc>
<doc id="1711" url="http://fr.wikipedia.org/wiki?curid=1711" title="C (langage)">
C (langage)

Le C est un langage de programmation impératif, généraliste, issu de la programmation système. Inventé au début des années 1970 pour réécrire UNIX, C est devenu un des langages les plus utilisés. De nombreux langages plus modernes comme C++, Java et PHP reprennent des aspects de C.
Caractéristiques générales.
C est un langage de programmation impératif et généraliste. C est qualifié de langage de bas niveau dans le sens où chaque instruction du langage est conçue pour être compilée en un nombre d'instructions machine assez prévisible en termes d'occupation mémoire et de charge de calcul. Il propose un éventail de types entiers et flottants conçus pour pouvoir correspondre directement aux types supportés par le processeur. Il fait en outre un usage intensif de la notion de pointeur. Il a une notion de type composé, mais ne propose aucune opération qui traite directement des objets de plus haut niveau (fichier informatique, chaîne de caractères, liste…). Ces types plus évolués doivent être traités en manipulant des pointeurs et des types composés. De même, le langage ne propose pas en standard la gestion de la programmation orientée objet, ni de système de gestion d'exceptions. Il existe des fonctions standards pour gérer les entrées-sorties et les chaînes de caractères, mais contrairement à d'autres langages, aucun opérateur spécifique pour améliorer l'ergonomie. Ceci rend aisé le remplacement des fonctions standards par des fonctions spécifiquement conçues pour un programme donné.
Ces caractéristiques en font un langage privilégié quand on cherche à maîtriser les ressources utilisées, le langage machine généré par les compilateurs étant relativement prévisible et parfois même optimal sur les machines d'architecture RISC à grand nombre de registres. Ce langage est donc extrêmement utilisé dans des domaines comme la programmation embarquée sur microcontrôleurs, les calculs intensifs, l'écriture de systèmes d'exploitation et tous les modules où la rapidité de traitement est importante. Il constitue une bonne alternative au langage d'assemblage dans ces domaines, avec les avantages d'une syntaxe plus expressive et de la portabilité du code source. Le langage C a été inventé pour écrire le système d'exploitation UNIX, et reste utilisé pour la programmation système. Ainsi le noyau de grands systèmes d'exploitation comme Windows et Linux sont développés en grande partie en C.
En contrepartie, la mise au point de programmes en C, surtout s'ils utilisent des structures de données complexes, est plus difficile qu'avec des langages de plus haut niveau. En effet, dans un souci de performance, le langage C impose à l'utilisateur de programmer certains traitements (libération de la mémoire, vérification de la validité des indices sur les tableaux…) qui sont pris en charge automatiquement dans les langages de haut niveau.
Dépouillé des commodités apportées par sa bibliothèque standard, C est un langage simple, et son compilateur l'est également. Cela se ressent au niveau du temps de développement d'un compilateur C pour une nouvelle architecture de processeur : Kernighan et Ritchie estimaient qu'il pouvait être développé en deux mois car .
Qualités et défauts.
C'est un des langages les plus utilisés car :
Ses principaux inconvénients sont :
Histoire.
Le langage C est apparu au cours de l'année 1972 dans les Laboratoires Bell. Il était développé en même temps que UNIX par Dennis Ritchie et Ken Thompson. Ken Thompson avait développé un prédécesseur de C, le langage B, qui est lui-même inspiré de BCPL. Dennis Ritchie a fait évoluer le langage B dans une nouvelle version suffisamment différente pour qu'elle soit appelée C. Par la suite, Brian Kernighan aida à populariser le langage. Il procéda aussi à quelques modifications de dernière minute. En 1978, il fut notamment le principal auteur du livre décrivant le langage enfin stabilisé ; Ritchie s'était occupé des appendices et des exemples avec Unix. On parle encore de C K&R, en anglais (pour ) lorsqu'on se réfère au langage tel qu'il existait à cette époque.
Influences subies.
Bien que C soit officiellement inspiré de B et de BCPL, on note une forte influence de PL/1 (ou de PL360) ; on a pu dire que C était à Unix et au PDP11 ce que PL1 fut pour la réécriture de Multics.
Par ailleurs, l'expression conditionnelle semble directement inspirée de Lisp ou d'Algol 60.
Normalisations.
Inventé au début des années 1970, le langage a été complètement décrit pour la première fois en 1978 dans le livre "The C Programming Language" de Brian Kernighan et Dennis Ritchie. On appelle généralement C traditionnel ou K&R C ce premier langage.
En 1983, l'Institut national américain de normalisation (ANSI) a formé un comité de normalisation du langage qui a abouti en 1989 à la norme dite ANSI C ou C89 (formellement ANSI X3.159-1989). En 1990, cette norme a également été adoptée par l'Organisation internationale de normalisation (C ISO, formellement ISO/CEI 9899:1990). ANSI C est une évolution du C K&R qui reste extrêmement compatible. Elle reprend quelques idées de C++.
En 1995, le groupe de travail de l'ISO a publié deux correctif et un amendement à C89. Ces changements assez modestes sont parfois appelés C89 avec amendement 1, ou C94 / C95. Trois fichiers d'entêtes ont été ajoutés, dont deux concernant les caractères larges et un autre définissant un certain nombre de macros en rapport avec la norme ISO 646.
En 1999, une nouvelle évolution du langage est normalisée par l'ISO : C99 (formellement ISO/CEI 9899:1999). Parmi les ajouts, on notera du côté syntaxe des fonctionnalités (types complexes, mot-clef « restrict », directives agissant sur la simplification des instructions arithmétiques) souhaitables pour les calculs numériques intensifs, domaine habituel de Fortran ; ou encore le mélange des déclarations avec le reste du code. Au niveau de la sémantique, la gestion des tableaux dynamiques, ou encore des pointeurs restreints a été ajoutée. La bibliothèque standard du C99 s'est vue enrichir de six fichiers d'entêtes depuis la précédente norme.
En 2011, l'ISO ratifie une nouvelle version du standard : C11, formellement ISO/IEC 9899:2011.
Éléments du langage.
Sources.
L'usage est de donner l'extension de nom de fichier codice_1 aux fichiers source C. En outre, des fichiers permettant de partager les interfaces, portent le même nom, avec l'extension (suffixe) codice_2 ("h" pour "header" en anglais, soit "en-tête" en français). Chaque fichier codice_1 est compilé séparément.
Les rôles des fichiers codice_1 et codice_2 sont répartis ainsi :
Syntaxe.
La syntaxe de C a été conçue pour être brève. Historiquement, elle a souvent été comparée à celle de Pascal, langage impératif également créé dans les années 1970. Voici un exemple avec une fonction factorielle :
Là où Pascal utilise des mots clés comme codice_15, codice_16, codice_17 et codice_18, C utilise des parenthèses et accolades.
Programme proposé en exemple en 1978 dans de Brian W. Kernighan et Dennis M. Ritchie :
Le même programme, conformément à la norme ISO :
Créer un programme affichant est depuis devenu l'exemple de référence pour présenter les bases d'un nouveau langage.
Mots clés.
codice_35, codice_36, codice_37, codice_38, codice_39 (C89), codice_40, codice_41, codice_42, codice_43, codice_44, codice_45 (C89), codice_46, codice_47, codice_48, codice_49, codice_50, codice_51 (C99), codice_22, codice_53, codice_54, codice_55 (C99), codice_56, codice_57, codice_58 (C89), codice_59, codice_60, codice_61, codice_62, codice_63, codice_64, codice_65, codice_25 (C89), codice_67 (C89), codice_68, codice_69 (C99), codice_70 (C99),
codice_71 (C99).
Les termes ci-dessus sont réservés pour être exploités en tant que mots clés, et ne doivent pas être utilisés autrement.
Instructions du préprocesseur.
codice_72,
codice_73,
codice_74 (C89),
codice_75,
codice_76,
codice_77,
codice_78 (C89),
codice_79,
codice_80,
codice_81,
codice_82,
codice_83.
Types.
Le langage C comprend de nombreux types de nombres entiers, occupant plus ou moins de bits. La taille des types n'est que partiellement standardisée : le standard fixe uniquement une taille minimale et une magnitude minimale. Les magnitudes minimales sont compatibles avec d'autres représentations binaires que le complément à deux, bien que cette représentation soit presque toujours utilisée en pratique. Cette souplesse permet au langage d'être efficacement adapté à des processeurs très variés, mais elle complique la portabilité des programmes écrits en C.
Chaque type entier a une forme « signée » pouvant représenter des nombres négatifs et positifs, et une forme « non signée » ne pouvant représenter que des nombres naturels. Le type codice_38, généralement utilisé pour représenter un caractère, est un type entier comme les autres, si ce n'est que, selon l'implémentation, il équivaut à codice_85 ou à codice_86.
Le type codice_45 est un type énuméré.
Il existe des types de nombres à virgule flottante, de précision, donc de longueur en bits, variable ; en ordre croissant :
C99 a ajouté codice_88, codice_89 et codice_90, représentant les nombres complexes associés.
Types élaborés :
Les versions du langage antérieures à C99 ne proposent pas de type booléen, mais il est possible d'en définir un :
ou, en version condensée :
C99 ajoute le type _Bool.
Commentaire.
Dans les versions de C antérieures à C99, les commentaires devaient commencer par une barre oblique et un astérisque (« /* ») et se terminer par un astérisque et une barre oblique. Tout ce qui est compris entre ces symboles est du commentaire, saut de ligne compris :
La norme C99 a ajouté la possibilité de faire des commentaires sur une seule ligne, de la même manière qu’en C++ :
Structures de contrôle.
La syntaxe des différentes structures de contrôle existantes en C est largement reprise dans plusieurs autres langages, comme le C++ bien sûr, mais également Java, C#, PHP ou encore JavaScript.
Les trois grands types de structures sont présents :
Comportements ambigus.
La norme du langage C laisse la définition exacte du comportement de plusieurs opérations au choix du concepteur du compilateur. Ces comportements sont donc définis par l'implémentation. Cette propriété de C permet au compilateur d'utiliser directement les instructions proposées par le processeur, donc de compiler des programmes exécutables courts et efficaces. En contrepartie, c'est parfois la cause de bugs de portabilité des codes source écrits en C. Prenons pour exemple la division entière d'un nombre négatif : -5 / 3. Alors que Fortran, Pascal et Ada spécifient un résultat de -1, et que Modula-3 spécifie un résultat de -2, C garantit simplement que la valeur absolue du reste est strictement inférieure à la valeur absolue du diviseur. La seule garantie dans cet exemple est donc que le résultat sera compris entre -2 et -1.
Pour le programmeur et l'efficacité de C, le plus important est sans doute le fait que les tailles des types de données de base ne doivent respecter que des "garanties minimales". Ainsi, le type codice_22 correspondant au mot machine peut avoir une taille de sur un processeur et une taille de sur un processeur .
Outre les comportements laissés au choix de l'implémentation, des constructions syntaxiquement valables ont un comportement lors de l'exécution complètement indéfini. En plus de la classique division par zéro, on peut signaler l'affectation multiple d'une variable dans la même expression, avec l'exemple :
Les meilleurs compilateurs décèlent certaines constructions problématiques et peuvent les signaler, mais aucun ne prétend à l'exhaustivité.
Bibliothèques logicielles.
La bibliothèque standard.
La bibliothèque standard normalisée, disponible avec toutes les implémentations, présente la simplicité liée à un langage bas-niveau. Voici une liste de quelques en-têtes déclarant des types et fonctions de la bibliothèque standard :
La bibliothèque standard normalisée n'offre aucun support de l'interface graphique, du réseau, des entrées/sorties sur port série ou parallèle, des systèmes temps réel, des processus ou des , ou encore de la gestion avancée des erreurs (comme avec des exceptions structurées). Cela pourrait restreindre d'autant la portabilité pratique des programmes qui ont besoin de faire appel à certaines de ces fonctionnalités, sans l'existence de très nombreuses bibliothèques portables et palliant ce manque ; dans le monde UNIX, ce besoin a aussi fait émerger une autre norme, POSIX.1.
Les bibliothèques externes.
Le langage C étant un des langages les plus utilisés en programmation, de nombreuses bibliothèques ont été créées pour être utilisées avec le C. Fréquemment, lors de l'invention d'un format de données, une bibliothèque ou un logiciel de référence en C existe pour manipuler le format. C'est le cas pour libjpeg, libpng, Expat, les décodeur de référence MPEG, libsocket etc.
Des sources à l'exécutable.
La génération d'un exécutable, à partir des fichiers sources se fait en plusieurs étapes, qui sont souvent automatisées à l'aide d'outils comme make, SCons (écrit en Python), ou bien des outils spécifiques à l'environnement de développement intégré (IDE) utilisé.
Les étapes menant des sources au fichier exécutable sont au nombre de quatre : précompilation, compilation, assemblage, édition de liens.
Précompilation.
Durant cette étape, le préprocesseur effectue plusieurs opérations sur les fichiers sources, en suivant des instructions incluses dans les fichiers eux-mêmes. Le préprocesseur produit alors des fichiers intermédiaires (qui ont généralement l'extension « .i ») pour chaque fichier source, qui seront utilisés dans l'étape suivante.
Le préprocesseur effectue des remplacements de textes, des inclusions de fichiers (généralement les fichiers d'en-têtes contenant diverses déclarations) avec la possibilité d'effectuer certaines opérations uniquement si certaines conditions sont remplies. C'est également durant cette étape que les commentaires sont supprimés.
Compilation.
La phase de compilation consiste généralement en la génération du code assembleur (encore lisible par un être humain, mais dépendant du processeur). Pour chaque fichier source, on obtient un fichier en langage d'assemblage.
Cette étape est divisée en trois sous-étapes, qui sont :
Par abus de langage, on appelle compilation toute la phase de génération d'un fichier exécutable à partir des fichiers sources. Mais c'est seulement une des étapes menant à la création d'un exécutable.
Certains compilateurs C fonctionnent à ce niveau en deux phases, la première générant un fichier compilé dans un langage intermédiaire destiné à une machine virtuelle idéale (voir P-Code) portable d'une plate-forme à l'autre, la seconde convertissant le langage intermédiaire en langage d'assemblage dépendant du processeur utilisé sur la plate-forme cible.
D'autres compilateurs C permettent de ne pas générer de langage d'assemblage, mais seulement le fichier compilé en langage intermédiaire, qui sera interprété ou compilé automatiquement en code natif à l'exécution sur la machine cible (par une machine virtuelle qui sera liée au programme final).
Assemblage.
Cette étape consiste en la génération d'un fichier "objet" pour chaque fichier de code assembleur. Ces fichiers "objet" sont en langage machine. C'est un format binaire, dépendant du processeur. Les fichiers objets sont généralement d’extension « .o » sous Unix ou Linux, ou « .obj » avec les outils de développement pour plates-formes "Microsoft", "Intel", "Digital", "IBM" : DOS, Windows, VMS, CP/M… où les extensions se présentent usuellement sous la forme de trois caractères.
Cette phase est parfois regroupée avec la précédente (par établissement d'un flux de données interne sans passer par des fichiers en langage intermédiaire ou langage d'assemblage), dans ce cas le compilateur génère directement un fichier objet binaire.
Pour les compilateurs qui génèrent du code intermédiaire, cette phase d'assemblage peut aussi être totalement supprimée : c'est la machine virtuelle (liée au programme final, ou utilisée séparément comme chargeur du programme à exécuter sur une machine virtuelle partagée et optimisée spécialement sur la machine hôte) qui interprétera ou compilera ce langage en code machine natif directement sur la machine hôte. Dans ce cas, la machine virtuelle qui interprète le langage intermédiaire ou le compile en code natif optimisé pour la machine hôte, peut être un composant du système d'exploitation ou une bibliothèque partagée installée sur celui-ci, et cette machine virtuelle ne sera même pas incluse dans le programme final livrable.
Édition de liens.
L'édition de liens est la dernière étape et a pour but de réunir tous les éléments d'un programme. Les différents fichiers objets sont alors réunis, ainsi que les bibliothèques statiques, pour ne produire qu'un fichier exécutable.
Le but de l'édition de liens est de sélectionner les éléments de code utiles présents dans un ensemble de codes compilés et de bibliothèques, et de résoudre les références mutuelles entre ces différents éléments afin de permettre à ceux-ci de se référencer directement à l'exécution du programme.
Optimiseurs.
Des essais de comparaison entre le C et l'assembleur effectués depuis 1990 sur des machines RISC montrent, de façon tout à fait contre-intuitive, un net avantage au C lorsque toutes les options d'optimisation du compilateur sont activées. Les optimiseurs construisent en effet un graphe chromatique qui leur permet d'allouer sans se tromper les usages de registres de façon quasi-optimale, là où un programmeur serait vite perdu. Ils regroupent de plus directement les instructions en réarrangeant les chargements et sauvegardes de registres pour bénéficier de l'effet . La même opération effectuée sur un programme source serait envisageable, mais le rendrait quasi impossible ensuite à maintenir.
En revanche, les optimiseurs ont moins de latitude concernant la réorganisation d'instructions CISC, plus complexes, et dans ce cas précis les résultats sont moins tranchés.
Exemples.
Voici quelques exemples présentant très succinctement quelques propriétés du C. Pour plus d'information, voir le .
Chaînes de caractères.
Voici l'exemple de fonction de copie de chaîne de caractères donné dans "The C Programming Language, edition", .
Le principe est de copier les octets-caractères jusqu'à ce que l'on copie le caractère nul, qui marque par convention la fin d'une chaîne en C. La bibliothèque standard de C offre une fonction codice_137 similaire, dont le prototype est codice_138.
La boucle codice_68 utilise une notation classique mais très brève permise par C, qui a contribué à lui donner une réputation de langage peu lisible. L'expression codice_140 copie un caractère, retourne sa valeur, et incrémente les pointeurs codice_141 et codice_142. Cette boucle n'a pas de corps, car toutes les opérations sont effectuées dans l'expression de test du codice_68. On considère qu'il faut maîtriser ce genre de notation pour maîtriser C.
Allocation mémoire.
La structure codice_144 représente un élément d'une liste chaînée, contenant des données de type codice_22. Les deux fonctions qui suivent (codice_146 et codice_147) servent à ajouter et supprimer un élément de la liste.
Dans cet exemple, les deux fonctions essentielles sont codice_129 et codice_149. La première sert à allouer de la mémoire, le paramètre qu'elle reçoit est le nombre de bytes que l'on désire allouer et elle retourne l'adresse du premier byte qui a été alloué, sinon elle retourne NULL. codice_149 sert à libérer la mémoire qui a été allouée par codice_129.

</doc>
<doc id="91111" url="http://fr.wikipedia.org/wiki?curid=91111" title="R (langage de programmation et environnement statistique)">
R (langage de programmation et environnement statistique)

R est un logiciel libre de traitement des données et d'analyse statistiques mettant en œuvre le langage de programmation S. C'est un projet GNU fondé sur l'environnement développé dans les laboratoires Bell par John Chambers et ses collègues. Depuis plusieurs années, deux nouvelles versions apparaissent au printemps et à l'automne. Il dispose de nombreuses fonctions graphiques.
Le logiciel R est considéré par ses créateurs comme étant une exécution de S, avec la sémantique dérivée du langage Scheme. C'est un logiciel libre distribué selon les termes de la licence GNU GPL et est disponible sous GNU/Linux, FreeBSD, NetBSD, OpenBSD, Mac OS X et Windows. Il représente aujourd'hui l'un des objectifs techniques majeurs de la communauté hacker GNU.
Une enquête menée par Rexer Analytics auprès de analystes, retrouve que R est le logiciel le plus souvent utilisé lorsqu'il s'agit d'un travail en entreprise, dans le monde académique, au sein d'organismes publics ou d'ONG et chez les analystes travaillant comme consultants.
Les paquets.
Si R dispose dans sa version de base de la plupart des fonctionnalités utiles pour la statistique courante, ses possibilités s'élargissent dès que l'on utilise les paquets (ou « extensions »), souvent écrits en R et mis librement à disposition. Ces paquets couvrent un très large champ et vont de la statistique multivariée aux méthodes de ré-échantillonnage, de l'économétrie à la biométrie, des modèles de régression sur séries chronologiques ou les modèles à équations simultanées, en passant par l'analyse de données écologiques (Ade4 et vegan), sans oublier l'approche bayésienne. 
Face au nombre toujours croissant de paquets (on comptait près de 80 nouveaux paquets d'octobre à décembre 2007), une page offre des regroupements des paquets selon les domaines abordés.
Parmi ces extensions, on peut également citer celles qui permettent d'interfacer directement R avec des bases de données comme PostgreSQL (via le langage procédural PL/R) et MySQL ou des SIG comme GRASS, celles qui permettent d'exporter ses résultats en LaTeX ou OpenDocument, ou encore celles regroupant des fonctions décrites dans des ouvrages de référence, telles MASS, UsingR ou ISwR.
L'installation des extensions se fait de la manière suivante :
Pour pouvoir l'utiliser, il suffit ensuite d'exécuter :
Interface graphique.
Il existe des interfaces graphiques pour R, comme 
Certains éditeurs de texte proposent également des modes pour R :
Il est également possible d'exécuter des fonctions R directement sur le Web, sans installer le logiciel.
Éléments permettant la réalisation technique du logiciel R.
Les sources du logiciel R sont disponibles dans le dépôt R sources. Il est codé dans les langages C, C++, Fortran et Java. Avant de penser à le recompiler, il faut donc installer un certain nombre de composants.
Sous Windows, la plupart des outils ont été regroupés dans un seul exécutable qui s'appelle R-tools (R-tools). De plus, pour travailler sur la documentation du logiciel, il faut installer le compilateur de fichiers d'aide Microsoft (HTML Help Workshop). Il faut aussi l'outil LaTeX (MiKTeX). Enfin pour la création de l'exécutable d'installation, on utilise le classique inno-setup (inno-setup). Pour retrouver ces quelques indications techniques et pour aller plus loin, on peut consulter le lien suivant : .
Communauté.
Le projet R a été représenté par Toby Dylan Hocking lors de la réunion hacker GNU organisée à Paris du 25 au 28 août 2011 dans les locaux de l'IRILL.

</doc>
<doc id="6016432" url="http://fr.wikipedia.org/wiki?curid=6016432" title="Numerical Recipes">
Numerical Recipes

Numerical Recipes est le titre générique d'une série d'ouvrages sur les algorithmes et l'analyse numérique par William H. Press, Saul Teukolsky, William Vetterling et Brian Flannery. Édité dans de nombreuses éditions, les livres sont imprimés depuis 1986, la dernière édition datant de 2007.
Contenu.
Les livres "Numerical Recipes" couvrent des sujets de l'analyse numérique (interpolation numérique, intégration, algèbre linéaire, équations différentielles, etc), traitement du signal (transformée de Fourier, filtre), traitement des données statistique, ainsi que quelques points sur "in machine learning" (modèles de Markov cachés, machine à vecteurs de support). Le style d'écriture se veut accessible et sur un ton informel. L'accent est mis sur la compréhension des bases sous-jacentes des techniques, pas sur les raffinements qui peuvent, en pratique, être nécessaires pour atteindre des performances et une fiabilité optimale. Peu de résultats sont prouvés avec une réelle rigueur, même si les idées derrière les preuves sont souvent esquissées, et les références sont données.
Pratiquement toutes les méthodes qui sont présentées sont également rédigées en code, qui est imprimé dans le livre.
Selon l'éditeur, Cambridge University Press, les livres "Numerical Recipes" sont les ouvrages sur les méthodes de programmation les plus vendus de tous les temps. Selon "ISI Web of Knowledge", ces dernières années, les livres "Numerical Recipes" ont été cités plus de 3000 fois par an dans la littérature scientifique (par exemple, 3962 fois dans les années 2008).
Histoire.
Édité pour la première fois en 1986 avec des codes en Fortran (rapidement suivi par des éditions en Pascal, BASIC et C), "Numerical Recipes" a pris, dès le départ, une position éditoriale en désaccord avec la sagesse conventionnelle de la communauté d'analyse numérique :
Toutefois, comme il s'est avéré que les années 1980 ont été fertiles pour le côté « boîte noire », ce qui donne des environnements intégrés importants tels que MATLAB et Mathematica qui restent des standards aujourd'hui. Au début des années 1990, lorsque les deuxièmes éditions de "Numerical Recipes" (avec des codes en C, Fortran 77 et Fortran 90) ont été publiées, il était clair que les utilisateurs de "Numerical Recipes" ne représentaient plus la majorité des scientifiques faisant de la programmation, mais a provoqué la scission "entre" ceux qui étaient plus orientés analystes numériques mathématiques et la plus grande communauté utilisant des environnements intégrés. Les deuxièmes éditions ont occupé un rôle stable dans cet environnement de niche.
Au milieu des années 2000, la pratique du calcul scientifique a été radicalement modifiée par l'usage régulier d'Internet et du Web. Reconnaissant que leurs livres "Numerical Recipes" ont été plus appréciés pour leurs textes explicatifs que pour leurs exemples de code, les auteurs ont considérablement élargi la portée de l'ouvrage, et considérablement réécrit une grande partie du texte. Ils ont continué d'inclure du code, toujours imprimé dans le livre, maintenant en C ++, pour chaque méthode discutée. La "Third Edition" a également été édité en version électronique, et rendue par la suite accessible sur le Web gratuitement (avec une quantité de lecture limitée) ou par paiement ou abonnement (avec une quantité de lecture illimitée).
Critiques.
Étant donné le style de rédaction des livres, il n'est pas surprenant qu'ils étaient (et restent dans une certaine mesure) controversés au sein de la communauté de l'analyse numérique. Les premières critiques étaient centrées sur le « manque supposé de fiabilité » (la première édition contenait en effet quelques erreurs), l'exclusion de certains algorithmes, et l'affirmation des auteurs, pas toujours correcte, selon laquelle leurs programmes sont aussi efficaces et fiables que ceux des bibliothèques de type « boîte noire », comme les "NAG Numerical Libraries". Bien qu'il ne mentionne pas "Numerical Recipes" nommément, Whaley "et al." démontrent que LAPACK avec une librairie BLAS hautement optimisé peut être d'un ordre de grandeur plus rapide qu'une routine simple directement inspirée de "Numerical Recipes". Comme autre exemple, Frigo et Johnson pointent le fait que le code de transformée de Fourier rapide (FFT) de "Numerical Recipes" est de 5 à 40 fois plus lent que les programmes hautement optimisés sur des architectures numériques modernes.
Un deuxième point de critiques notent le fait que, bien qu'imprimé dans des livres, les auteurs des ouvrages détiennent les droits d'auteur sur le code, et non disponible à l'usage sous une licence publique générale GNU ou similaire. En effet, une des premières motivations de la GNU Scientific Library était qu'une bibliothèque libre était en partie nécessaire comme à "Numerical Recipes". Sur ce point, rien n'a été épargné aux auteurs de "Numerical Recipes". Ils tirent leurs revenus de la vente de licences individuelles et d'entreprise pour le code, et gèrent clairement la marque "Numerical Recipes" comme une entreprise.
Un troisième point critiqué est le style de code utilisé dans les livres, que certains lecteurs modernes trouvent « fortranisé », même quand le langage du livre est plus orienté objet. 
Certaines de ces critiques sont justifiés, et en raison de l'héritage historique des parties du code. Cependant, les auteurs ont défendu leur style comme nécessaire pour le format des livres, ce qui nécessite un style très laconique de codage en raison des limitations d'espace et du souci de lisibilité.
Liste partielle des différentes éditions.
Les livres diffèrent par leur version d'édition ("1st", "2nd" et "3rd") et par le langage informatique utilisé dans les codes donnés.
Les livres sont édités par Cambridge University Press.

</doc>
<doc id="6070254" url="http://fr.wikipedia.org/wiki?curid=6070254" title="Information Processing Language">
Information Processing Language

IPL ("", c'est-à-dire « Langage de traitement de l'information ») est un langage de programmation développé par Allen Newell, Shaw Cliff et Herbert Simon à la RAND Corporation et le Carnegie Institute of Technology à partir de 1956. Newell avait le rôle de spécificateur-application programmeur, Shaw était le programmeur système et Simon a pris le rôle de programmeur-utilisateur.
Le langage comprend des fonctionnalités destinées à la résolution générale de problèmes, y compris des listes, des associations, des schémas (frames), l'allocation dynamique de mémoire, les types de données, la récursivité, la récupération associative, des fonctions comme arguments, les générateurs (flux), et le multitâche coopératif. 
IPL a lancé le concept de traitement de listes, mais dans un style en langage assembleur. Certains aspects d'IPL ont d'ailleurs influencé le LISP.

</doc>
<doc id="6086987" url="http://fr.wikipedia.org/wiki?curid=6086987" title="MOLOG">
MOLOG

MOLOG est une généralisation du langage Prolog permettant d'étendre le paradigme de la Programmation logique à la logique non classique et en particulier à la logique modale, la logique aléthique ou la logique temporelle. Le nom "MOLOG" est un acronyme de MOdal LOGic et également une référence à l'acronyme "PROLOG", PROgrammation 
LOGique. Il a été créé par Luis Fariñas Del Cerro, Andreas Herzig et Jean-Marc Alliot entre 1986 et 1994.
Contexte.
Au milieu des années 80, le langage PROLOG est devenu une référence en matière de langage de programmation permettant d'utiliser l'expressivité de la logique mathématique en lieu et place de l'enchainement d'instructions ou de fonctions caractéristiques des langages impératifs ou fonctionnels. L'un des problèmes de PROLOG était sa limitation à l'utilisation des clauses de Horn en calcul des prédicats du premier ordre. Plusieurs équipes se sont lancées dans la réalisation de méta-interpréteurs spécifiques, généralement écrits eux-mêmes en PROLOG, mais qui permettaient d'étendre PROLOG à d'autres logiques, comme Templog ou Temporal Prolog pour la logique temporelle, N-Prolog pour les logiques hypothétiques, ou les extensions de contexte.
Principe et développement.
Le premier but de MOLOG était d'être capable de traiter de façon générique toutes les formes de logique, contrairement aux méta-interpréteurs spécialisés sus-cités. Pour ce faire, le système se décomposait en trois parties (au lieu de deux pour un système PROLOG classique): 
Le moteur d'inférence et la base de clauses de Horn sont également présents en PROLOG (le moteur d'inférence étant le mécanisme central de fonctionnement de PROLOG, et la base de clauses le "programme" rédigé par l'utilisateur). Mais en PROLOG les règles de résolution sont implicites (et incluses dans le moteur d'inférences) et se réduisent globalement au classique modus ponens en chainage arrière. L'idée centrale de MOLOG est d'externaliser les règles de résolutions, permettant ainsi de définir le fonctionnement du langage sur des clauses de Horn étendues comprenant des opérateurs modaux.
Les premières versions de MOLOG étaient également des méta-interpréteurs écrits en PROLOG, mais la lenteur de PROLOG d'une part et la complexité beaucoup plus importante de la résolution en logique non-classique d'autre part ne permettaient pas de faire fonctionner les programmes MOLOG dans des temps raisonnables. 
En 1992, une version de MOLOG fut développée en ADA faisant ainsi le pendant à C-PROLOG, une version de PROLOG écrite en C. Cette version était extrêmement rapide, capable de fonctionner en parallèle sur des réseaux d'ordinateurs, et permettait ainsi de faire de la résolution automatique en logique non-classique dans des temps raisonnables. Le système fut présenté à la grand-messe des systèmes dits de "cinquième génération".
Exemple de programme.
Un classique exemple d'utilisation de MOLOG est la formalisation en logique modale multi-S4 du problème connu en anglais sous le nom de "Wise Men Problem", dont voici l'énoncé:
"Un roi souhaitait choisir parmi ses trois fils, Gauvin, Lancelot et Arthur, lequel lui succèderait. Pour ce faire, il organisa une épreuve consistant à les réunir tous les trois dans la même pièce, puis à les coiffer chacun d'un heaume soit noir, soit blanc. Chacun des princes était capable de voir la couleur des heaumes des deux autres mais pas la couleur du sien. Le roi s'adressa alors à ses fils et leur dit: "Je puis vous dire qu'il y a dans cette pièce au moins l'un d'entre vous qui porte un heaume blanc." Puis il s'adressa successivement à Gauvin, Lancelot puis Arthur, en leur demandant de quelle couleur était leur heaume. Le premier fut incapable de répondre ainsi que le second. Quant à Arthur, il sut évidemment que son heaume était blanc, et fut ainsi désigné héritier du royaume."
Après avoir brièvement noté que notre roi est un fieffé chenapan qui avait tout arrangé pour qu'Arthur soit son successeur (Lancelot et Gauvin portent des heaumes noirs, et Arthur un heaume blanc, configuration qui garantit le résultat), voyons comment modéliser ce problème en MOLOG.
Nous allons tout d'abord exprimer que tout le monde sait que si le heaume de Gauvin est
noir et que le heaume d'Arthur est noir alors le heaume de Lancelot est blanc (hypothèse qu'il y a au moins un heaume blanc):
NEC(X) signifiant X sait que, et NEC(_) signifie tout le monde sait que. NEC est un des opérateurs modaux étendant la logique classique dans le cadre des clauses de Horn étendues. Bien entendu, les deux clauses symétriques doivent être ajoutées au programme:
Il faut ensuite exprimer que tout le monde sait que, si, pour Lancelot, le heaume d'Arthur peut être blanc, alors il est blanc de façon certaine, puisque Lancelot voit le heaume d'Arthur:
POS(X) est un autre opérateur modal signifiant il est possible pour X que. Cette clause signifie donc, en la lisant de gauche à droite, que tout le monde sait (NEC(_)) que s'il est possible pour lancelot (POS(lancelot)) que le heaume d'Arthur soir blanc (blanc(arthur)) alors (→) Lancelot sait (NEC(lancelot)) que le heaume d'Arthur est blanc (blanc(arthur)). Cette clause doit être complétée par les clauses symétriques de celle-ci, les symétries concernant les trois princes et les deux couleurs. Il faut cependant faire bien attention de ne rien écrire de la forme:
En effet, s'il est possible pour Lancelot que son heaume soit blanc, cela ne lui permet en rien de conclure, car il est incapable de voir son propre heaume, et donc la possibilité du fait n'entraine pas sa certitude.
Il ne reste plus qu'à rajouter les clauses correspondant aux réponses successives des trois princes, clauses qui créent l'asymétrie d'information et permettent ainsi à Arthur de trouver la solution alors que les deux premiers princes ne le peuvent pas:
La première clause signifie que Lancelot sait qu'il est possible pour Gauvin que Gauvin ait un heaume noir, puisque Gauvin n'a pas pu répondre. La seconde dit qu'Arthur sait que Lancelot sait qu'il est possible pour Gauvin que Gauvin ait un heaume noir. Et la troisième exprime que Arthur sait qu'il est possible pour Lancelot que Lancelot ait un heaume noir.
Le problème ainsi posé est résolu en quelques secondes par MOLOG. Une version du langage avec cet exemple déjà codé est disponible en ligne.
Utilisation ultérieure.
Le langage était rapide et puissant, mais il souffrait de deux défauts majeurs:
MOLOG est donc une curiosité historique qui n'eut guère d'avenir, sauf peut-être à montrer que, malgré une expressivité potentielle bien supérieure à la logique classique, les logiques modales sont d'un emploi complexe qui en limite l'utilisabilité.
Liens externes.
Source de la dernière version de MOLOG, nécessite un compilateur ADA.

</doc>
<doc id="6120926" url="http://fr.wikipedia.org/wiki?curid=6120926" title="Julia (langage de programmation)">
Julia (langage de programmation)

Julia est un langage de programmation de haut niveau, performant et dynamique pour le calcul scientifique, avec une syntaxe familière aux utilisateurs d'autres environnements de développement similaires (Matlab, R, Scilab, Python, etc...). Il fournit un compilateur sophistiqué, une exécution parallèle distribuée, la précision numérique, et une bibliothèque de fonctions mathématique étendue. La bibliothèque, essentiellement écrite dans le langage Julia lui-même, intègre également des bibliothèques matures et le nec-plus-ultra des langages C et langage Fortran pour l'algèbre linéaire, la génération des nombres aléatoires, les FFTs, et le traitement de chaînes. Des bibliothèques continuent d'être ajoutées au fil du temps. Les programmes Julia sont organisés autour de la définition de fonctions, et de leur surcharge autour de différents types de combinaisons de types d'argument

</doc>
<doc id="7445" url="http://fr.wikipedia.org/wiki?curid=7445" title="C++">
C++

Le C++ est un langage de programmation permettant la programmation sous de multiples paradigmes comme la programmation procédurale, la programmation orientée objet et la programmation générique. Le langage C++ n'appartient à personne et par conséquent n'importe qui peut l'utiliser sans besoin d'une autorisation ou obligation de payer pour avoir le droit d'utilisation.<br><br>
C++ est l'un des langages de programmation les plus populaires, avec une grande variété de plateformes matérielles et de systèmes d'exploitation.
Histoire.
Bjarne Stroustrup a développé C++ au cours des années 1980, alors qu'il travaillait dans le laboratoire de recherche Bell d'AT&T. Il s'agissait en l'occurrence d'améliorer le langage C. Il l'avait d'ailleurs nommé "C with classes" (« »). Les premières améliorations se concrétisèrent donc par la prise en charge des classes, ainsi que par de nombreuses autres fonctionnalités comme les fonctions virtuelles, la surcharge des opérateurs, l'héritage (simple ou multiple), les , la gestion des exceptions, etc.
Le langage C++ est normalisé par l'ISO. Sa première normalisation date de 1998 (ISO/CEI 14882:1998). Le standard a ensuite été amendé par l'erratum technique de 2003 ISO/CEI 14882:2003. Le standard actuel a été ratifié et publié par ISO en septembre 2011 sous le nom de ISO/IEC 14882:2011. (aussi appelé C++11).
Les prochains standards du langage devraient être publiés en 2014 (mise à jour mineure) et en 2017.
En langage C, ++ est l'opérateur d'incrémentation, c'est-à-dire l'augmentation de la valeur d'une variable de 1. C'est pourquoi C++ porte ce nom : cela signifie que C++ est un niveau au-dessus du C. Il existe de nombreuses bibliothèques C++ en plus de la bibliothèque standard de C++ () qui est incluse dans la norme. Par ailleurs, C++ permet l'utilisation de l'ensemble des bibliothèques C existantes.
Fonctionnalités introduites par C++.
On peut considérer que C++ « est du C » avec un ajout de fonctionnalités. Cependant, certains programmes syntaxiquement corrects en C ne le sont pas en C++.
Les fonctionnalités ajoutées sont :
La compilation d'un programme en C++ effectue également un contrôle plus minutieux sur le typage.
Histoire de C++.
Stroustrup a commencé à travailler sur C avec classes en 1979. L'idée de créer un nouveau langage vient de l'expérience en programmation de Stroustrup pour sa thèse de doctorat. Stroustrup trouvait que Simula avait des fonctionnalités très utiles pour le développement de gros programmes mais qu'il était trop lent pour être utilisé en pratique (cela était dû à un problème d'implémentation du compilateur Simula), tandis que BCPL était rapide mais de trop bas niveau et non adapté au développement de gros logiciels. Quand Stroustrup commença à travailler aux laboratoires Bell, on lui demanda d'analyser le noyau UNIX en vue de faire du calcul distribué. Se rappelant sa thèse, Stroustrup commença à améliorer le langage C avec des fonctionnalités similaires à celle de Simula. C fut choisi parce qu'il est rapide, portable et d'usage général. En outre, il était une bonne base pour le principe original et fondateur de C++ : « vous ne payez pas pour ce que vous n'utilisez pas ». Dès le départ, le langage ajoutait à C la notion de classe (avec encapsulation des données), de classe dérivée, de vérification des types renforcés (typage fort), d'« inlining », et d'argument par défaut.
Comme Stroustrup développait C avec classes, il écrivit CFront, un compilateur qui générait du code source C à partir de code source C avec classes. La première commercialisation se fit en octobre 1985.
En 1983, le nom du langage passa de "C avec classes" à celui de « C++ ». Parmi les nouvelles fonctionnalités qui furent ajoutées au langage, il y avait les fonctions virtuelles, la surcharge des opérateurs et des fonctions, les références, les constantes, le contrôle du typage amélioré et les commentaires en fin de ligne. En 1985 fut publiée la première édition de , apportant ainsi une référence importante au langage qui n'avait pas encore de standard officiel. En 1989, c'est la sortie de la version 2.0 de C++. Parmi les nouvelles fonctionnalités, il y avait l'héritage multiple, les classes abstraites, les fonctions membres statiques, les fonctions membres constantes, et les membres protégés. En 1990, (« ARM ») fut publié apportant les bases du futur standard. Les ajouts de fonctionnalités tardifs qu'il comportait couvraient les modèles, les exceptions, les espaces de noms, les nouvelles conversions et le type booléen.
Comme le langage C++ évoluait, la bibliothèque standard évoluait de concert. La première addition à la bibliothèque standard de C++ concernait les flux d'entrées/sorties qui apportaient les fonctionnalités nécessaires au remplacement des fonctions C traditionnelles telles que "printf" et "scanf". Ensuite, parmi les additions les plus importantes, il y avait la Standard Template Library.
Après des années de travail, un comité réunissant l'ANSI et l'ISO standardisa C++ en 1998 (ISO/CEI 14882:1998), l'année où le comité de standardisation se réunissait à Sophia Antipolis dans le sud de la France. Pendant quelques années après la sortie officielle du standard, le comité traita le rapport de problèmes et publia une version corrigée du standard C++ en 2003.
Personne ne possède le langage C++. Il est libre de droit. Le document de standardisation n'est quant à lui pas disponible gratuitement.
La bibliothèque standard (C++ standard library).
La bibliothèque standard du C++ est en grande partie un sur-ensemble des fonctions disponibles dans la bibliothèque standard du C. Elle englobe la Standard Template Library (STL) qui met à la disposition du programmeur des outils puissants comme les collections (conteneurs) et les itérateurs.
À l'origine, la STL était une bibliothèque développée par Alexander Stepanov qui travaillait pour Hewlett-Packard. Dans la norme, celle-ci n'est pas appelée STL, car elle est considérée comme faisant partie de la bibliothèque standard du C++. Toutefois, beaucoup de personnes l'appellent encore de cette manière pour distinguer d'une part, les fonctions d'entrées/sorties comprises dans cette bibliothèque et, d'autre part, celles fournies par la bibliothèque C.
Comme en C, l'utilisation d'une bibliothèque se fait par l'intermédiaire de la directive codice_1 (suivie du nom du fichier d'en-tête).
La programmation orientée objet en C++.
C++ utilise les concepts de la programmation orientée objet et permet entre autres :
L'encapsulation en C++.
L'encapsulation permet de faire abstraction du fonctionnement interne (c'est-à-dire, la mise en œuvre) d'une classe et ainsi de ne se préoccuper que des services rendus par celle-ci. C++ met en œuvre l'encapsulation en permettant de déclarer les membres d'une classe avec le mot réservé codice_2, codice_3 ou codice_4. Ainsi, lorsqu'un membre est déclaré :
C++ n'impose pas l'encapsulation des membres dans leurs classes. On pourrait donc déclarer tous les membres publics, mais en perdant une partie des bénéfices apportés par la programmation orientée objet. Il est de bon usage de déclarer toutes les données privées, ou au moins protégées, et de rendre publiques les méthodes agissant sur ces données. Ceci permet de cacher les détails de la mise en œuvre de la classe.
Voici l'exemple de Hello world donné dans "The C++ Programming Language, Third Edition" de Bjarne Stroustrup :
Une importante notion de C++ sont les espaces de noms (). Dans un espace de noms sont définis des noms de fonctions et de variables. Ce mécanisme permet de résoudre les ambiguïtés lorsque plusieurs variables provenant de différents composants sont homonymes.
Pour recourir à une fonction d'un espace de nom, l'opérateur de résolution de portée « :: » est utilisé.
Ce code source fait appel à la variable globale cout définie dans l'espace de nom standard (std).
La directive using.
Il est possible de spécifier un espace de nom précis à utiliser afin d'éviter d'avoir à recourir à l'opérateur de résolution de portée. Pour cela, le mot clé using est utilisé avec cette syntaxe :
Ainsi, pour utiliser la variable cout définie dans le "namespace" standard sans utiliser l'opérateur de résolution de portée, il est possible d'écrire :
Cela est valable pour tous les espaces de noms. Cette instruction se place en général avant le début du code source proprement dit :
using peut aussi être utilisé dans les classes. Si une classe B hérite d'une classe A, elle peut passer des attributs protected en public :
Déclaration et définition de classe.
Il est d'usage de séparer prototype (déclaration) et implémentation (définition) de classe dans deux fichiers :
La déclaration se fait dans un fichier d'en-tête (dont l'extension varie selon les préférences des développeurs : sans extension dans le standard, .h comme en C, .hh ou .hpp pour différencier C et C++) alors que la définition de la classe se fera dans un fichier source (d'extension également variable, en général .C, .cc, .cpp ou .cxx).
Déclaration de classe.
Exemple de la déclaration de la classe MessageInternet comportant des attributs privés et des méthodes publiques dont le constructeur 'MessageInternet' :
Implémentation (définition) de classe.
Dans le fichier source, le nom d'une méthode définie par une classe doit nécessairement être précédé du nom de la classe suivi immédiatement des caractères "::".
Par exemple, voici l'implémentation (définition) de la classe déclarée précédemment :
Templates.
À quoi servent les templates ?
Les templates permettent d'écrire des fonctions et des classes en paramétrant le type de certains de leurs constituants (type des paramètres ou type de retour pour une fonction, type des éléments pour une classe collection par exemple). Les templates permettent d'écrire du code générique, c'est-à-dire qui peut servir pour une "famille" de fonctions ou de classes qui ne diffèrent que par la valeur de ces paramètres.
Paramètres des templates.
Les paramètres peuvent être de différentes sortes :
Pourquoi utiliser des templates ?
En programmation, il faut parfois écrire de nombreuses versions d'une même fonction ou classe suivant les types de données manipulées.
Par exemple, un tableau de int ou un tableau de double sont très semblables, et les fonctions de tri ou de recherche dans ces tableaux sont identiques, la seule différence étant le type des données manipulées.
En résumé, l'utilisation des templates permet de « paramétrer » le type des données manipulées.
Exemple de templates.
Dans la bibliothèque standard C++, on trouve de nombreux templates. On citera à titre d'exemple, les entrées/sorties, les chaînes de caractères ou les conteneurs. Les classes "string", "istream", "ostream" et "iostream" sont toutes des instanciations de type "char".
Les fonctions de recherche et de tri sont aussi des templates écrits et utilisables avec de nombreux types.
Dans la ligne codice_6, on doit explicitement donner le type codice_7 pour le type paramétré codice_8 car le compilateur ne déduit pas le type de codice_8 lorsqu'on passe en même temps un codice_10 (1) et un codice_7 (2.2f).
Spécialisation des templates.
Un template donné peut avoir plusieurs instanciations possibles selon les types donnés comme paramètres. Si un seul paramètre est spécialisé, on parle de "spécialisation partielle". Ceci permet par exemple :
SFINAE.
Le mécanisme décrit par l'abréviation SFINAE ("Substitution Failure Is Not An Error") permet de surcharger un template par plusieurs classes, même si certaines spécialisations, par exemple, ne peuvent pas être utilisées pour tous les paramètres de templates. Le compilateur, lors de la substitution, ignore alors les instantiations inapplicables, au lieu d'émettre une erreur de compilation.
Le polymorphisme et les méthodes virtuelles en C++.
Le polymorphisme est mis en œuvre à l'aide du mécanisme des méthodes virtuelles en C++. Lorsqu'une méthode virtuelle est appelée, l'implémentation de la méthode exécutée est choisie en fonction du type réel de l'objet. L'appel n'est donc résolu qu'à l'exécution, le type de l'objet ne pouvant pas - a priori - être connu à la compilation.
Un mot clé est alors introduit : codice_12. Ce mot clé est placé devant la déclaration de la méthode.
Le mot clé codice_12, placé devant le prototype de la fonction, indique au compilateur que la fonction est susceptible d'être redéfinie dans une classe dérivée. Il suffit alors de dériver une classe et de définir une nouvelle fonction de même signature (même nom, paramètres compatibles - voir la notion de covariance).
Ainsi l'appel de cette fonction sur un objet dont on ignore le type, mais accédé en tant qu'objet de la classe de base, pourra donner lieu à l'appel de la fonction définie dans la classe dérivée.
Il est généralement conseillé d'utiliser le mot clé codice_12 devant la déclaration du destructeur de la classe de base, afin que celui des sous-classes soit appelé également lorsque le programme utilise un pointeur d'instance de la classe de base au lieu d'un pointeur d'instance de la classe dérivée si et seulement si la classe de base peut être utilisée pour manipuler des classes dérivées.
Ce type de polymorphisme est dit dynamique. Le mécanisme de la surcharge est un polymorphisme statique. Dans les deux cas il faut appliquer une logique (par exemple : le nombre et le type des paramètres) pour résoudre l'appel. Dans le cas de la surcharge, la logique peut être entièrement calculée à la compilation. Ce calcul permet des optimisations rendant le polymorphisme statique "plus rapide" que sa version dynamique. La liaison dynamique de méthodes issues du mécanisme des méthodes virtuelles induit souvent une table cachée de résolution des appels. Cette table cachée des méthodes augmente le temps nécessaire à l'appel de méthode à l'exécution par l'ajout d'une indirection supplémentaire.
Le choix entre liaison dynamique et surcharge (polymorphisme dynamique et statique) est typiquement un problème de calculabilité des appels, ayant souvent pour conséquence finale un choix entre expressivité et performance.
Construction.
Un programme C++ peut être produit avec des outils qui automatisent le processus de construction. Les plus utilisés sont :

</doc>
<doc id="6181495" url="http://fr.wikipedia.org/wiki?curid=6181495" title="CoffeeScript">
CoffeeScript

CoffeeScript est un langage de programmation, qui se compile en JavaScript. Le langage ajoute du sucre syntaxique inspiré par Python, Ruby et Haskell afin d'améliorer la brièveté et la lisibilité du JavaScript, tout en ajoutant des fonctionnalités comme le filtrage par motif ou les listes en compréhension.
Le résultat est compilé de façon prévisible en JavaScript, et les programmes peuvent être écrits avec moins de code (typiquement un tiers de lignes en moins) sans effet sur la vitesse d'exécution. Depuis le , CoffeeScript est dans la liste des projets les plus populaires de GitHub.
Le langage a une popularité relativement importante dans la communauté de Ruby. Le support de CoffeeScript est inclus dans la version 3.1 de Ruby on Rails. De plus, Brendan Eich a cité CoffeeScript comme une influence sur son idée du futur du JavaScript.
Histoire.
Le , Jeremy Ashkenas a effectué le premier commit Git de CoffeeScript avec le commentaire : « "" » (« premier commit du langage mystère »). Le compilateur était écrit en Ruby. Le , il a publié la première version numérotée et documentée, la 0.1.0. Le , le version 0.5 a été publiée, remplaçant le compilateur Ruby par un compilateur écrit en pur CoffeeScript. 
Le , Ashkenas a annoncé la publication de la version stable 1.0.0 sur Hacker News, le site où le projet a été annoncé pour la première fois.
Exemples.
Tests et compréhensions.
Pour calculer l'IMC de Barry, joueur de basket amateur, on fait d'habitude quelque chose comme ceci (ici en JavaScript):
CoffeeScript permet de combiner les deux tests en un seul:
ou, plus naturellement pour qui est habitué à la langue anglaise,
Boucles et compréhensions.
En général, l'implémentation de l'algorithme d'Euclide utilise une boucle "tant que" (ici, en Python):
C'est également possible en CoffeeScript; mais celui-ci possède également une boucle "jusqu'à":
Une boucle "for" peut souvent être remplacée par une liste en compréhension. Par exemple, pour calculer les carrés des premiers nombres impairs (c'est-à-dire dont le reste modulo 2 vaut 1), on peut utiliser l'une des propositions suivantes:
fonctions et jQuery.
Le code JavaScript permettant d'initialiser la bibliothèque jQuery est :
Ou, plus simplement :
En CoffeeScript, le mot-clé codice_1 est remplacé par le symbole codice_2, et l'indentation est utilisée à la place des accolades, comme en Python ou en Haskell. Les parenthèses peuvent généralement être omises. Ainsi, le snippet ci-dessus peut être écrit, en CoffeeScript :
Ou bien :
Compilation.
Le compilateur CoffeeScript est écrit en CoffeeScript depuis la version 0.5 et est disponible en tant qu'utilitaire Node.js ; cependant, la base du compilateur ne nécessite pas Node.js et peut être utilisée dans n'importe quel environnement JavaScript. Une des alternatives à l'utilitaire Node.js est Coffee Maven Plugin, un plugin pour le moteur de production Apache Maven. Ce plugin utilise Mozilla Rhino, un moteur JavaScript écrit en Java.
Le site officiel, CoffeeScript.org, dispose d'un bouton « Essayer CoffeeScript » dans la barre de navigation ; cliquer dessus ouvre une fenêtre modale qui permet d'entrer du code CoffeeScript, de voir le résultat en JavaScript, et de l'essayer directement dans le navigateur. Le site jscoffee propose une traduction bidirectionnelle.

</doc>
<doc id="6237862" url="http://fr.wikipedia.org/wiki?curid=6237862" title="Logtalk">
Logtalk

Logtalk est un langage de programmation logique, orienté objet, issu de Prolog.

</doc>
<doc id="5440456" url="http://fr.wikipedia.org/wiki?curid=5440456" title="Langage de programmation Red">
Langage de programmation Red

Red est un langage de programmation impératif et fonctionnel créé en 2011 par Nenad Rakocevic. Il est distribué en tant que logiciel libre selon les termes de la licence BSD modifiée avec un interpréteur Juste-à-temps, les deux étant respectivement basés sur le langage de programmation REBOL et l'interprète REBOL.
Historique.
Le langage de programmation Red est officiellement annoncé à la conférence "REBOL & Boron" le 26 février 2011 aux Pays-Bas par son créateur Nenad Rakocevic. Ce programmeur français s'était lancé dans le développement de ce nouveau langage en octobre 2010 en réponse à la stagnation que connaissait alors REBOL. Rakocevic était par ailleurs connu au sein de cette communauté pour ses contributions, dont la création du serveur HTTP Cheyenne. Le projet est un succès tant et si bien qu'il est élu par ses pairs « "Rebol" de l'année 2011 ». Red repose en effet sur le langage de programmation REBOL qui lui sert également de « bootstrapping ». Le langage Red est ensuite présenté à l'échelle internationale pour la journée du logiciel libre 2011, ce qui confère au projet une certaine visibilité.
Caractéristiques.
Voici les principales caractéristiques de Red :
Schéma du langage.
Voici un schéma détaillant les différents niveaux du langage de programmation Red :
Exemple.
Un exemple en couleur :

</doc>
<doc id="6251929" url="http://fr.wikipedia.org/wiki?curid=6251929" title="Pawn (langage de programmation)">
Pawn (langage de programmation)

Le pawn est un langage de programmation "open source".
"Info : Pawno est ce qu'on appelle un IDE : Integrated Development Environment. En Français, cela se traduit par Environnement de développement.
Il contient l'éditeur de code, le compilateur, et le débuggeur qui vous retournera les erreurs. Il vous évite donc d'éditer le texte et d'avoir à utiliser un autre logiciel pour compiler."
Le Pawno sert à scripter un 'serveur' de jeu sur la plate-forme de Grand Theft Auto San Andreas Multiplayer.

</doc>
<doc id="2482644" url="http://fr.wikipedia.org/wiki?curid=2482644" title="C++11">
C++11

C++11, anciennement connu sous le nom de C++0x, est la nouvelle norme pour le langage C++ en informatique. Elle a été approuvée unanimement le 12 août 2011. Elle remplace la précédente norme, ISO/CEI 14882, publiée en 1998 et mise à jour en 2003. Ces dernières sont plus connues sous les noms informels de C++98 et C++03. C++11 introduit plusieurs nouveautés au langage initial, ainsi que de nouvelles fonctionnalités à la bibliothèque standard du C++ comme la plupart des bibliothèques du Technical Report 1, à l'exception de la bibliothèque de fonctions mathématiques spéciales.
C++11 a été publié sous le nom de ISO/IEC 14882:2011 en septembre 2011. Une version payante est disponible sur le site de l'ISO. Le dernier "working draft" gratuit est le N3337, qui date du 12 janvier 2012, les seules différences avec le standard étant des corrections éditoriales.
Un langage de programmation comme le C++ suit une évolution qui permet aux programmeurs de coder plus rapidement, de façon plus élégante et permettant de faire du code maintenable. Ce processus soulève inévitablement des questions de compatibilité avec le code existant, ce qui s'est produit de temps en temps pendant le processus de développement du C++. Cependant, d'après l'annonce faite par Bjarne Stroustrup (l'inventeur du langage C++ et membre du comité), la nouvelle norme sera presque totalement compatible avec la norme actuelle.
Changements prévus pour la mise à jour de la norme.
Comme dit précédemment, les changements du langage C++ concernent aussi bien le langage initial que la bibliothèque standard.
Durant le développement de chaque fonctionnalité de la nouvelle norme, le comité a appliqué les directives suivantes :
Extensions du langage.
Multitâche.
Mémoire locale pour un thread.
La mémoire locale de thread ou Thread Local Storage n'est pas un concept inventé par la nouvelle norme : de nombreux compilateurs proposent déjà cette fonctionnalité, ainsi que la bibliothèque threads de Boost. C++11 introduit le mot-clef codice_1 pour déclarer qu'une variable doit être stockée dans une zone mémoire appartenant au thread. Chaque thread embarque ainsi sa propre copie d'une variable déclarée de la sorte, et les modifications d'une de ces copies n'affectent pas les copies appartenant aux autres threads.
Lorsqu'une variable statique (ou une variable de classe) est ainsi définie, sa durée de vie est alors réduite à celle du thread (le destructeur des objets, notamment, est appelé lorsque le thread s'achève).
Les classes.
Délégation du constructeur.
En C++, un constructeur appartenant à une classe ne peut pas appeler un autre constructeur de cette même classe, ce qui peut entraîner de la duplication de code lors de l'initialisation de ses attributs. En permettant au constructeur de déléguer la création d'une instance à un autre constructeur, C++11 apporte donc une solution.
Dans l'exemple ci-dessus, on peut voir que le second constructeur appelle le premier constructeur, ce qui aurait conduit à une erreur de compilation en C++.
Sizeof sur les attributs de classes sans objet explicite.
En C++03, codice_3 peut être utilisé sur des types ou des objets, mais pas sur un membre de classe (excepté dans la bibliothèque Qt).
C++11 le rend possible. On peut donc maintenant faire :
Ce qui résultait en une erreur de compilation avant.
Liste d'initialiseurs.
Pour initialiser un conteneur à l'aide de valeurs connues, il fallait le faire élément par élément. C++11 introduit le patron de classe codice_4 qui permet d'initialiser les conteneurs avec la même syntaxe que celle permettant en C d'initialiser les tableaux , donc à l'aide d'une suite de valeurs entre accolades.
Les Templates.
Les templates variadiques.
Pour remplacer les fonctions variadiques du C (déconseillées en C++), C++0x introduit les templates variadiques. Ces templates étendent le concept précédent en lui ajoutant la possibilité de prendre un nombre quelconque d'arguments. Elles sont supportées par le compilateur GCC depuis la version 4.3 car elles font partie de l'expérimentation du support de C++0x.
L'utilité de templates possédant un nombre quelconque d'arguments se perçoit aisément avec la classe codice_6, qui généralise le concept de paire (triplet, n-uplet, etc.) ou bien avec cet exemple d'implémentation de la fonction "printf" :
C++0x définit un certain nombre de concepts que nous pouvons approcher grâce au code source suivant :
Les concepts.
Les concepts ont été retirés de la norme.
Les chevrons (codice_10).
Les compilateurs C++ actuels traitent toujours une séquence de deux signes "supérieur à" comme un opérateur de décalage binaire vers la droite. En conséquence, lors de l'imbrication de l'utilisation de patrons, les programmeurs sont obligés d'insérer un espace entre les deux chevrons fermants.
Par exemple, en C++03, ce code provoque une erreur de compilation :
C++11 tentera de détecter automatiquement si les symboles doivent jouer le rôle de chevrons fermants ou d'opérateur de décalage binaire.
Template externe.
Les templates ne sont actuellement pas pris en compte par l'éditeur de liens : il est nécessaire d'incorporer leur définition dans tous les fichiers sources les utilisant en programmation modulaire. Leur compilation était donc longue et gourmande puisque la classe était recompilée dans chaque fichier source, pour chaque type utilisé.
C++11 permettra l'utilisation du mot-clé codice_11 pour rendre les templates globaux. Les fichiers désirant utiliser le template n'ont qu'à le déclarer.
Autres nouvelles fonctionnalités du C++11.
Assertions statiques.
La bibliothèque Boost propose déjà cette facilité à travers la macro codice_12. Cependant, son implémentation est étrange, basée sur la métaprogrammation et des comparaisons de taille de structures intermédiaires créées pour l'assertion sans trop de rapport avec le concept.
Par conséquent, intégrer la fonction dans le langage apporte une solution propre au problème.
En pratique, une assertion statique permet de vérifier à la compilation qu'une valeur est vraie. Par exemple, il est possible d'implémenter les concepts en utilisant codice_13 et codice_12. Si une classe template nécessite que son type template soit un POD, elle peut faire une assertion statique sur codice_15, ce qui est une constante intégrale de type codice_16 et remplit dont le critère pour paraître dans une assertion statique.
En outre, en C++11, l'expression :
permettrait à une bibliothèque d'être certaine qu'elle est compilée sur un système vérifiant cette condition (x86-64 par exemple).
codice_17 permet aussi de préciser un message d'erreur. Dans ce cas-là, l'assertion précédente ressemblerait à :
Inférence de types.
Le mot clé codice_18 se voit assigner une nouvelle sémantique par le nouveau standard. Nous connaissions son unique sémantique d'indicateur de classe de stockage pour une variable. En effet, déclarer une variable automatique revenait à indiquer au compilateur qu'elle était valide seulement dans l'espace où elle était déclarée ; ce comportement étant aussi celui par défaut, le mot clé était inutile. Dans le nouveau standard, il change de sémantique et prend la place du type dans la déclaration. Le type sera alors automatiquement décidé par correspondance avec le type retourné par l'objet utilisé pour l'initialisation de la variable. Les variables étant déclarées avec codice_18 devront donc impérativement être initialisées. Exemple :
Le type de codice_20 est un type interne de la bibliothèque surchargé environ quatre-vingts fois avec un script Perl. Trouver le type exact pour stocker le résultat d'un codice_21 dans un objet n'était pas pratique du tout avant le nouveau rôle du mot clé codice_18, d'où son apparition.
Le nouveau standard ajoute le mot clé codice_23 qui permet de typer une variable à partir du type d'une autre variable. Exemple:
Le type de codice_24 sera du même type que codice_25, soit codice_26. Cette déclaration automatique du type d'une variable peut être très utile dans les templates.
Sémantique des RValues Reference/Move.
L'introduction de la sémantique "move" (déplacement) prend son sens en constatant qu'en C++, il n'y a aucune manière générique de déplacer un objet sans le copier. Par exemple lorsqu'une fonction retourne un objet de grosse taille, celui-ci est copié dans une zone temporaire avant d'être à nouveau copié là où le résultat de la fonction est affecté. Après chaque étape de copie l'objet copié devient inutile et est détruit. Cela est très peu efficace car il serait beaucoup plus rapide de déplacer l'objet plutôt que de le recopier et détruire l'original. C'est particulièrement vrai si l'objet est d'un type proche du type codice_27 ci-dessous, où codice_28 est un type d'objet coûteux à dupliquer :
En effet le déplacement d'un objet de ce type codice_27 requiert simplement la recopie du membre codice_30 alors que sa duplication alloue et copie un nouvel objet codice_28. Le problème que résout C++11 par l'ajout des RValues reference est de pouvoir appeler la fonction codice_32 en lieu et place du constructeur de recopie dans les cas où la copie correspond à un déplacement.
Ceci s'obtient par l'ajout du constructeur de déplacement ci-dessous :
Le double & marque la référence sur "rvalue" (parfois aussi appelée "temporaire"). C'est-à-dire une référence sur quelque chose qui est temporaire ou est sur le point d'être détruit. Le constructeur de déplacement sera donc choisi par le compilateur à la place du constructeur de recopie en cas de copie d'un objet temporaire ou sur le point d'être supprimé. Sur tous les autres aspects une référence sur une rvalue est identique à une référence classique maintenant appelée référence sur "lvalue" (que l'on peut définir grossièrement par : tout ce qui a une adresse).
De cette définition ressort un fait qui peut sembler paradoxal : une variable de type référence sur une rvalue n'est généralement pas une référence sur une rvalue ! En effet à partir du moment où une référence sur une rvalue est écrite dans une variable, y compris si elle est de type référence sur rvalue, elle perd son caractère temporaire dans l'espace de définition de cette variable.
Mais parfois il est utile d'appeler le constructeur de déplacement même à partir d'une variable qui n'est pas temporaire. Par exemple la commande "swap" est souvent introduite par le patron de fonction ci-dessous :
Cette fonction a pour inconvénient d'appeler d'abord le constructeur de recopie, puis deux opérateurs d'assignation. Ce sont donc 3 copies au total, qui peuvent être des opérations extrêmement coûteuses, voire impossibles si les objets impliqués sont de taille importante. Ici le constructeur de déplacement n'est pas appelé car a, b et c comme source de la copie ne sont pas temporaires.
C++11 introduit la fonction codice_33 qui retourne une référence à une rvalue et prend pour paramètre une référence à une lvalue ou à une rvalue. Son patron est le suivant :
La fonction codice_34 donne à ce qu'il retourne la valeur de son paramètre. La fonction move ne modifie pas l'objet qui lui est passé mais reçoit et fourni une référence sur un objet non constant. L'objet d'origine peut donc être modifié à partir du résultat de la fonction codice_34. Le point important de "move" est qu'il n'y a aucune copie de faite. En utilisant "move", on peut ainsi réécrire de façon concise codice_36, sans qu'il n'y ait de copie.
Énumérations fortement typées.
L'énumération du langage C était similaire à une liste de définitions de symboles (macros) correspondant à des nombres entiers, et C++ n'avait répondu qu'en interdisant la conversion d'un type énumération dans un autre.
C++11 proposera des énumérations « fortement typées ». Ces énumérations seront obtenues en remplaçant codice_37 par codice_38 ou codice_39.
La conversion d'éléments de ces énumérations vers les entiers sera prohibée et l'accès aux éléments se fera à l'aide de l'opérateur de résolution de portée. Voici un exemple d'utilisation :
L'opérateur de résolution de portée sera optionnel avec des énumérations faiblement typées :
De plus, C++11 vous permettra de choisir le type d'entier sous-jacent des énumérations (tous sauf codice_40):
Par défaut, ce type sera codice_26.
Ce comportement sera aussi possible avec les énumérations normalement typées, et il sera bien sûr toujours possible de définir la valeur d'une partie de l'énumération :
Boucles basées sur des intervalles.
Le code nécessaire en C++ pour le parcours d'un intervalle et l'action sur ses éléments est répétitif et long. De nombreux langages, comme Java, ont fourni à leurs utilisateurs un opérateur codice_42 qui permet de parcourir une liste avec aisance. Pour répondre aux attentes, la norme C++11 fournira une nouvelle syntaxe de l'instruction codice_43 qui s'implémentera de cette façon :
Ce code permet de doubler tous les éléments du tableau codice_44. L'entier codice_45 défini pour le corps de la boucle codice_43 référence successivement chacun des éléments du tableau.
Ce type de parcours fonctionnera pour les listes classiques, les listes d'initialiseurs, ainsi que les conteneurs de la STL définissant les fonctions membres codice_47 et codice_48.
Pointeur codice_49.
Le nouveau mot-clé codice_50 a été proposé comme constante du langage avec le caractère particulier d'être assignable à tous les types de pointeurs. En effet, contrairement au C où la macro préprocesseur est généralement définie avec codice_51, en C++ il est interdit d'assigner un codice_52 à un pointeur d'un type différent. L'usage était donc de définir codice_49 avec l'entier 0. Ce comportement restera compatible, mais il sera aussi possible d'écrire :
La constante NULL définie comme l'entier 0 ne permettait pas au compilateur de déterminer quelle surcharge de codice_20 choisir dans le code suivant:
Le mot clé codice_50 est une constante du type codice_56, non convertible en entier. Pour appeler la fonction f avec un pointeur NULL, la surcharge est correctement choisie en C++11 dans le code suivant:
Extension de la bibliothèque standard.
Threads.
La bibliothèque standard a implémenté dans la nouvelle norme du C++, le modèle de classe std::thread, celui-ci n'est qu'une implémentation des threads de la bibliothèque Boost.
Voici, un exemple résumant quelque peu son utilisation:
Type tuple.
Un tuple (ou encore isplate) est une collection de dimension fixe d'objets de types différents. Tout type d'objet peut être élément d'un tuple.
Cette nouvelle fonctionnalité est implémentée dans un nouvel en-tête et bénéficie des extensions de C++11 comme :
Le patron de classe codice_6 est déclaré par la ligne :
Un exemple de définition et d'utilisation du type codice_6 :
Il est possible de créer le tuple codice_59 sans définir son contenu si les éléments du tuple possèdent un constructeur par défaut. De plus, il est possible d'assigner un tuple à un autre tuple : si les deux tuples sont de même type, il est nécessaire que chaque élément du tuple ait un constructeur par copie, sinon il faut que le type de chaque élément de l'opérande de droite soit compatible avec le type correspondant dans l'opérande de gauche ou que l'élément correspondant de l'opérande gauche ait un constructeur approprié.
Les opérateurs relationnels sont disponibles (pour les tuples ayant le même nombre d'éléments).
Deux expressions sont introduites pour vérifier les caractéristiques d'un tuple (à la compilation) :
Table de hachage.
Intégrer les tables de hachage (conteneurs associatifs non ordonnés) dans la bibliothèque standard du C++ est l'une des demandes les plus récurrentes.
Cela n'avait pas été réalisé pour la norme actuelle (celle écrite en 1995 et approuvée en 1998) à cause des contraintes de temps.
Bien que cette solution soit moins efficace que les arbres équilibrés dans le pire des cas (en cas de collisions importantes), elle est cependant la meilleure dans la plupart des applications réelles.
Les collisions seront uniquement gérées par chaînage linéaire car le comité ne considère pas opportun de standardiser des solutions d'adressage ouvert qui introduisent un nombre important de problèmes intrinsèques (en particulier quand la suppression d'éléments est permise).
Pour éviter les conflits de noms avec les bibliothèques non standards qui ont leur propre implémentation des tables de hachage, on utilisera le préfixe codice_65, au lieu de codice_66.
Cette nouvelle fonctionnalité intégrera quatre types de tables de hachage, différentes selon qu'elles acceptent ou non des éléments de même clé (clé unique ou clé équivalente) et qu'elles associent chaque clé à la valeur associée.
Ces nouvelles classes remplissent toutes les demandes des classes de conteneurs et contiennent toutes les méthodes nécessaires pour accéder aux éléments : codice_67, codice_68, codice_47, codice_48.
Ces classes n'ont pas nécessité les nouvelles extensions du langage C++ mais seulement une légère extension du header codice_71 et l'introduction des headers codice_72 et codice_73. 
Aucun autre changement aux classes de la norme actuelle n'est nécessaire et elles ne dépendent d'aucune autre extension de la bibliothèque standard.
Expressions régulières.
La bibliothèque définie dans le fichier d'en-tête codice_74 est fait d'un ensemble de nouvelles classes :
La fonction codice_77 est utilisée pour une recherche.
codice_78 est utilisée pour effectuer un "chercher-remplacer", elle renvoie pour cela une nouvelle chaîne.
Les algorithmes codice_77 et codice_78 prennent une expressions régulières et une chaîne et écrivent les occurrences trouvés dans la structure codice_76.
Voici, un exemple d'utilisation de codice_76:
Notez l'utilisation du double backslash, car le C++ utilise le backslash comme un caractère d'échappement. Les chaînes littérales en C++11 peuvent permettre d'éviter le problème.
L'utilisation de la bibliothèque codice_74 ne requiert aucune dépendance explicite.
Amélioration des nombres aléatoires extensibles.
La bibliothèque standard de C permet de générer des nombres pseudo-aléatoires grâce à la fonction codice_84. L'algorithme de génération n'est pas standardisé mais laissé au choix du fournisseur de la bibliothèque. Le C++ n'y a rien changé, mais C++11 va fournir une manière différente de générer les nombres pseudo-aléatoires.
Cette fonctionnalité est découpée en deux parties qui forment un objet de génération de nombres aléatoires :
C++11 définit trois algorithmes de génération, chacun ayant des avantages et des inconvénients.
C++11 fournira un certain nombre de lois standard : codice_85, codice_86, codice_87, codice_88, codice_89, codice_90, codice_91, codice_92 et codice_93.
Le générateur et la distribution se combinent comme dans l'exemple suivant :
Fonctions mathématiques spéciales.
Le fichier header codice_94 définit déjà plusieurs fonctions mathématiques usuelles :
Le comité a décidé d'ajouter de nouvelles fonctions qui nécessitent actuellement l'utilisation de bibliothèques non-standards.
Ces nouvelles fonctions auront un intérêt principalement pour les programmeurs de disciplines scientifiques et pour l'ingénierie.
Le tableau suivant montre les 23 fonctions décrites dans TR1.
Chacune de ces fonctions possède deux variantes supplémentaires. En rajoutant le suffixe ‘f’ ou ‘l’ au nom de la fonction, on obtient les mêmes fonctions agissant sur des codice_126 ou des codice_127 respectivement. Par exemple :

</doc>
<doc id="6615370" url="http://fr.wikipedia.org/wiki?curid=6615370" title="Object-PL/SQL">
Object-PL/SQL

Object-PL/SQL (Object-Procedural Language/Structured Query Language ou tout simplement O-PL/SQL) est une méthodologie d'usage de l'extension procédurale pour le langage SQL dans la Base de Données Oracle. Les particularités additionnelles de la version 7 au-delà d'autres améliorations ultérieures sont orientées vers l'usage du paradigme de la base de données orientée objet.
Bien que la syntaxe générale du langage PL/SQL ressemble à celle du Pascal et de l'Ada, il y a eu beaucoup d'améliorations, qui incluent surtout le "code java intégré" et la "syntaxe orientée objet" dans le SQL.
L'intégration de déclencheurs et de procédures stockées constituent conjointement une des plus grandes percées qui ont favorisé l'usage du PL/SQL dans un paradigme orienté objet. L'inclusion pour le syntaxe SQL de déclarations comme ., et aussi l'implementation de l'objet "type" (similaire à presque tous les langages OO), ont complété le minimum d'articles nécessaires pour la démarche d'une extension du SQL sans l'usage d'aucun logiciel particulier de projection ou "persistence framework" .
Autonomie, notorieté et importance de l'O-PL/SQL.
L'O-PSL/SQL n'est pas simplement l'usage d'une version d'un langage de programmation, mais c'est le "modus faciendi" qui définit l'autonomie du thème Chacune des versions du PL/SQL, en débutant de la , apporte de si nombreuses innovations que c'est impossible de traiter ces usages-ci de sub-thèmes du PL/SQL. Il y a eu une vraie révolution qui a établi la frontière entre le langage usé jadis et l'aspect orienté objet dans ce nouveau langage. C'est précisément cet abord qui a provoqué l'emploi à large échelle de l'O-PL/SQL.
Une confusion d'objets.
On ne doit pas confondre les notions d'"objet de base de données" avec celles-là d'"objet de classe". Il faut, en chaque situation, identifier qu'est-ce que c'est un "objet" dans un contexte donné.
"Objet de base de données" est un concept qui concerne la base de données relationnelle ou séquentielle et qui est utilisé dans les nouveaux modèles. "Tables", "déclencheurs", "colonnes", "indices" sont des exemples d'objets de base de données qui sont rencontrés dans Object-PL/SQL, mais les mêmes éléments peuvent être traités dans l'autre contexte, de la notion des objets Java, spécifiquement un élément d'un ensemble dont le début de son existence se passe à partir de l'"instanciation" d'une classe.
The PL/SQL.
le PL/SQL est le langage SQL étendu utilisé par la Base de données Oracle.
PL/SQL est disponible dans l'Oracle (depuis version 7) et dans l'IBM DB2 (depuis version 9.7).
O-PL/SQL permet de définir des classes et les "instancier" comme objets, de créer des types de données définis par l'utilisateur (programmateur) et "constructeurs", au-delà d'écrire des procédures stockées et des déclencheurs en Java, et aussi de la création de types "user-defined" et de constructeurs.
Exemples d'usage de la syntaxe de l'O-PL/SQL.
Il y a ici un petit ensemble d'exemples extraites de la documentation officielle et d'autres sources:
Exemple 1.
Un exemple simple d'"object-oriented PL/SQL"
Maintenant, la codification du type est accomplie. Donc, il est défini comment se conduisent-ils les fonctions de type, les procédures et les constructeurs:
On est prêt à dériver de "base_type". Le mot-clé "under" est utilisé pour la dérivation. Le type dérivé definit un nouveau attribut (nommé "m"), qui superpose "func".
Bien comme les types bases, il faut codifier les méthodes superposées au type dérivé:
Les types créés peuvent être instanciés et les méthodes peuvent être demandées:
Résultats
Les types créés sont devenus des types "réels" et on les peut utiliser pour attributs dans tables:
Résultats:
Résultat:
Exemple 2.
Un autre exemple de procédure stockée en Java intégré est rencontré dans Oracle Documentation.
Liens externes.
Examples d'O-Pl/SQL

</doc>
<doc id="6671779" url="http://fr.wikipedia.org/wiki?curid=6671779" title="Tea (langage de programmation)">
Tea (langage de programmation)

Tea est un langage de script pour l'environnement Java inventé par Jorge Nunes en 1997. 
Il combine les fonctionnalités de Java, Scheme et Tcl.
Caractéristiques.
Tea est un langage de programmation fonctionnel intégrant les fonctions comme objets.
Exemples.
Une fonction carré :
Une liste :
Un objet cercle :

</doc>
<doc id="6696997" url="http://fr.wikipedia.org/wiki?curid=6696997" title="Liste d'instructions">
Liste d'instructions

La liste d'instruction, ou (IL) en anglais, est un des cinq langages de programmation pour automates programmables industriels (API) définis par la norme CEI 61131-3. C'est un langage de bas niveau, comparable à l'assembleur.
Langages dérivés.
Siemens propose, pour programmer ses API, un langage dérivé d'IL appelé ' (STL) en anglais, et ' (AWL) en allemand.

</doc>
<doc id="6719375" url="http://fr.wikipedia.org/wiki?curid=6719375" title="Rust (Mozilla)">
Rust (Mozilla)

Rust est un langage de programmation compilé multi-paradigme expérimental développé par Mozilla Research. Il a été conçu pour être « un langage sécurisé, concurrent, pratique », supportant les styles de programmation purement fonctionnelle, modèle d'acteur, procédurale et orientée objet.
Le langage s'est développé à partir d'un projet personnel du développeur en chef Graydon Hoare, qui commença à travailler dessus en 2006. Son employeur Mozilla commença sa participation en 2009 et révéla officiellement leurs travaux pour la première fois en 2010. La même année, le projet passa du compilateur initialement utilisé (écrit en OCaml) au compilateur auto-hébergé écrit en Rust. Ce compilateur, connu sous le nom de "rustc", s'est compilé avec succès en 2011. Le compilateur auto-hébergé utilise LLVM pour son Backend.
La première version alpha numérotée du compilateur Rust apparait en janvier 2012. La version actuelle est la version 0.9, sortie en janvier 2014.
De par la politique de Mozilla, Rust est entièrement développé de façon ouverte (les ingénieurs de Mozilla Research publient leurs idées et les décisions prises lors des meetings) et sollicite les remarques et contributions de la communauté. La conception du langage est graduellement améliorée au travers des retours de l'équipe travaillant sur le moteur de rendu Servo et de façon pragmatique lors de l'écriture du compilateur.
Points forts.
Rust repose sur des concepts connus et éprouvés (d'où le nom "Rust", « la rouille » en anglais) et n'intègre pas de concepts nouveaux et non testés. Ces concepts ont été empruntés à des langages de programmation existants et assemblés dans un seul langage :
Rust est souvent décrit comme l'un des successeurs potentiels de C++ (avec D et, dans une moindre mesure, Go) notamment grâce à sa sûreté — c'est un objectif clairement affiché par les développeurs.
Exemples de code.
Le classique Hello World, valide avec la version 0.8:

</doc>
<doc id="6734198" url="http://fr.wikipedia.org/wiki?curid=6734198" title="Dependency Constraint Language">
Dependency Constraint Language

En informatique, le langage DCL (Dependency Constraint Language) permet de localiser dans le code source d'un logiciel des décisions d'implémentation qui représentent des violations à l'architecture décrite au départ.
Il permet de contrôler deux types de violations :
Utilisation.
Le langage DCL spécifie quatre primitives pour définir les contraintes :
Il se complète par d’autres primitives pour des besoins spécifiques : access, declare, create, extend, implement, throw, annotate.

</doc>
<doc id="6413486" url="http://fr.wikipedia.org/wiki?curid=6413486" title="HaXe">
HaXe

Haxe est un langage de programmation développé par Nicolas Cannasse et la société Motion-Twin qui, dans le cadre d’une utilisation pour le Web, permet d’écrire la partie serveur et la partie client dans un même langage.
À cette fin, Haxe permet de :
Haxe permet donc d'assurer l’interopérabilité entre ces différentes plateformes en fournissant des bibliothèques communes.
Il permet, par ailleurs, de créer du code C++, et des cibles Java et C# sont en préparation (courant 2012 - 2013) .
Voir aussi.
Liens internes.
Neko (langage)

</doc>
<doc id="3716608" url="http://fr.wikipedia.org/wiki?curid=3716608" title="MMIX">
MMIX

MMIX, prononcé et usuellement typographié dans une police à chasse fixe (), est à la fois un jeu d'instructions 64-bit RISC et une architecture informatique conçu par Donald Knuth, avec une aide importante de , un des concepteurs de l'architecture MIPS, et de Richard L. Sites, un des concepteurs de l’architecture Alpha. Knuth lui-même présente ce projet en ces mots :
Architecture.
En termes d’architecture informatique est un ordinateur RISC 64 bits, avec 256 registres 64 bits généraux et 32 registres 64 bits à usage spécifique. est une machine gros-boutiste avec des instructions 32 bits et un 64 bits. Son jeu d'instructions comprend 256 codes opérations, dont un est réservé pour un potentiel usage futur. Les nombres à virgule flottante sont implémentés conformément au standard IEEE 754.
Instructions.
Les instructions de sont toutes définies et utilisables à partir de leur code opération, qui est un nombre d’un octet, généralement noté sous forme hexadécimale. Cependant pour améliorer la lisibilité du code assembleur, une étiquette mnémotechnique unique est associé à chacun des codes. Ainsi l’étiquette est équivalente à l’instruction numéro , qui est le code opérateur de l’addition.
La plupart des instructions sont de la forme "opérateur X Y Z", où "opérateur" spécifie l’instruction, X est un registre servant d’accumulateur, c’est-à-dire utilisé pour stoker le résultat de l’instruction, et Y et Z désignent les registres servant d’opérandes à l’instruction. Par exemple signifie "affecter à la Somme (arithmétique) du nombre stocké dans le registre et du nombre ".
La plupart des instructions peuvent prendre soit des valeurs immédiates, soit utiliser le contenu d’un registre ; ainsi un seul mnémonique peut correspondre à un ou deux codes opérations.
Typiquement, les programmes sont construits en utilisant le langage assembleur . L’exemple ci-dessous est un programme écrit en qui affiche Hello world :
Registres.
Dans une puce d’architecture il y a 256 registres généraux ,
auxquels on accède par le référence noté de à et 32 registres spéciaux. Deux des registres spéciaux, et , déterminent quels sont les registres locaux et lesquels sont globaux. Tous les registres, de à sont des registres locaux. Les registres de à [rG-1 sont des "registres marginaux" qui retournent toujours 0 s'ils sont utilisés comme source dans une opération. Utiliser un registre marginal en tant que destination d’une opération déclenchera une incrémentation automatique de pour inclure ce registre. Tous les registres de à sont appelés registres globaux et ne sont pas sauvegardés sur la pile de registre.
Pile de registre local.
La pile de registre local fournit à chaque procédure ses propres registres locaux , notés de à . Si une procédure est appelée, les registres locaux sont ajoutés sur la pile. Les arguments de la procédure sont placés dans les registres locaux restants. Quand une procédure se termine, elle retire les registres précédemment ajoutés. Comme il n’y a que 256 registres physiques, il peut être nécessaire de stocker une partie de la pile en mémoire. Cette action est implémentée avec les registres spéciaux et qui enregistrent quelle partie de la pile de registre local est en mémoire et quelle partie est toujours dans les registres physiques locaux. Le registre de pile assure également la .
Registres spéciaux.
Les 32 registres spéciaux de l’architecture physique sont définis comme suit :
Implémentation matérielle.
Il n’existe actuellement aucune implémentation matérielle de l’architecture à jeu d’instruction . Cependant, le projet fpgammix fournie implémente une implémentation Verilog, ce qui ouvre la possibilité de l’utiliser dans un circuit logique programmable.
Outils logiciels.
L’architecture de jeu d’instruction est utilisable à travers tout une panoplie d’outils logiciels pour la recherche en développement logiciel et en architecture d’ordinateur.
Simulateurs et assembleurs.
Knuth a développé un ensemble de logiciels nommé MMIXware comprenant un simulateur comportemental simple de la machine, et MMIXAL, un logiciel d’assemblage, une suite de tests, des programmes d’exemples, une documentation complète, et un simulateur de pipeline de l’architecture .
Andrew Pochinsky, membre de l’équipe du centre de recherche théorique en physique du à développé MMIXX un paquet implémentant un serveur graphique basé sur X11. Elle peut être combiné avec la machine virtuelle de pour fournir un affichage de 640×480 pixes en vrai couleur pour Linux et UNIX.
Compilateur.
Le projet ' (GCC) comprend une partie envers de pour ses compilateurs C/C++, initialement développé par Hans-Peter Nilsson, et qui fait partie de la distribution standard du projet depuis la fin 2001. Il continue d’être activement développé et maintenu par des volontaires.
L’ensemble des outils existant devraient théoriquement permettre de compiler, construire et amorcer un noyau de système d’exploitation comme Linux sur un processeur si une implémentation matériel venait à exister.

</doc>
<doc id="306482" url="http://fr.wikipedia.org/wiki?curid=306482" title="REALbasic">
REALbasic

REALbasic, est un langage de programmation inspiré du Visual Basic 6 de Microsoft qui fonctionne sur Mac OS X, Windows et Linux. "REALbasic" fut créé par Andrew Barry. Il s'appelait originellement CrossBasic (cross=transversal) car il était capable de compiler le même code de programmation pour Mac et Java (le système de développement était uniquement sur Mac). En 1997, CrossBasic fut racheté par FYI Software qui changea son nom en REALbasic tandis que la société s'appela REAL Software. Suite à ceci, la version Java fut abandonnée.
Généralités.
REALbasic, est le langage de l'environnement de développement Real Studio. Ce langage de programmation s'inspire du visual basic 6 de Microsoft. Il en est cependant une version moderne. Il est totalement orienté objet, typé et multi thread. Cet outil de développement fonctionne sur Mac OS X, Windows et Linux, et est capable de compiler des logiciels pour les mêmes plateformes, sous réserve d'avoir acheté la version Pro.
Actuellement, c'est la version 2011 R4 qui est commercialisée. Cet outil de développement permet notamment de générer des applications pour Mac au format Universal Binary, Intel ou Power PC. REALbasic est pratique, il permet de développer facilement et rapidement, et surtout pour plusieurs plateformes ce qui évite de redévelopper plusieurs fois les mêmes applications. En fonction de la complexité de ses dernières, on ne pourra cependant se passer de vérifier la compatibilité et surtout la pertinence de votre code (notamment de l'interface utilisateur) avec tous les systèmes. RealBasic offre heureusement la possibilité de faire varier le code en fonction de la plateforme cible.
Realbasic permet de développer des applications consoles, graphiques ou web.
Il est disponible en 4 versions : personnelle, professionnelle, entreprise et web.
Base de données.
Ce langage inclut des connecteurs aux bases de données les plus répandus : sqlite, mysql, oracle, Microsoft Sql Server, ODBC...
Les utilisateurs de la version personnelle devront cependant se contenter de sqlite et mysql community edition.
Enrichissement du langage par plug'in.
Il existe toute sorte de modules du gratuit jusqu'à plusieurs milliers d'euros qui vous permettrons d'enrichir les fonctionnalités du langage.
C'est d'ailleurs à la fois un avantage et un inconvénient. Si bien évidemment l'enrichissement du langage par module permet d'ouvrir de nouvelles perspectives elles augmentent considérablement le cout de votre solution de développement. Or un des grands avantages de RealBasic c'est le prix : HT pour la version personnelle et HT pour la version professionnelle. Si l'on est tenté d'acheter des modules supplémentaires le cout totale peut vite atteindre le même niveau que des environnements de développement ultra professionnel contre qui realbasic aura du mal à lutter.
L'achat de modules n'est pas non plus indispensable car RealBasic est très complet, cela constitue néanmoins un option intéressante et viable dans certains cas.
Facilité de déploiement chez le client.
Un des très grand avantages de ce langage c'est que l'application qu'il génère ne nécessite aucune installation sur l'ordinateur de l'utilisateur final. Les applications RealBasic fonctionnent donc parfaitement sur une clef USB. C'est une des raisons principale du succès de ce langage.
On peut déposer par copier coller l'application n'importe où sur un disque externe ou interne : elle fonctionnera de façon identique.
Deboguage à distance.
Avec RealBasic vous pouvez deboguer une application qui s'exécuterai sur un poste distant depuis votre poste de développeur.
Cela permet de cerner et de résoudre plus rapidement et facilement les problèmes.
Liens avec pack office de Microsoft.
Si vous optez pour la version Windows vous aurez à votre disposition des contrôles qui vous permettrons de piloter Excel, Word et PowerPoint.
il vous sera donc possible par exemple de générer des document excel avec realbasic.
GUI (Graphic User Interface) et Code.
Dans REALbasic on peut noter deux grandes interfaces notables. Le code et l'interface graphique, en anglais le 'Graphic User Interface'. Le principal système de l'interface graphique est le système de 'drag & drop' (Glissez et déposer) qui s'avère être très simple. Il suffit de glisser les outils vers une fenêtre qui représente votre programme.
L'intégration du code dans la GUI est extrêmement bien faite et surpasse dans ce cadre beaucoup d'autres outils de développement plus onéreux. La façon dont les fonctions, procédures, classes, module, variables ... sont visualisés permet non seulement de mieux concevoir le projet, mais elle apporte aussi une vision claire de la structure de chaque éléments. Il devient ainsi plus facile de reprendre un programme que l'on a laissé de côté plusieurs mois ou de lire le code d'un autre programmeur.
Exemple de code.
Voici un exemple de surcharge d'opérateur pour une hypothétique classe de nombre complexe afin d'additionner un nombre réel ou complexe à un autre nombre complexe :
La même fonction peut être définie pour accepter des nombres en double précision. Ce code montre comme utiliser cette classe de complexe pour additionner un réel à un complexe :
Types de projets envisageables.
Realbasic fera des merveilles pour les personnes qui désirent développer des applications de saisies de données standard. On développera avec des programmes de gestion de fichiers clients, des gestions de compte bancaire ou de documents comptables, interrogations de bases de données etc... Il conviendra aussi bien au développeur de shareware qu'à l'informaticien d'une PME qui désire développer des applications internes. Les difficultés surviendrons plutôt lorsque l'on voudra développer des applications qui nécessitent la collaboration de beaucoup de développeurs ou des projets ambitieux. Realbasic n'est pas reconnus comme un outil majeur dans le monde du développement. Il n'est pas facile par exemple d'éditer des états papiers très complexes ( étiquettes avec images etc... ). Le programmeur devra donc avoir un recours plus grand à la ligne de code pour rivaliser avec des logiciels qui ont été développés avec des outils plus puissants ( Visual studio, Windev etc...).
Il existe cependant une vieille controverse chez les programmeurs pour qui le basic est longtemps resté synonyme de langage de débutant. Soyons clair il n'existe pas de logiciel poids lourds de l'informatique développé en basic. Mais ce type de langage a fortement bénéficié de l'évolution de puissance des ordinateurs et on ne peut plus dire de nos jours que programmer en basic constitue un désavantage. Le développeur basic recherche la simplicité du langage et veut un résultat rapide souvent dans le cadre d'un projet à l'ambition moyenne. RealBasic ne requiert pas la même technicité que le c++, c sharp ou objective c, ni le même investissement intellectuel. Il cherche simplement à proposer un outil généraliste et efficace dans les projets les plus communs. En s'appuyant sur une interface utilisateur très ergonomique, realbasic s'éloigne des basics des années 1980 avec qui finalement il ne partage plus rien.
Realbasic est actuellement l'une des très rares solutions de développement multiplateforme très facile d'accès autant au niveau de l'utilisation qu'au niveau du prix.
Un potentiel pédagogique important.
RealBasic conviendra aussi aux professeurs qui enseignent la programmation dans les collèges et lycées par le fait qu'il permet par un apprentissage rapide d'accéder à des préceptes de programmation avancés. Le professeur pourra donner à ses élèves le goût de la programmation. Ces derniers pourront en quelques heures s'étonner de leur création. L'avantage est double : les élèves ne sont pas découragés et la durée d'apprentissage étant réduite, il reste plus de temps pour se concentrer sur les objectifs à atteindre.
Un système communautaire intégré.
RealBasic inclut un système ingénieux (et gratuit) de rapport d'erreur. Si l'on rencontre un bogue dans realbasic, si l'on souhaite une évolution ou si l'on désire partager des idées, on peut utiliser "Feedback". Il s'agit d'un logiciel qui met en contact avec la communauté (anglophone) de realbasic. Les ingénieurs de Real software scrutent les questions et y répondent quand cela est nécessaire.
Rythme et cout des mises à jour.
Real Software procède à une mise à jour majeure par an. Puis au cours de l'année le produit évoluera par une mise à jour mineure (correction de bugs) tous les 90 jours environ. L'achat d'une licence entraine 6 mois de mises à jour gratuites. Passé ce délai les mises à jour seront payantes.
En fait l'utilisateur devra souscrire s'il veut bénéficier des évolutions du produits d'un plan de mise à jour pour une durée de une à deux années (renouvelable). Le coût des mises à jour est d'environ à par an pour la version personnelle, par an pour la professionnelle et par an pour la version entreprise.

</doc>
<doc id="7029317" url="http://fr.wikipedia.org/wiki?curid=7029317" title="TMG (langage)">
TMG (langage)

Le TMG est un compilateur de compilateur créé par Robert M. McClure et présenté à l'Association for Computing Machinery en 1968, implémenté par Douglas McIlroy. TMG fonctionnait en particulier sur OS/360 et les premiers systèmes UNIX, et fut utilisé pour créer l'EPL, une version primitive du langage PL/I.
En 1970, Ken Thomson voulut écrire un compilateur de fortran en TMG sur un PDP-7, mais créa à la place le langage B, précurseur du langage C fortement influencé par le BCPL.

</doc>
<doc id="7044700" url="http://fr.wikipedia.org/wiki?curid=7044700" title="Concurrent C">
Concurrent C

Le concurrent C est une extension du langage de programmation C développée aux laboratoires Bell d'AT&T en 1984. Elle a pour but de faciliter l'implémentation d'algorithmes parallèles en C, qui ne supporte la programmation concurrente que par le biais d'extensions (même si certaines, comme les Threads POSIX, sont très répandues).
Description.
Le concurrent C est compatible avec le C (la plupart des programmes écrits en C sont valables en concurrent C). S'inspirant de l'Ada, le concurrent C permet la communication inter-processus entre les threads par échange de données synchrone : l'émetteur est bloqué par les fonctions de communication inter-processus tant que le récepteur n'a pas lu les données transférées.
Il était implémenté par AT&T sous la forme d'un préprocesseur, qui produisait du code en C ensuite compilé normalement.

</doc>
<doc id="1806643" url="http://fr.wikipedia.org/wiki?curid=1806643" title="F Sharp">
F Sharp

F♯ est un langage de programmation fonctionnel, impératif et orienté objet pour la plate-forme .NET. F♯ est développé par Microsoft Research dont le noyau est dérivé du langage OCaml (avec lequel il est fortement compatible). Ces deux langages de programmation font partie de la famille des langages ML.
C'est un langage qui a été conçu spécifiquement pour la plate-forme .NET et est donc fortement orienté-objet. Depuis novembre 2010, Microsoft a mis à la disposition de tous les bibliothèques core et son compilateur F♯, sous la licence Apache 2.
Présentation.
F♯ est un langage fortement typé utilisant l'inférence de types. Ce mécanisme délègue le typage des variables et des fonctions au compilateur. Néanmoins, le langage permet au développeur d'indiquer explicitement le type à la déclaration. Intégré à l'écosystème .NET, F♯ supporte les types primitifs de la plate-forme ainsi que ses objets. De plus il étend le système de type et permet de faire la distinction entre les types dits immuables et ceux dits modifiables. Les objets sont considérés comme des types modifiables (en place), et sont utilisés pour la mise en place du modèle de programmation objet au sein du langage. Les types immuables sont utilisés principalement lorsque l'on programme de manière fonctionnelle ; la modification d'un type immuable crée une nouvelle instance sans pour autant écraser l'ancienne.
Comme tous les langages dérivé de ML, F♯ utilise par défaut le mécanisme de l'évaluation stricte. Cependant il peut, à l'instar de Haskell, mettre en œuvre l'évaluation paresseuse des expressions grâce à l'utilisation du mot-clé codice_1. Pour la programmation fonctionnelle, il fournit plusieurs constructions et un ensemble de types immuables : les n-uplets, des enregistrements, des types sommes et des listes.
Un n-uplet représente une collection de n valeurs, n ≥ 0. La valeur correspond à l'arité du n-uplet. Le type unit représente le n-uplet vide et dont l'unique valeur possible est (). Ce type est utilisé pour typer des fonctions qui ne prennent pas en entrée de valeur et/ou n'en renvoient pas. Le 3-uplet (ou triplet) est représenté par codice_2, où A, B, et C peuvent être de n'importe quel type. Un n-uplet peut être utilisé pour stocker des valeurs uniquement lorsque le nombre de valeurs est connu au moment du codage et reste constant tout au long de l'exécution.
Un enregistrement est une version spécialisée des n-uplets où les champs sont nommés, comme dans . Les enregistrements peuvent être créés de la façon suivante : codice_3. Le mot-clé codice_4 est utilisé pour créer une copie de l'enregistrement : codice_5 crée un nouvel enregistrement à partir d'un précédent enregistrement nommé r et dont il change la valeur du champ Nom.
Le type liste est une liste chainée qui peut se représenter soit à l'aide de la notation codice_6 (composé à l'aide de l'opérateur codice_7, l'équivalent de l'opérateur cons des langages Lisp/Scheme), soit dans une notation abrégée : codice_8. Une liste vide est notée codice_9.
La dernière sorte de type algébrique de données, les types sommes (qui sont, fonctionnellement, des équivalents typés des unions du langage C) peuvent être définis comme une somme de n'importe lequel des types immuables évoqués précédemment. Par exemple,
peut contenir des valeurs instanciées soit par codice_10 soit par codice_11. Le type des valeurs retournées par les constructeurs peut lui aussi être défini.
Exemples.
Voici le traditionnel hello world :
Cet autre exemple traditionnel chez les langages fonctionnels a pour objectif de montrer la concision que l'on peut obtenir avec ce type de langages :
Cette variante, avec un accumulateur, met en œuvre la récursion terminale, une optimisation commune parmi les langages fonctionnels :

</doc>
<doc id="7081003" url="http://fr.wikipedia.org/wiki?curid=7081003" title="SETL">
SETL

SETL fournit deux types de données de base : Les "ensembles non ordonnés" et les "suites" (appelées également "tuples"). Les éléments des ensembles et des tuples peuvent être de n'importe quel type arbitraire, y compris les ensembles et les tuples eux-mêmes. Le "fonctions" sont fournis en tant qu'ensembles de "paires" (c.-à-d., tuples de longueur 2) et peuvent avoir des domaines et de codomaines de types arbitraires. Les opérations primitives dans SETL incluent, entre d'autres, l'appartenance ensembliste, l'union, l'intersection et la puissance d'ensembles. SETL permet d'exprimer des expressions booléennes quantifiées construites en utilisant le calcul des prédicats du premier ordre, les quantificateurs universels et quantificateurs existentiels. SETL fournit aussi plusieurs itérateurs pour produire diverses boucles sur des structures de données. 
Échantillon de code.
Retourner tous les nombres premiers inférieurs à n : 
La notation est semblable à la compréhension de liste.
Historique.
ABC, le précurseur de Python, a été inspiré par SETL à , qui a passé une année avec le groupe de SETL à NYU avant de proposer la version finale d'ABC.

</doc>
<doc id="7085138" url="http://fr.wikipedia.org/wiki?curid=7085138" title="MapBasic">
MapBasic

MapBasic est un langage de programmation utilisé pour la création d'outils et de fonctionnalités pour la suite logicielle (SIG) MapInfo. MapBasic est basé sur la famille de langages de programmation BASIC.
MapBasic est intégrable dans des programmes développés dans des langages tels que Visual Basic, C ou encore C++.

</doc>
<doc id="7094718" url="http://fr.wikipedia.org/wiki?curid=7094718" title="C++14">
C++14

C++14 est le nom de la prochaine norme du langage C++. Elle est annoncée comme une mise à jour mineure du langage, faisant suite à la norme de 2011 connue sous le nom de C++11.
Une mise à jour plus importante est aussi déjà annoncée sous le nom de C++17.
Améliorations possibles.
Les propositions d'améliorations suivantes ont été faites :
L'ajout de deux "headers" à la bibliothèque standard, codice_11 et codice_12, ont dans un premier temps été espérés pour C++14, mais quelques jours après la conférence de Bristol (avril 2013), suivant les sources, il est possible que ces nouveautés soient repoussées pour C++17. Ces API ainsi que d'autres pourraient sortir sous la forme de "Technical Specifications" d'ici là.

</doc>
<doc id="182608" url="http://fr.wikipedia.org/wiki?curid=182608" title="Langage Ladder">
Langage Ladder

Ladder Diagram (LD) ou Langage Ladder ou schéma à contacts est un langage graphique très populaire auprès des automaticiens pour programmer les Automates Programmables Industriels. Il ressemble un peu aux schémas électriques, et est facilement compréhensible.
"Ladder" est le mot anglais pour échelle.
Origine.
L'idée initiale du Ladder est la représentation de fonction logique sous la forme de schémas électriques. Cette représentation est originalement matérielle : quand l'Automate Programmable Industriel n'existait pas, les fonctions étaient réalisées par des câblages. Par exemple, pour réaliser un ET logique avec des interrupteurs, il suffit de les mettre en série. Pour réaliser un OU logique, il faut les mettre en parallèle.
Le Ladder a été créé et normalisé dans la norme CEI 61131-3. Il est, depuis, très utilisé dans la programmation des Automates Programmables Industriels.
Principe.
Un programme Ladder se lit de haut en bas et l'évaluation des valeurs se fait de gauche à droite. Les valeurs correspondent en fait, si on le compare à un schéma électrique, à la présence ou non d'un potentiel électrique à chaque nœud de connexion.
En effet, le Ladder est basé sur le principe d’une alimentation en tension représentée par deux traits verticaux reliée horizontalement par des bobines, des contacts et des blocs fonctionnels, d'où le nom 'Ladder' (échelle).
Les composants du langage.
Il existe 3 types d'élément de langage :
Les entrées (ou contacts).
Il existe deux types de contact :
Ce contact est fermé lorsque la variable booléenne associée (X ici) est vraie, sinon, il est ouvert.
Ce contact est ouvert lorsque la variable booléenne associée (X ici) est vraie, sinon il est fermé.
Les sorties (ou bobines).
Il existe, de même que pour les contacts, deux types de bobines :
Si cette bobine est soumise à un potentiel, c’est-à-dire qu'il existe un circuit fermé reliant cette bobine des deux côtés du potentiel, alors la variable booléenne associée (X ici) est mémorisée à 'vraie', sinon elle est mémorisée à 'fausse'.
Si cette bobine est soumise à un potentiel, c’est-à-dire qu'il existe un circuit fermé reliant cette bobine des deux côtés du potentiel, alors la variable booléenne associée (X ici) est mémorisée à 'fausse', sinon elle est mémorisée à 'vraie'.
Réalisation de fonction logique.
Comme dit précédemment, les fonctions logiques sont dérivées de leurs réalisations électriques. Donc chaque fonction logique (AND, OR, XOR, NAND, NOR, NOT) a une représentation qui correspond à son équivalent électrique.
C'est-à-dire :
équivaut à X AND Y
équivaut à NOT(X) AND Y
équivaut à X OR Y 
Plus complexe :
équivaut à S = X.(Y+Z)
Exemple de lecture.
Dans ce réseau, si A OU B est actionné ET si F n'est pas actionné, la sortie S est active; soit S = (A+B)./F
Le signe "/F" signifie l'inversion de l'entrée "F", cela se prononce "F barre".

</doc>
<doc id="1229314" url="http://fr.wikipedia.org/wiki?curid=1229314" title="Haxe">
Haxe

Haxe est un langage de programmation développé par Nicolas Cannasse et la société Motion-Twin qui, dans le cadre d’une utilisation pour le Web, permet d’écrire la partie serveur et la partie client dans un même langage.
À cette fin, Haxe permet de :
Haxe permet donc d'assurer l’interopérabilité entre ces différentes plateformes en fournissant des bibliothèques communes.
Il permet, par ailleurs, de créer du code C++, et des cibles Java et C# sont en préparation (courant 2012 - 2013) .
Voir aussi.
Liens internes.
Neko (langage)

</doc>
<doc id="7470234" url="http://fr.wikipedia.org/wiki?curid=7470234" title="CHIP-8">
CHIP-8

CHIP-8 est un langage de programmation hexadécimal interprété utilisant une machine virtuelle, développé par Joseph Weisbecker en 1978. Il était spécifiquement conçu pour faciliter la conception de jeux vidéo sur les micro-ordinateurs 8-bits bas de gamme de cette époque, comme le COSMAC VIP, le Telmac 1800 ou le DREAM 6800.
Le CHIP-8 a connu un regain d'intérêt en 1990, lorsqu'un interpréteur avait été développé pour la calculatrice graphique HP-48, inspirant des évolutions du langage (Super Chip-48).
Des interpréteurs du CHIP-8 et ses évolutions ont été développées pour un grand nombre de plateformes. Ceci est en partie dû au fait que le court jeu d'instruction, la simplicité des caractéristiques, ainsi qu'une bonne documentation technique et une grande communauté ont fait de la machine virtuelle du CHIP-8 un cas d'école pour les programmeurs désirant débuter dans le développement des émulateurs.
Histoire.
En décembre 1978, Joseph Weisbecker introduit dans un article de Byte Magazine le CHIP-8 pour démontrer la puissance des langages de programmation hexadécimaux interprétés.
Le CHIP-8 se veut alors comme étant un langage de plus haut niveau que l'assembleur tout en restant un pseudo-langage machine, mais utilisable sur les machines bas de gamme de l'époque, n'ayant que 1 ou 2 kB de mémoire adressable, des terminaux monochromes basse résolution de quelques dizaines de pixels, et des claviers 16 touches.
Non seulement l'interpréteur CHIP-8 pouvait s'exécuter sur du matériel bas de gamme, ses programmes occupant 5 à 10 fois moins de place que des programmes équivalents en BASIC, à une époque où la mémoire RAM coutait extrêmement cher.
A titre comparatif, l'interpréteur BASIC le plus léger nécessitait au moins 8 kB de mémoire, un clavier complet et un terminal capable d'afficher des caractères alphanumériques, autrement dit un matériel dont le prix était encore hors de portée des particuliers.
Le langage CHIP-8 offre des boucles de contrôle, arithmétique, affichage de graphiques monochromes, émission de bips sonores, et support des claviers 16-touches hexadécimaux. De nombreux jeux phares de l'époque (Pong, Space Invaders, Pac-Man, etc.) sont vite adaptés en CHIP-8.
En 1990, Andreas Gustafsson développe un interpréteur en CHIP-8 pour la calculatrice graphique HP-48 qui manque alors de moyens de créer facilement des jeux. Ceci lance regain d'intérêt au langage, et entraine des évolutions baptisées Chip-48, puis Super Chip-48 visant à tirer parti des possibilités de la calculatrice HP-48, notamment une plus grande résolution des graphismes. Par la suite, la machine virtuelle de CHIP-8 a souvent été utilisée comme cas pratique pour les gens souhaitant s'initier à la programmation d'émulateurs, et des implémentations de l'interpréteur de CHIP-8 et ses évolutions ont été développés sur une grande variété de plateformes.
Caractéristiques de la machine virtuelle.
CHIP-8 peut adresser 3584 octets de mémoire sur la plage 0x200 - 0xFFF. Sur les premiers ordinateurs où CHIP-8 était implémenté, l'interpréteur occupait les 512 octets de la plage 0x000 à 0x1FF. De plus la plage 0xF00 à 0xFFF était réservée à l'affichage, et la plage 0xEA0 à 0xEFF à la pile d'appel et les variables.
La machine virtuelle du CHIP-8 implémente 16 registres de données de 8 bits, nommés V0 à VF. Le registre VF sert d'indicateur de retenue et son contenu est modifié par certaines fonctions. CHIP-8 comprend également un registre d'index de 16 bits exploité par certaines fonctions de mémoire. Enfin, il existe des registres utilisés par l'interpréteur mais inaccessibles aux programmes qui comprennent un compteur de programme de 16-bits et un pointeur de pile de 8-bits qui pointe vers le plus haut niveau de la pile.
CHIP-8 utilise également une pile stockant les adresses de retour des sous-routines. Originellement, 48 octets étaient alloués pour cette pile, permettant jusqu'à 12 niveaux d'appels.
CHIP-8 comporte deux timers :
Les tiers sont décrémentés à une cadence de 60 hertz jusqu'à ce qu'ils atteignent zéro.
Les entrées sont faites à l'aide de claviers à 16 touches prenant les valeurs 0x0 à 0xF. Les touches 2,4,6 et 8 sont usuellement utilisées comme flèches directionnelles. CHIP-8 fournit des fonctions permettant de détecter qu'une touche a été pressée ou non, ou d'attendre qu'une touche soit pressée.
CHIP-8 supporte une résolution d'affichage de 64x32 pixels monochromes. L'affichage des graphiques se fait uniquement par sprite de 8 pixels de large pour 1 à 15 de haut. L'affichage des sprites se fait uniquement en mode XOR, et si un pixel est désactivé lors de l'affichage d'un sprite, l'indicateur de retenue est fixé à 1, ce qui permet la détection de collision.
CHIP-8 comporte originellement 35 codes opérations (CHIP-48 ayant ajouté dix instructions supplémentaires). Les instructions ont une longueur de deux octets. Les bits de poids fort des adresses sont stockés en premier.

</doc>
<doc id="7590815" url="http://fr.wikipedia.org/wiki?curid=7590815" title="JADE (langage de programmation)">
JADE (langage de programmation)

JADE est une plateforme de programmation multi-agent implémentée en java. Les agents qui tournent sous JADE communiquent via le langage "Agent Communication Language" ou ACL.

</doc>
<doc id="6469" url="http://fr.wikipedia.org/wiki?curid=6469" title="Java (langage)">
Java (langage)

Le langage Java est un langage de programmation informatique orienté objet créé par James Gosling et Patrick Naughton, employés de Sun Microsystems, avec le soutien de Bill Joy (cofondateur de Sun Microsystems en 1982), présenté officiellement le au "SunWorld".
La société Sun a été ensuite rachetée en 2009 par la société Oracle qui détient et maintient désormais Java.
La particularité et l'objectif central de Java est que les logiciels écrits dans ce langage doivent être très facilement portables sur plusieurs systèmes d’exploitation tels que UNIX, Windows, Mac OS ou GNU/Linux, avec peu ou pas de modifications. Pour cela, divers plateformes et frameworks associés visent à guider, sinon garantir, cette portabilité des applications développées en Java.
Aperçu.
Le langage Java reprend en grande partie la syntaxe du langage C++, très utilisée par les informaticiens. Néanmoins, Java a été épuré des concepts les plus subtils du C++ et à la fois les plus déroutants, tels que les pointeurs et références, ou l’héritage multiple contourné par l’implémentation des interfaces. Les concepteurs ont privilégié l’approche orientée objet de sorte qu’en Java, tout est objet à l’exception des types primitifs (nombres entiers, nombres à virgule flottante, etc.).
Java permet de développer des applications client-serveur. Côté client, les applets sont à l’origine de la notoriété du langage. C’est surtout côté serveur que Java s’est imposé dans le milieu de l’entreprise grâce aux servlets, le pendant serveur des applets, et plus récemment les JSP (JavaServer Pages) qui peuvent se substituer à PHP, ASP et ASP.NET.
Java a donné naissance à un système d'exploitation (JavaOS), à des environnements de développement (eclipse/JDK), des machines virtuelles (, JRE) applicatives multiplate-forme (JVM), une déclinaison pour les périphériques mobiles/embarqués (J2ME), une bibliothèque de conception d'interface graphique (AWT/Swing), des applications lourdes (Jude, Oracle SQL Worksheet, etc.), des technologies web (servlets, applets) et une déclinaison pour l'entreprise (J2EE). La portabilité du bytecode Java est assurée par la machine virtuelle Java, et éventuellement par des bibliothèques standard incluses dans un JRE.
Cette machine virtuelle peut interpréter le bytecode ou le compiler à la volée en langage machine.
La portabilité est dépendante de la qualité de portage des JVM sur chaque OS.
Historique.
"N’hésitez pas à vérifier la qualité de la traduction pour être certain qu’il n’y ait pas de contresens."
L'origine du langage.
Le langage Java est issu d’un projet de Sun Microsystems datant de 1990 : l’ingénieur Patrick Naughton n’était pas satisfait par le langage C++ utilisé chez Sun, ses interfaces de programmation en langage C, ainsi que les outils associés. Alors qu’il envisageait une migration vers NeXT, on lui proposa de travailler sur une nouvelle technologie et c’est ainsi que le Projet (furtif) vit le jour.
Le Projet fut rapidement rebaptisé avec l’arrivée de James Gosling et de Mike Sheridan. Ensemble, aidés d’autres ingénieurs, ils commencèrent à travailler dans un bureau de la rue Sand Hill à Menlo Park en Californie. Ils essayèrent d’élaborer une technologie pour le développement d’applications d’une nouvelle génération, offrant à Sun la perspective d’opportunités uniques.
L’équipe envisageait initialement d’utiliser le langage C++, mais l’abandonna pour différentes raisons. Tout d’abord, ils développaient sur un système embarqué avec des ressources limitées et estimaient que l’utilisation du C++ demandait un investissement trop important et que cette complexité était une source d’erreur pour les développeurs. L'absence de ramasse-miettes impliquait que la gestion de la mémoire devait être programmée manuellement, un défi mais aussi une source d’erreur(s).
L’équipe était aussi troublée par les lacunes du langage C++ au niveau de la sécurité, de la programmation distribuée, du . De plus, ils voulaient une plate-forme qui puisse être portée sur tout type d’appareils ou de plate-forme.
Bill Joy avait envisagé un nouveau langage combinant le meilleur du langage de programmation Mesa et du langage C. Dans un article appelé "Plus loin ()", il proposa à Sun que ses ingénieurs développent un environnement orienté objet basé sur le langage C++. À l’origine, Gosling envisageait de modifier et d’améliorer le langage C++, qu’il appelait C++ ++ --, mais l’idée fut bientôt abandonnée au profit du développement d’un nouveau langage de programmation qu’ils appelèrent (chêne) en référence, selon la légende, à un arbre planté devant la fenêtre de leur bureau.
L’équipe travailla avec acharnement et, à l’été 1992, ils furent capables de faire une démonstration constituée d'une plate-forme incluant le système d’exploitation Green, le langage Oak (1992), les bibliothèques et le matériel. Leur première réalisation, présentée le , fut la construction d’un PDA appelé Star7 ayant une interface graphique et un agent intelligent appelé Duke pour prêter assistance à l’utilisateur.
En novembre de la même année, le fut abandonné pour devenir FirstPerson, Inc, appartenant en totalité à Sun Microsystems et l’équipe fut relocalisée à Palo Alto. L’équipe FirstPerson était intéressée par la construction d’outils hautement interactifs et quand Time Warner publia un appel d’offres en faveur d’un décodeur multifonctions, FirstPerson changea d’objectif pour proposer une telle plate-forme.
Cependant, l’industrie de la télévision par câble trouva qu’elle offrait trop de possibilités à l’utilisateur et FirstPerson perdit le marché au profit de Silicon Graphics. Incapable d’intéresser l’industrie audiovisuelle, la société fut réintégrée au sein de Sun.
Java rencontre Internet.
De juin à , après trois jours de remue-méninges avec John Gage, James Gosling, Joy, Naughton, Wayne Rosing et Eric Schmidt, l’équipe recentra la plate-forme sur le web. Ils pensaient qu’avec l’avènement du navigateur Mosaic, Internet était le lieu où allait se développer le même genre d’outil interactif que celui qu’ils avaient envisagé pour l’industrie du câble. Naughton développa comme prototype un petit navigateur web, WebRunner qui deviendra par la suite HotJava.
La même année le langage fut renommé Java après qu’on eut découvert que le nom était déjà utilisé par un fabricant de carte vidéo.
Origine du nom Java.
Le nom Java fut inventé dans un petit bar fréquenté par quelques membres de l’équipe. Il n’a pas été déterminé clairement si ce nom est un acronyme :
La croyance selon laquelle Java doit son nom aux produits vendus dans le bar tient au fait que le code sur (également appelé nombre magique) des fichiers de classe est en hexadécimal 0xCAFEBABE.
Certaines personnes prétendent également que le nom de Java vient du fait que le programme était destiné à pouvoir tourner sur des systèmes embarqués, comme des cafetières (Java signifiant café en argot américain). De là vient le logo actuel de Java, schématisant une tasse de café fumant.
Lancement public de Java.
En , HotJava et la plate-forme Java furent présentés pour Sun Executives. Java 1.0a fut disponible en téléchargement en 1994 mais la première version publique du navigateur HotJava arriva le à la conférence SunWorld.
L’annonce fut effectuée par John Gage, le directeur scientifique de Sun Microsystems. Son annonce fut accompagnée de l’annonce surprise de Marc Andressen, vice-président de l’exécutif de Netscape que Netscape allait inclure le support de Java dans ses navigateurs. Le , le groupe Javasoft fut constitué par Sun Microsystems pour développer cette technologie. Deux semaines plus tard la première version de Java était disponible.
Avènement de Java 2.
L'apparition de la version 1.2 du langage marque un tournant significatif : c'est en 2000 qu'apparait simultanément la déclinaison en deux plateformes Java :
Sun les qualifie alors de plateforme Java 2 par opposition aux premières générations 1.0 et 1.1. Toutes les versions ultérieures, de J2EE 1.2 à Java SE ou Java EE 7 restent désignées sous le qualificatif de plateformes Java 2, bien que le '2' ait été depuis officiellement abandonné.
Histoire récente.
Utilisation Web.
Côté client.
Applets
Historiquement, la possibilité des navigateurs Web de lancer des applets Java était la seule solution pour afficher des applications clientes riches (RIA pour Rich Internet Application). Puis des technologies concurrentes ont émergé parmi lesquelles Macromedia Flash, le DHTML JavaScript, Silverlight basé sur XAML ou Xul.
Les applets sur le poste Client peuvent communiquer avec des servlets sur le Serveur, tout comme Javascript peut communiquer avec le Serveur au moyen d’AJAX. Flex utilise quant à lui la technologie Flash par le biais du Adobe Flash Player.
À une époque où Javascript souffrait de problèmes de compatibilité inter-navigateur, les applets Java avaient l'avantage de la portabilité car le portage d'interfaces complexes était difficile à assurer pour tous les navigateurs du marché.
Mais les progrès faits dans les technologies concurrentes à Java ont amené la plupart des développeurs à se détourner des applets Java et des problèmes inhérents à cette technologie (incompatibilités entre les JVM, mauvaises performances, pauvreté des bibliothèques graphiques, complexité), outre la retombée de la « mode » Java. Enfin, les navigateurs modernes n'incluent plus systématiquement l'environnement Java à cause de sa taille importante, et le taux de machines capables d'afficher des applets n'était plus que de 70 % en 2010, bien plus faible que pour Flash par exemple. En 2010, la quasi-totalité des applications clients riches utilisent des technologies alternatives ; Flash pour l'essentiel mais aussi GWT.
Enfin, la perspective de l'arrivée prochaine de HTML5, destiné à embarquer de nombreuses fonctionnalités RIA et multimédia, rend également les applets caduques.
JavaFX
JavaFX est une plateforme pour Rich Internet Applications, un peu comme Adobe Flash. Cependant, là encore, la concurrence est rude. Microsoft Silverlight, et la convergence de Adobe Flash et de JavaScript/Ecmascript en ActionScript, sont également bien positionnées dans ce nouveau domaine.
Côté serveur.
Avec les serveurs d’applications, on utilise des EJB pour encapsuler les classes définies précédemment. Ces éléments sont utilisés dans des architectures J2EE pour des applications multicouches.
L'avantage qu'on tire de ce travail est de pouvoir cacher au client l'implémentation du code côté serveur.
Utilisation sur poste de travail.
L’utilisation native du langage Java pour des applications sur un poste de travail restait jusqu'à présent relativement rare à cause de leur manque de rapidité. Cependant, avec l’accroissement rapide de la puissance des ordinateurs, les améliorations au cours de la dernière décennie de la machine virtuelle Java et de la qualité des compilateurs, plusieurs technologies ont gagné du terrain comme Netbeans et l’environnement Eclipse, les technologies de fichiers partagés LimeWire, Vuze (ex Azureus), et I2P. Java est aussi utilisé dans le programme de mathématiques Matlab, au niveau de l’interface homme machine et pour le calcul formel. Les applications Swing apparaissent également comme une alternative à la technologie .NET.
Utilisation avec les mobiles.
Oracle annonce début octobre 2012 à la conférence JavaOne sa volonté de proposer des solutions Java pour le domaine des logiciels embarqués, pour processeurs moins puissants que ceux habituellement disponibles sur les PC. Oracle fédère autour d'elle tout un éco-système d'entreprises spécialistes de ces segments de marchés, comme l'éditeur IS2T ou encore STMicroelectronics qui propose du Java sur ses STM32 dont le cœur est un CortexM3/M4.
Java, notamment via Eclipse et NetBeans, offre déjà des environnements de développement intégrés pour mobile. Java est le principal langage utilisé pour développer des applications pour le système d'exploitation libre pour Mobile de Google : Android.
JavaFX peut aussi permettre l'utilisation de Java sur mobiles, bien que ce ne soit pas son objectif principal.
OS Windows, Mac OS X et Linux.
Microsoft a fourni en 2001 un environnement de travail de type Java, dénommé J++, avec ses systèmes d’exploitation avant la sortie de Windows XP. Suite à une décision de justice, et au vu du non-respect des spécifications de ce langage, Microsoft a dû abandonner celui-ci et créer un nouveau langage, de nom C# (cf. chapitre « Indépendance vis-à-vis de la plate-forme » plus bas)
Beaucoup de fabricants d’ordinateurs continuent d’inclure un environnement JRE sur leurs systèmes Windows.
Java apparaît également comme un standard au niveau du MacOS X d’Apple aussi bien que pour les distributions Linux. Ainsi, de nos jours, la plupart des utilisateurs peuvent lancer des applications Java sans aucun problème.
Toutefois, sur ordinateur Apple, la distribution de Java 5 à Java 6 fut assurée directement par Apple, et non par Oracle. Cette politique entraîna des retards et des restrictions de version :
Passage sous licence open-source.
Le , le code source du compilateur javac et de la machine virtuelle ont été publiés en Open Source sous la Licence publique générale GNU.
Le , Sun Microsystems annonce le passage de Java, c’est-à-dire le JDK (JRE et outils de développement) et les environnements Java EE (déjà sous licence CDDL) et Java ME sous licence GPL d’ici mars 2007, sous le nom de projet OpenJDK.
En , Sun publie effectivement OpenJDK sous licence libre. Cependant OpenJDK dépend encore de fragments de code non libre que Sun ne détient pas. C'est pourquoi la société Redhat lance en le projet qui vise à remplacer les fragments de code non libre et ainsi rendre OpenJDK utilisable sans aucun logiciel propriétaire. En , le projet IcedTea a passé les tests rigoureux de compatibilité Java (TCK). 
IcedTea est donc une implémentation open-source des spécifications de Java. Sun, puis Oracle, garde toutefois le contrôle de la technologie par le biais d'un catalogue de brevets s'appliquant à Java, ainsi que par le maintien du TCK sous une licence propriétaire.
Acquisition par Oracle.
La société Oracle a acquis en 2009 l'entreprise Sun Microsystems. On peut désormais voir apparaître le logo Oracle dans les documentations de l'api Java.
Le 12 avril 2010, James Gosling, le créateur du langage de programmation Java démissionne d’Oracle pour des motifs qu’il ne souhaite pas divulguer. Il était devenu le directeur technologique de la division logicielle client pour Oracle.
Historique des versions.
Le langage Java a connu plusieurs évolutions depuis le JDK 1.0 () avec l’ajout de nombreuses classes et packages à la bibliothèque standard. Depuis le J2SE1.4, l’évolution de Java est dirigée par le JCP () qui utilise les JSR () pour proposer des ajouts et des changements sur la plate-forme Java. Le langage lui-même est spécifié par le JLS (), les modifications du JLS étant gérées sous le code JSR 901.
Il faut noter que les évolutions successives du langage ne portent guère sur sa syntaxe -relativement stable depuis le début- mais principalement sur l'enrichissement de ses fonctions, avec l'embarquement et l'optimisation de bibliothèques logicielles (API) dans des domaines très variés de l'informatique : bases de données, gestion XML, informatique distribuée et web, multimédia, sécurité…
Numérotation des versions.
Il faut distinguer la version du langage Java de celles des plateformes et du JRE :
Philosophie.
Lors de la création du langage Java, il avait été décidé que ce langage devait répondre à cinq objectifs :
Un langage orienté objet et familier.
La première caractéristique, le caractère orienté objet (« OO ») et familier, fait référence à une méthode de programmation et de conception du langage et le fait qu'un programme écrit en Java ressemble assez fort à un programme écrit en C++.
Bien qu’il existe plusieurs interprétations de l’expression orienté objet, une idée phare dans ce type de développement est que les différents types de données doivent être directement associés avec les différentes opérations qu’on peut effectuer sur ces données. En conséquence, les données (appelées "Propriétés") et le code les manipulant (appelé "Méthodes") sont combinés dans une même entité appelée "Classe" d'objet. Le code devient logiquement découpé en petites entités cohérentes et devient ainsi plus simple à maintenir et plus facilement réutilisable, étant intrinsèquement modulaire.
D’autres mécanismes tels l’"héritage" permettent d’exploiter toutes les caractéristiques d’une "Classe" précédemment écrite dans ses propres programmes sans même avoir à en connaître le fonctionnement interne, on n’en voit que l’"interface" (l'interface décrit les propriétés et les méthodes sans fournir le code associé). Java interdit la notion d'héritage depuis plusieurs classes parent sauf si elles sont des interfaces.
Dans la version 1.5 du langage ont été rajoutés les "génériques", un mécanisme de polymorphisme semblable (mais différent) aux du langage C++ ou aux foncteurs d’OCaml. Les génériques permettent d’exprimer d’une façon plus simple et plus sûre les propriétés d’objets comme des conteneurs (listes, arbres…) : le type liste est alors considéré génériquement par rapport au type d’objet contenu dans la liste.
Mécanisme du ramasse-miettes.
Cet élément contribue à la robustesse et à la performance des programmes, le ramasse-miettes () est appelé régulièrement et automatiquement pendant l'exécution du programme. Sur les systèmes multi-processeurs et/ou multi-cœurs celui-ci emploie même des threads multiples à faible priorité afin de perturber le moins possible l'exécution de programme. En outre, le programmeur peut au besoin suggérer de lancer le ramasse-miettes à l’aide de la méthode "System.gc()".
Un grief récurrent à l’encontre de langages comme C++ est la lourde tâche d’avoir à programmer manuellement la gestion de la mémoire. En C++, la mémoire allouée par le programme pour créer un objet est désallouée lors de la destruction de celui-ci (le plus souvent par un appel explicite à l'opérateur ). Si le programmeur oublie de coder la désallocation, ceci aboutit à une « fuite mémoire », et le programme en consomme de plus en plus. Pire encore, si par erreur un programme demande plusieurs fois une désallocation, ou emploie une zone de mémoire après avoir demandé sa désallocation, celui-ci deviendra très probablement instable et se plantera.
En Java, une grande partie de ces problèmes est évitée grâce au ramasse-miettes. L'espace mémoire nécessaire à chaque objet créé est alloué dans un tas de mémoire () réservé à cet usage. Le programme peut ensuite accéder à chaque objet grâce à sa référence dans le tas. Quand il n'existe plus aucune référence permettant d'atteindre un objet, le ramasse-miettes le détruit automatiquement — puisqu'il est devenu inaccessible — libérant la mémoire et prévenant ainsi toute fuite de mémoire.
Le ramasse-miettes emploie un algorithme de marquage puis libération qui permet de gérer les cas complexes d'objets se référençant mutuellement ou de boucles de références (cas d'une liste à chaînage double par exemple). En pratique il subsiste des cas d'erreur de programmation où le ramasse-miettes considèrera qu'un objet est encore utile alors que le programme n'y accèdera plus, mais dans l’ensemble, le ramasse-miettes rend plus simple et plus sûre la destruction d’objets en Java (en supprimant la nécessité de placer au bon endroit du code l'appel à l'opérateur ).
Indépendance vis-à-vis de la plate-forme.
L’indépendance vis-à-vis de la plate-forme signifie que les programmes écrits en Java fonctionnent de manière parfaitement similaire sur différentes architectures matérielles. La licence de Sun pour Java insiste ainsi sur le fait que toutes les implémentations doivent être compatibles. On peut ainsi théoriquement effectuer le développement sur une architecture donnée et faire tourner l’application finale sur toutes les autres.
Ce résultat est obtenu par :
Noter que même s’il y a explicitement une première phase de compilation, le bytecode Java est soit interprété, soit converti à la volée en code natif par un compilateur à la volée (, JIT).
Types de compilations.
Les premières implémentations du langage utilisaient une machine virtuelle interprétée pour obtenir la portabilité. Ces implémentations produisaient des programmes qui s’exécutaient plus lentement que ceux écrits en langage compilé (C, C++, etc.) si bien que le langage souffrit d’une réputation de faibles performances.
Des implémentations plus récentes de la machine virtuelle Java (JVM) produisent des programmes beaucoup plus rapides qu’auparavant, en utilisant différentes techniques:
Bilan de la portabilité Java.
Après que Sun ait constaté que l’implémentation de Microsoft ne supportait pas les interfaces RMI et JNI, et comportait des éléments spécifiques à certaines plates-formes par rapport à sa plate-forme initiale, Sun déposa plainte en justice contre Microsoft, et obtint des dommages et intérêt (20 millions de dollars). Cet acte de justice renforça encore les termes de la licence de Sun. En réponse, Microsoft arrêta le support de Java sur ses plates-formes et, sur les versions récentes de Windows, Internet Explorer ne supporte pas les applets Java sans ajouter de plug-in. Cependant, Sun met à disposition gratuitement des environnements d’exécution de Java pour les différentes plates-formes Microsoft.
La portabilité est techniquement un objectif difficile à atteindre et le succès de Java en ce domaine est mitigé. Quoiqu’il soit effectivement possible d’écrire des programmes pour la plate-forme Java qui fonctionnent correctement sur beaucoup de machines cibles, le nombre important de plates-formes avec de petites erreurs et des incohérences a abouti à un détournement du slogan de Sun « » () en () !
L’indépendance de Java vis-à-vis de la plate-forme est cependant un succès avec les applications côté serveur comme les services web, les servlets et le Java Beans aussi bien que les systèmes embarqués sur OSGi, utilisant l’environnement .
Exécution sécurisée de code distant.
La plate-forme Java fut l’un des premiers systèmes à offrir le support de l’exécution du code à partir de sources distantes. Une applet peut fonctionner dans le navigateur web d’un utilisateur, exécutant du code téléchargé d’un serveur HTTP. Le code d’une applet fonctionne dans un espace très restrictif, ce qui protège l’utilisateur des codes erronés ou mal intentionnés. Cet espace est délimité par un objet appelé "gestionnaire de sécurité". Un tel objet existe aussi pour du code local, mais il est alors par défaut inactif.
Le gestionnaire de sécurité (la classe SecurityManager) permet de définir un certain nombre d’autorisations d’utilisation des ressources du système local (système de fichiers, réseau, propriétés système…). Une autorisation définit :
Les éditeurs d’applet peuvent demander un certificat pour leur permettre de signer numériquement une applet comme sûre, leur donnant ainsi potentiellement (moyennant l’autorisation adéquate) la permission de sortir de l’espace restrictif et d’accéder aux ressources du système local.
Éléments du langage.
Voici un exemple d’un programme typique écrit en Java :
Le fichier source porte presque toujours le nom de la classe avec l'extension ".java" (ici "HelloWorld.java", ce serait même obligatoire si la classe avait l'attribut public dans sa déclaration — la rendant alors accessible à tout autre programme). On peut compiler puis exécuter cet exemple avec les commandes suivantes (sous Linux) :
La ligne « export CLASSPATH=. » sert à indiquer à Java qu’il doit également chercher les programmes class dans le répertoire courant.
Ce chemin peut également être spécifié au lancement du programme par l’option -classpath (ou -cp en abrégé) :
Mots réservés, primitifs et littéraux.
Notes :
Types.
Pour instancier une variable, la syntaxe (ici la même qu'en C) est la suivante :
"maVariable" est alors allouée sur la pile.
Les collections d'objets.
Il est souvent nécessaire de stocker de nombreuses données dans des collections : liste d’achats, notes des élèves, etc.
Les collections peuvent être consultées, modifiées, on peut les trier, les recopier, les supprimer etc. Elles peuvent avoir une taille fixe ou variable.
Les collections à taille fixe sont moins lourdes que les collections à taille variable.
Collections de taille variable.
La classe abstraite codice_20 est fournie pour implémenter les collections à taille variable.
Structures de contrôle.
Boucles.
Bien qu’elles aient toutes un rôle similaire, chaque boucle est pourtant adaptée à une situation :
Structures conditionnelles.
Remarques : Java permet également d'utiliser la structure de contrôle switch sur une énumération ; par ailleurs le switch ne fonctionne pas sur toutes les constantes de type numérique mais seulement sur les entiers.
Switch fonctionne également avec des variables de type char.
La commande break sort immédiatement la boucle en cours (for, while, do), et permet de sortir d’une clause contenue dans un switch. Si le break est omis, l'exécution du switch se poursuit de case en case.
Une expression continue termine l’itération en cours et continue à la prochaine. Elle s’écrit comme suit : continue, mais son usage est à proscrire puisqu'elle tend à favoriser un type de programmation non structurée (programmation spaghetti).
L’énoncé return termine une méthode.
Avec return uneValeur, uneValeur sera renvoyée à la méthode appelante.
Opérateur ternaire ? : : Instruction conditionnelle pouvant être employée comme une expression
Traitement des exceptions.
Le bloc de code finally sera exécuté quel que soit le résultat lorsque le programme sortira du bloc try-catch.
Voici un exemple de capture d’une exception :
Cet exemple permet d’illustrer le mécanisme des exceptions en Java. Dans le cas d’une erreur d’entrée/sortie dans le bloc try, l’exécution reprend dans le bloc catch correspondant à cette situation (exception de type IOException).
Dans ce bloc catch, la variable e référence l’exception qui s’est produite. Ici, nous invoquons la méthode printStackTrace() qui affiche dans la console des informations sur l’exception qui s’est produite : nom, motif, état de la pile d’appels au moment de la levée de l’exception et, éventuellement, numéro de ligne auquel l’erreur s’est produite.
Le bloc finally est ensuite exécuté (ici pour refermer les ressources utilisées). Il ne s’agit ici que d’un exemple, l’action à mettre en œuvre lorsqu’une exception survient dépend du fonctionnement général de l’application et de la nature de l’exception.
Types génériques.
Un type générique est autrement appelé un Template, il prend un ou plusieurs autres types en arguments.
Le type passé en paramètre est déterminé lors de l'instanciation.
Cela permet notamment dans le cadre des ArrayList d'éviter les transtypages
Ces types génériques ne sont utilisés qu'à la compilation, et non directement dans le bytecode.
Différence avec le C++ : les templates en C++ dupliquent une classe pour chaque type. Java, au contraire, agit au moment de la compilation comme si on avait dupliqué les classes de ces types intrinsèques mais ne traite en réalité qu'avec une seule classe.
Codage du code source.
Les spécifications du langage Java précisent qu’il est formé de caractères au format UTF-16, ce qui permet l’utilisation dans le code source de tous les caractères existant dans le monde :
Pour assurer la portabilité entre plates-formes, les noms de classes devraient néanmoins être formés uniquement de caractères ASCII.
Environnements de développement.
JavaStyle.
Les JavaStyle sont des conventions de programmation en langage Java définies par Sun. Le respect de conventions strictes assure une homogénéité dans le code source d’une application développée par toute une équipe et favorise la diffusion du code source auprès d’une communauté partageant les mêmes conventions de codage.
On peut noter l'utilisation de lowerCamelCase pour les noms de méthodes et de variables.
Cf. Les conventions de nommage édictées par Oracle
Frameworks et API.
Sun fournit un grand nombre de et d’API afin de permettre l’utilisation de Java pour des usages très diversifiés.
On distingue essentiellement 4 grands :
La persistance est basée sur les standards :
On trouve toutefois de nombreuses autres technologies, API et extensions optionnelles pour Java :
Outils de développement.
La programmation peut se faire depuis une invite de commande en lançant un compilateur Java (souvent nommé javac), mais pour avoir plus de confort, il est préférable d’utiliser un environnement de développement intégré ou IDE, certains sont gratuits.
On peut citer :
Automatisation.
Un programme Java peut être produit avec des outils qui automatisent le processus de construction (c'est-à-dire l'automatisation de certaines tâches faisant appel à un nombre potentiellement grand de dépendances comme l'utilisation de bibliothèques, la compilation, la génération d'archives, de documentation, le déploiement, etc.).
Les plus utilisés sont :
Résultats :

</doc>
<doc id="7703217" url="http://fr.wikipedia.org/wiki?curid=7703217" title="Sizeof">
Sizeof

Dans les langages de programmation C et C++, l'opérateur unaire sizeof sert à calculer la taille de n'importe quel type de données, mesurée en nombre d'octets nécessaires pour stocker le type. Un octet dans ce contexte est de même taille qu'un « unsigned char », et peut faire plus de 8 bits, bien que ce soit rare.
Le résultat de sizeof est la taille du type de l'expression de son opérande (qui peut également être un nom de variable ou un spécificateur de type), et est de type entier non signé (généralement « size_t »). L'opérateur sizeof peut être appliqué à tout type de données (y compris les types primitifs comme les entiers ou les types à virgule flottante), des types de pointeurs ou des types de données composés (unions, structures ou classes C++).

</doc>
